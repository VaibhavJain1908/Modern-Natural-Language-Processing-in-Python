{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_for_NLP .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7wEs7iGPF79Z",
        "lKhYHjMwGmgN",
        "5iSza00XGsJZ",
        "JcWt47VeVReq",
        "PlJ8bQh1XpEg",
        "XYEy1WBlZKoz",
        "ZIAqM1WjaZEp",
        "vGj_cZXMnlKX",
        "8CWYqd7xnuz3",
        "lVlRBR7zo3ZD",
        "DlUH4wUlsHkD",
        "PNk4zWZp7Rm7",
        "kLC1k_UEB9AZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wEs7iGPF79Z",
        "colab_type": "text"
      },
      "source": [
        "# Stage 1: Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr4qjCArGB7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FViGQGgIGJot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKhYHjMwGmgN",
        "colab_type": "text"
      },
      "source": [
        "# Stage 2: Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iSza00XGsJZ",
        "colab_type": "text"
      },
      "source": [
        "## Loading files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8ew9Wr_GwTB",
        "colab_type": "text"
      },
      "source": [
        "We import files from our personal google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki_huYIOGlXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/europarl-v7.fr-en.en\",\n",
        "          mode='r',\n",
        "          encoding='utf-8') as f:\n",
        "    europarl_en = f.read()\n",
        "with open(\"/content/drive/My Drive/europarl-v7.fr-en.fr\",\n",
        "          mode='r',\n",
        "          encoding='utf-8') as f:\n",
        "    europarl_fr= f.read()\n",
        "with open(\"/content/drive/My Drive/P85-Non-Breaking-Prefix.en\",\n",
        "          mode='r',\n",
        "          encoding='utf-8') as f:\n",
        "    non_breaking_prefix_en= f.read()\n",
        "with open(\"/content/drive/My Drive/P85-Non-Breaking-Prefix.fr\",\n",
        "          mode='r',\n",
        "          encoding='utf-8') as f:\n",
        "    non_breaking_prefix_fr= f.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcWt47VeVReq",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzVhnc6iVTxU",
        "colab_type": "text"
      },
      "source": [
        "Getting the non_breaking_prefixes as a clean list of words with a point at the end so it is easier to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YbaubBhU2X7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_breaking_prefix_en = non_breaking_prefix_en.split(\"\\n\")\n",
        "non_breaking_prefix_en = [' ' + pref + '.' for pref in non_breaking_prefix_en]\n",
        "non_breaking_prefix_fr = non_breaking_prefix_fr.split(\"\\n\")\n",
        "non_breaking_prefix_fr = [' ' + pref + '.' for pref in non_breaking_prefix_fr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztVTUxHgWAdA",
        "colab_type": "text"
      },
      "source": [
        "We will need each word and other symbol that we want to keep to be in lower case and separated by spaces so we can \"tokenize\" them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CHj8Q_xV_19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_en = europarl_en\n",
        "# Add $$$ after non ending sentence points\n",
        "for prefix in non_breaking_prefix_en:\n",
        "    corpus_en = corpus_en.replace(prefix, prefix+\"$$$\")\n",
        "corpus_en = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\", \".$$$\", corpus_en)\n",
        "# Remove $$$ markers\n",
        "corpus_en = re.sub(r\".\\$\\$\\$\", '', corpus_en)\n",
        "# Clear multiple spaces\n",
        "corpus_en = re.sub(r\"  +\", \" \", corpus_en)\n",
        "corpus_en = corpus_en.split('\\n')\n",
        "\n",
        "corpus_fr = europarl_fr\n",
        "for prefix in non_breaking_prefix_fr:\n",
        "    corpus_fr = corpus_fr.replace(prefix, prefix + '$$$')\n",
        "corpus_fr = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\", \".$$$\", corpus_fr)\n",
        "corpus_fr = re.sub(r\".\\$\\$\\$\", '', corpus_fr)\n",
        "corpus_fr = re.sub(r\"  +\", \" \", corpus_fr)\n",
        "corpus_fr = corpus_fr.split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlJ8bQh1XpEg",
        "colab_type": "text"
      },
      "source": [
        "## Tokenizing text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKevqS9IXoK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    corpus_en, target_vocab_size = 2**13)\n",
        "tokenizer_fr = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    corpus_fr, target_vocab_size = 2**13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPTcpgzHYFNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE_EN = tokenizer_en.vocab_size + 2 # = 8190\n",
        "VOCAB_SIZE_FR = tokenizer_fr.vocab_size + 2 # = 8171"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMCFgGPdYiUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = [[VOCAB_SIZE_EN-2] + tokenizer_en.encode(sentence) + [VOCAB_SIZE_EN-1]\n",
        "          for sentence in corpus_en]\n",
        "outputs = [[VOCAB_SIZE_FR-2] + tokenizer_fr.encode(sentence) + [VOCAB_SIZE_FR-1]\n",
        "          for sentence in corpus_fr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYEy1WBlZKoz",
        "colab_type": "text"
      },
      "source": [
        "## Remove too long sentences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88M0ZSMWY69c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "idx_to_remove = [count for count, sent in enumerate(inputs)\n",
        "                 if len(sent) > MAX_LENGTH]\n",
        "for idx in reversed(idx_to_remove):\n",
        "    del inputs[idx]\n",
        "    del outputs[idx]\n",
        "idx_to_remove = [count for count, sent in enumerate(outputs)\n",
        "                 if len(sent) > MAX_LENGTH]\n",
        "for idx in reversed(idx_to_remove):\n",
        "    del inputs[idx]\n",
        "    del outputs[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIAqM1WjaZEp",
        "colab_type": "text"
      },
      "source": [
        "## Inputs/outputs creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HFoe0ZBaaED",
        "colab_type": "text"
      },
      "source": [
        "As we train with batches, we need each input to have the same length. We pad with the appropriate token, and we will make sure this padding token doesn't interfere with our training later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkWhA2NbaVaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                       value=0,\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=MAX_LENGTH)\n",
        "outputs = tf.keras.preprocessing.sequence.pad_sequences(outputs,\n",
        "                                                        value=0,\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=MAX_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EixoiXw9alZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xI0fYKsbUCv",
        "colab_type": "text"
      },
      "source": [
        "# Stage 3: Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE95D_xBbeFm",
        "colab_type": "text"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qe2QRpHbh6I",
        "colab_type": "text"
      },
      "source": [
        "Positional encoding formulae:\n",
        "\n",
        "$PE_{(pos,2i)} =\\sin(pos/10000^{2i/dmodel})$\n",
        "\n",
        "$PE_{(pos,2i+1)} =\\cos(pos/10000^{2i/dmodel})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4KF7FumbTkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoding(layers.Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "    \n",
        "    def get_angles(self, pos, i, d_model):\n",
        "        angles = 1 / np.power(10000., (2*(i//2)) / np.float32(d_model))\n",
        "        return pos * angles\n",
        "\n",
        "    def call(self, inputs):\n",
        "        seq_length = inputs.shape.as_list()[-2]\n",
        "        d_model = inputs.shape.as_list()[-1]\n",
        "        angles = self.get_angles(np.arange(seq_length)[:, np.newaxis],\n",
        "                                 np.arange(d_model)[np.newaxis, :],\n",
        "                                 d_model)\n",
        "        angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
        "        angles[:, 1::2] = np.cos(angles[:, 1::2])\n",
        "        pos_encoding = angles[np.newaxis, ...]\n",
        "        return inputs + tf.cast(pos_encoding, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGj_cZXMnlKX",
        "colab_type": "text"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CWYqd7xnuz3",
        "colab_type": "text"
      },
      "source": [
        "### Attention computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3KEteHynv33",
        "colab_type": "text"
      },
      "source": [
        "$Attention(Q, K, V ) = \\text{softmax}\\left(\\dfrac{QK^T}{\\sqrt{d_k}}\\right)V $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqU98SE3bQNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(queries, keys, values, mask):\n",
        "    product = tf.matmul(queries, keys, transpose_b=True)\n",
        "    \n",
        "    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
        "    scaled_product = product / tf.math.sqrt(keys_dim)\n",
        "    \n",
        "    if mask is not None:\n",
        "        scaled_product += (mask * -1e9)\n",
        "    \n",
        "    attention = tf.matmul(tf.nn.softmax(scaled_product, axis=-1), values)\n",
        "    \n",
        "    return attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVlRBR7zo3ZD",
        "colab_type": "text"
      },
      "source": [
        "### Multi-head attention sublayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltvde785oya7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(layers.Layer):\n",
        "    \n",
        "    def __init__(self, nb_proj):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.nb_proj = nb_proj\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.d_model = input_shape[-1]\n",
        "        assert self.d_model % self.nb_proj == 0\n",
        "        \n",
        "        self.d_proj = self.d_model // self.nb_proj\n",
        "        \n",
        "        self.query_lin = layers.Dense(units=self.d_model)\n",
        "        self.key_lin = layers.Dense(units=self.d_model)\n",
        "        self.value_lin = layers.Dense(units=self.d_model)\n",
        "        \n",
        "        self.final_lin = layers.Dense(units=self.d_model)\n",
        "        \n",
        "    def split_proj(self, inputs, batch_size): # inputs: (batch_size, seq_length, d_model)\n",
        "        shape = (batch_size,\n",
        "                 -1,\n",
        "                 self.nb_proj,\n",
        "                 self.d_proj)\n",
        "        splited_inputs = tf.reshape(inputs, shape=shape) # (batch_size, seq_length, nb_proj, d_proj)\n",
        "        return tf.transpose(splited_inputs, perm=[0, 2, 1, 3]) # (batch_size, nb_proj, seq_length, d_proj)\n",
        "    \n",
        "    def call(self, queries, keys, values, mask):\n",
        "        batch_size = tf.shape(queries)[0]\n",
        "        \n",
        "        queries = self.query_lin(queries)\n",
        "        keys = self.key_lin(keys)\n",
        "        values = self.value_lin(values)\n",
        "        \n",
        "        queries = self.split_proj(queries, batch_size)\n",
        "        keys = self.split_proj(keys, batch_size)\n",
        "        values = self.split_proj(values, batch_size)\n",
        "        \n",
        "        attention = scaled_dot_product_attention(queries, keys, values, mask)\n",
        "        \n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        \n",
        "        concat_attention = tf.reshape(attention,\n",
        "                                      shape=(batch_size, -1, self.d_model))\n",
        "        \n",
        "        outputs = self.final_lin(concat_attention)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlUH4wUlsHkD",
        "colab_type": "text"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfMLz5NAsGBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(layers.Layer):\n",
        "    \n",
        "    def __init__(self, FFN_units, nb_proj, dropout_rate):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.FFN_units = FFN_units\n",
        "        self.nb_proj = nb_proj\n",
        "        self.dropout_rate = dropout_rate\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.d_model = input_shape[-1]\n",
        "        \n",
        "        self.multi_head_attention = MultiHeadAttention(self.nb_proj)\n",
        "        self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n",
        "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=self.FFN_units, activation=\"relu\")\n",
        "        self.dense_2 = layers.Dense(units=self.d_model)\n",
        "        self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n",
        "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "    def call(self, inputs, mask, training):\n",
        "        attention = self.multi_head_attention(inputs,\n",
        "                                              inputs,\n",
        "                                              inputs,\n",
        "                                              mask)\n",
        "        attention = self.dropout_1(attention, training=training)\n",
        "        attention = self.norm_1(attention + inputs)\n",
        "        \n",
        "        outputs = self.dense_1(attention)\n",
        "        outputs = self.dense_2(outputs)\n",
        "        outputs = self.dropout_2(outputs, training=training)\n",
        "        outputs = self.norm_2(outputs + attention)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KamStqDOzJSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(layers.Layer):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 nb_layers,\n",
        "                 FFN_units,\n",
        "                 nb_proj,\n",
        "                 dropout_rate,\n",
        "                 vocab_size,\n",
        "                 d_model,\n",
        "                 name=\"encoder\"):\n",
        "        super(Encoder, self).__init__(name=name)\n",
        "        self.nb_layers = nb_layers\n",
        "        self.d_model = d_model\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding()\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        self.enc_layers = [EncoderLayer(FFN_units,\n",
        "                                        nb_proj,\n",
        "                                        dropout_rate) \n",
        "                           for _ in range(nb_layers)]\n",
        "    \n",
        "    def call(self, inputs, mask, training):\n",
        "        outputs = self.embedding(inputs)\n",
        "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        outputs = self.pos_encoding(outputs)\n",
        "        outputs = self.dropout(outputs, training)\n",
        "        \n",
        "        for i in range(self.nb_layers):\n",
        "            outputs = self.enc_layers[i](outputs, mask, training)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNk4zWZp7Rm7",
        "colab_type": "text"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_repr7S7QDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderLayer(layers.Layer):\n",
        "    \n",
        "    def __init__(self, FFN_units, nb_proj, dropout_rate):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.FFN_units = FFN_units\n",
        "        self.nb_proj = nb_proj\n",
        "        self.dropout_rate = dropout_rate\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.d_model = input_shape[-1]\n",
        "        \n",
        "        # Self multi head attention\n",
        "        self.multi_head_attention_1 = MultiHeadAttention(self.nb_proj)\n",
        "        self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n",
        "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "        # Multi head attention combined with encoder output\n",
        "        self.multi_head_attention_2 = MultiHeadAttention(self.nb_proj)\n",
        "        self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n",
        "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "        # Feed foward\n",
        "        self.dense_1 = layers.Dense(units=self.FFN_units,\n",
        "                                    activation=\"relu\")\n",
        "        self.dense_2 = layers.Dense(units=self.d_model)\n",
        "        self.dropout_3 = layers.Dropout(rate=self.dropout_rate)\n",
        "        self.norm_3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
        "        attention = self.multi_head_attention_1(inputs,\n",
        "                                                inputs,\n",
        "                                                inputs,\n",
        "                                                mask_1)\n",
        "        attention = self.dropout_1(attention, training)\n",
        "        attention = self.norm_1(attention + inputs)\n",
        "        \n",
        "        attention_2 = self.multi_head_attention_2(attention,\n",
        "                                                  enc_outputs,\n",
        "                                                  enc_outputs,\n",
        "                                                  mask_2)\n",
        "        attention_2 = self.dropout_2(attention_2, training)\n",
        "        attention_2 = self.norm_2(attention_2 + attention)\n",
        "        \n",
        "        outputs = self.dense_1(attention_2)\n",
        "        outputs = self.dense_2(outputs)\n",
        "        outputs = self.dropout_3(outputs, training)\n",
        "        outputs = self.norm_3(outputs + attention_2)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGy_kSdhAVMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(layers.Layer):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 nb_layers,\n",
        "                 FFN_units,\n",
        "                 nb_proj,\n",
        "                 dropout_rate,\n",
        "                 vocab_size,\n",
        "                 d_model,\n",
        "                 name=\"decoder\"):\n",
        "        super(Decoder, self).__init__(name=name)\n",
        "        self.d_model = d_model\n",
        "        self.nb_layers = nb_layers\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding()\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        \n",
        "        self.dec_layers = [DecoderLayer(FFN_units,\n",
        "                                        nb_proj,\n",
        "                                        dropout_rate) \n",
        "                           for i in range(nb_layers)]\n",
        "    \n",
        "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
        "        outputs = self.embedding(inputs)\n",
        "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        outputs = self.pos_encoding(outputs)\n",
        "        outputs = self.dropout(outputs, training)\n",
        "        \n",
        "        for i in range(self.nb_layers):\n",
        "            outputs = self.dec_layers[i](outputs,\n",
        "                                         enc_outputs,\n",
        "                                         mask_1,\n",
        "                                         mask_2,\n",
        "                                         training)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLC1k_UEB9AZ",
        "colab_type": "text"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKTX5977B4S5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocab_size_enc,\n",
        "                 vocab_size_dec,\n",
        "                 d_model,\n",
        "                 nb_layers,\n",
        "                 FFN_units,\n",
        "                 nb_proj,\n",
        "                 dropout_rate,\n",
        "                 name=\"transformer\"):\n",
        "        super(Transformer, self).__init__(name=name)\n",
        "        \n",
        "        self.encoder = Encoder(nb_layers,\n",
        "                               FFN_units,\n",
        "                               nb_proj,\n",
        "                               dropout_rate,\n",
        "                               vocab_size_enc,\n",
        "                               d_model)\n",
        "        self.decoder = Decoder(nb_layers,\n",
        "                               FFN_units,\n",
        "                               nb_proj,\n",
        "                               dropout_rate,\n",
        "                               vocab_size_dec,\n",
        "                               d_model)\n",
        "        self.last_linear = layers.Dense(units=vocab_size_dec, name=\"lin_ouput\")\n",
        "    \n",
        "    def create_padding_mask(self, seq):\n",
        "        mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "        return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "    def create_look_ahead_mask(self, seq):\n",
        "        seq_len = tf.shape(seq)[1]\n",
        "        look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "        return look_ahead_mask\n",
        "    \n",
        "    def call(self, enc_inputs, dec_inputs, training):\n",
        "        enc_mask = self.create_padding_mask(enc_inputs)\n",
        "        dec_mask_1 = tf.maximum(\n",
        "            self.create_padding_mask(dec_inputs),\n",
        "            self.create_look_ahead_mask(dec_inputs)\n",
        "        )\n",
        "        dec_mask_2 = self.create_padding_mask(enc_inputs)\n",
        "        \n",
        "        enc_outputs = self.encoder(enc_inputs, enc_mask, training)\n",
        "        dec_outputs = self.decoder(dec_inputs,\n",
        "                                   enc_outputs,\n",
        "                                   dec_mask_1,\n",
        "                                   dec_mask_2,\n",
        "                                   training)\n",
        "        \n",
        "        outputs = self.last_linear(dec_outputs)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IjFtIcNk8uD",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrGB3snwk5rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "D_MODEL = 128 # 512\n",
        "NB_LAYERS = 4 # 6\n",
        "FFN_UNITS = 512 # 2048\n",
        "NB_PROJ = 8 # 8\n",
        "DROPOUT_RATE = 0.1 # 0.1\n",
        "\n",
        "transformer = Transformer(vocab_size_enc=VOCAB_SIZE_EN,\n",
        "                          vocab_size_dec=VOCAB_SIZE_FR,\n",
        "                          d_model=D_MODEL,\n",
        "                          nb_layers=NB_LAYERS,\n",
        "                          FFN_units=FFN_UNITS,\n",
        "                          nb_proj=NB_PROJ,\n",
        "                          dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xZvAlujmg8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction=\"none\")\n",
        "\n",
        "def loss_function(target, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(target, 0))\n",
        "    loss_ = loss_object(target, pred)\n",
        "    \n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    \n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXEwrX1GomgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    \n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        \n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps**-1.5)\n",
        "        \n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "leaning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(leaning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCebgo-CsiNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "859cdd67-ca5d-4b0a-ad41-cb5d5057bed0"
      },
      "source": [
        "'''checkpoint_path = \"./drive/My Drive/projects/transformer/ckpt/\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!!\")'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latest checkpoint restored!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKYuetistFrA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d8f005be-162e-450e-b040-b0f09fcd03d8"
      },
      "source": [
        "EPOCHS = 20\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"Start of epoch {}\".format(epoch+1))\n",
        "    start = time.time()\n",
        "    \n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    \n",
        "    for (batch, (enc_inputs, targets)) in enumerate(dataset):\n",
        "        dec_inputs = targets[:, :-1]\n",
        "        dec_outputs_real = targets[:, 1:]\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = transformer(enc_inputs, dec_inputs, True)\n",
        "            loss = loss_function(dec_outputs_real, predictions)\n",
        "        \n",
        "        gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "        \n",
        "        train_loss(loss)\n",
        "        train_accuracy(dec_outputs_real, predictions)\n",
        "        \n",
        "        if batch % 50 == 0:\n",
        "            print(\"Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}\".format(\n",
        "                epoch+1, batch, train_loss.result(), train_accuracy.result()))\n",
        "            \n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print(\"Saving checkpoint for epoch {} at {}\".format(epoch+1,\n",
        "                                                        ckpt_save_path))\n",
        "    print(\"Time taken for 1 epoch: {} secs\\n\".format(time.time() - start))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of epoch 1\n",
            "Epoch 1 Batch 0 Loss 0.9228 Accuracy 0.4679\n",
            "Epoch 1 Batch 50 Loss 0.9844 Accuracy 0.4933\n",
            "Epoch 1 Batch 100 Loss 0.9747 Accuracy 0.4952\n",
            "Epoch 1 Batch 150 Loss 0.9638 Accuracy 0.4955\n",
            "Epoch 1 Batch 200 Loss 0.9642 Accuracy 0.4975\n",
            "Epoch 1 Batch 250 Loss 0.9673 Accuracy 0.4970\n",
            "Epoch 1 Batch 300 Loss 0.9674 Accuracy 0.4969\n",
            "Epoch 1 Batch 350 Loss 0.9645 Accuracy 0.4971\n",
            "Epoch 1 Batch 400 Loss 0.9630 Accuracy 0.4970\n",
            "Epoch 1 Batch 450 Loss 0.9584 Accuracy 0.4965\n",
            "Epoch 1 Batch 500 Loss 0.9568 Accuracy 0.4965\n",
            "Epoch 1 Batch 550 Loss 0.9560 Accuracy 0.4968\n",
            "Epoch 1 Batch 600 Loss 0.9558 Accuracy 0.4970\n",
            "Epoch 1 Batch 650 Loss 0.9550 Accuracy 0.4971\n",
            "Epoch 1 Batch 700 Loss 0.9538 Accuracy 0.4973\n",
            "Epoch 1 Batch 750 Loss 0.9530 Accuracy 0.4975\n",
            "Epoch 1 Batch 800 Loss 0.9522 Accuracy 0.4976\n",
            "Epoch 1 Batch 850 Loss 0.9511 Accuracy 0.4976\n",
            "Epoch 1 Batch 900 Loss 0.9496 Accuracy 0.4977\n",
            "Epoch 1 Batch 950 Loss 0.9483 Accuracy 0.4976\n",
            "Epoch 1 Batch 1000 Loss 0.9469 Accuracy 0.4976\n",
            "Epoch 1 Batch 1050 Loss 0.9456 Accuracy 0.4973\n",
            "Epoch 1 Batch 1100 Loss 0.9450 Accuracy 0.4974\n",
            "Epoch 1 Batch 1150 Loss 0.9437 Accuracy 0.4976\n",
            "Epoch 1 Batch 1200 Loss 0.9427 Accuracy 0.4978\n",
            "Epoch 1 Batch 1250 Loss 0.9406 Accuracy 0.4982\n",
            "Epoch 1 Batch 1300 Loss 0.9380 Accuracy 0.4986\n",
            "Epoch 1 Batch 1350 Loss 0.9359 Accuracy 0.4991\n",
            "Epoch 1 Batch 1400 Loss 0.9335 Accuracy 0.4996\n",
            "Epoch 1 Batch 1450 Loss 0.9308 Accuracy 0.5002\n",
            "Epoch 1 Batch 1500 Loss 0.9286 Accuracy 0.5013\n",
            "Epoch 1 Batch 1550 Loss 0.9261 Accuracy 0.5022\n",
            "Epoch 1 Batch 1600 Loss 0.9243 Accuracy 0.5031\n",
            "Epoch 1 Batch 1650 Loss 0.9221 Accuracy 0.5038\n",
            "Epoch 1 Batch 1700 Loss 0.9196 Accuracy 0.5045\n",
            "Epoch 1 Batch 1750 Loss 0.9173 Accuracy 0.5051\n",
            "Epoch 1 Batch 1800 Loss 0.9151 Accuracy 0.5059\n",
            "Epoch 1 Batch 1850 Loss 0.9129 Accuracy 0.5067\n",
            "Epoch 1 Batch 1900 Loss 0.9107 Accuracy 0.5076\n",
            "Epoch 1 Batch 1950 Loss 0.9089 Accuracy 0.5084\n",
            "Epoch 1 Batch 2000 Loss 0.9069 Accuracy 0.5091\n",
            "Epoch 1 Batch 2050 Loss 0.9049 Accuracy 0.5096\n",
            "Epoch 1 Batch 2100 Loss 0.9026 Accuracy 0.5100\n",
            "Epoch 1 Batch 2150 Loss 0.8998 Accuracy 0.5103\n",
            "Epoch 1 Batch 2200 Loss 0.8971 Accuracy 0.5106\n",
            "Epoch 1 Batch 2250 Loss 0.8941 Accuracy 0.5107\n",
            "Epoch 1 Batch 2300 Loss 0.8912 Accuracy 0.5109\n",
            "Epoch 1 Batch 2350 Loss 0.8887 Accuracy 0.5111\n",
            "Epoch 1 Batch 2400 Loss 0.8858 Accuracy 0.5113\n",
            "Epoch 1 Batch 2450 Loss 0.8829 Accuracy 0.5116\n",
            "Epoch 1 Batch 2500 Loss 0.8801 Accuracy 0.5118\n",
            "Epoch 1 Batch 2550 Loss 0.8778 Accuracy 0.5122\n",
            "Epoch 1 Batch 2600 Loss 0.8754 Accuracy 0.5125\n",
            "Epoch 1 Batch 2650 Loss 0.8731 Accuracy 0.5129\n",
            "Epoch 1 Batch 2700 Loss 0.8710 Accuracy 0.5132\n",
            "Epoch 1 Batch 2750 Loss 0.8688 Accuracy 0.5135\n",
            "Epoch 1 Batch 2800 Loss 0.8665 Accuracy 0.5138\n",
            "Epoch 1 Batch 2850 Loss 0.8647 Accuracy 0.5139\n",
            "Epoch 1 Batch 2900 Loss 0.8629 Accuracy 0.5142\n",
            "Epoch 1 Batch 2950 Loss 0.8608 Accuracy 0.5146\n",
            "Epoch 1 Batch 3000 Loss 0.8590 Accuracy 0.5148\n",
            "Epoch 1 Batch 3050 Loss 0.8575 Accuracy 0.5150\n",
            "Epoch 1 Batch 3100 Loss 0.8559 Accuracy 0.5152\n",
            "Epoch 1 Batch 3150 Loss 0.8540 Accuracy 0.5154\n",
            "Epoch 1 Batch 3200 Loss 0.8523 Accuracy 0.5157\n",
            "Epoch 1 Batch 3250 Loss 0.8501 Accuracy 0.5159\n",
            "Epoch 1 Batch 3300 Loss 0.8482 Accuracy 0.5162\n",
            "Epoch 1 Batch 3350 Loss 0.8464 Accuracy 0.5164\n",
            "Epoch 1 Batch 3400 Loss 0.8445 Accuracy 0.5167\n",
            "Epoch 1 Batch 3450 Loss 0.8427 Accuracy 0.5169\n",
            "Epoch 1 Batch 3500 Loss 0.8414 Accuracy 0.5171\n",
            "Epoch 1 Batch 3550 Loss 0.8398 Accuracy 0.5174\n",
            "Epoch 1 Batch 3600 Loss 0.8383 Accuracy 0.5177\n",
            "Epoch 1 Batch 3650 Loss 0.8368 Accuracy 0.5180\n",
            "Epoch 1 Batch 3700 Loss 0.8354 Accuracy 0.5183\n",
            "Epoch 1 Batch 3750 Loss 0.8336 Accuracy 0.5186\n",
            "Epoch 1 Batch 3800 Loss 0.8323 Accuracy 0.5189\n",
            "Epoch 1 Batch 3850 Loss 0.8312 Accuracy 0.5192\n",
            "Epoch 1 Batch 3900 Loss 0.8298 Accuracy 0.5195\n",
            "Epoch 1 Batch 3950 Loss 0.8288 Accuracy 0.5198\n",
            "Epoch 1 Batch 4000 Loss 0.8275 Accuracy 0.5201\n",
            "Epoch 1 Batch 4050 Loss 0.8262 Accuracy 0.5204\n",
            "Epoch 1 Batch 4100 Loss 0.8252 Accuracy 0.5207\n",
            "Epoch 1 Batch 4150 Loss 0.8248 Accuracy 0.5207\n",
            "Epoch 1 Batch 4200 Loss 0.8249 Accuracy 0.5207\n",
            "Epoch 1 Batch 4250 Loss 0.8253 Accuracy 0.5207\n",
            "Epoch 1 Batch 4300 Loss 0.8263 Accuracy 0.5206\n",
            "Epoch 1 Batch 4350 Loss 0.8275 Accuracy 0.5205\n",
            "Epoch 1 Batch 4400 Loss 0.8286 Accuracy 0.5203\n",
            "Epoch 1 Batch 4450 Loss 0.8299 Accuracy 0.5201\n",
            "Epoch 1 Batch 4500 Loss 0.8310 Accuracy 0.5199\n",
            "Epoch 1 Batch 4550 Loss 0.8325 Accuracy 0.5197\n",
            "Epoch 1 Batch 4600 Loss 0.8340 Accuracy 0.5195\n",
            "Epoch 1 Batch 4650 Loss 0.8355 Accuracy 0.5193\n",
            "Epoch 1 Batch 4700 Loss 0.8368 Accuracy 0.5191\n",
            "Epoch 1 Batch 4750 Loss 0.8382 Accuracy 0.5189\n",
            "Epoch 1 Batch 4800 Loss 0.8392 Accuracy 0.5187\n",
            "Epoch 1 Batch 4850 Loss 0.8404 Accuracy 0.5185\n",
            "Epoch 1 Batch 4900 Loss 0.8415 Accuracy 0.5184\n",
            "Epoch 1 Batch 4950 Loss 0.8428 Accuracy 0.5182\n",
            "Epoch 1 Batch 5000 Loss 0.8442 Accuracy 0.5179\n",
            "Epoch 1 Batch 5050 Loss 0.8454 Accuracy 0.5177\n",
            "Epoch 1 Batch 5100 Loss 0.8466 Accuracy 0.5175\n",
            "Epoch 1 Batch 5150 Loss 0.8485 Accuracy 0.5172\n",
            "Epoch 1 Batch 5200 Loss 0.8499 Accuracy 0.5169\n",
            "Epoch 1 Batch 5250 Loss 0.8512 Accuracy 0.5165\n",
            "Epoch 1 Batch 5300 Loss 0.8524 Accuracy 0.5162\n",
            "Epoch 1 Batch 5350 Loss 0.8536 Accuracy 0.5160\n",
            "Epoch 1 Batch 5400 Loss 0.8546 Accuracy 0.5157\n",
            "Epoch 1 Batch 5450 Loss 0.8557 Accuracy 0.5154\n",
            "Epoch 1 Batch 5500 Loss 0.8566 Accuracy 0.5151\n",
            "Epoch 1 Batch 5550 Loss 0.8575 Accuracy 0.5149\n",
            "Epoch 1 Batch 5600 Loss 0.8586 Accuracy 0.5146\n",
            "Epoch 1 Batch 5650 Loss 0.8595 Accuracy 0.5144\n",
            "Epoch 1 Batch 5700 Loss 0.8607 Accuracy 0.5142\n",
            "Saving checkpoint for epoch 1 at ./drive/My Drive/projects/transformer/ckpt/ckpt-16\n",
            "Time taken for 1 epoch: 1800.9735236167908 secs\n",
            "\n",
            "Start of epoch 2\n",
            "Epoch 2 Batch 0 Loss 0.9292 Accuracy 0.4712\n",
            "Epoch 2 Batch 50 Loss 0.9868 Accuracy 0.4947\n",
            "Epoch 2 Batch 100 Loss 0.9669 Accuracy 0.4969\n",
            "Epoch 2 Batch 150 Loss 0.9595 Accuracy 0.4976\n",
            "Epoch 2 Batch 200 Loss 0.9629 Accuracy 0.4970\n",
            "Epoch 2 Batch 250 Loss 0.9643 Accuracy 0.4972\n",
            "Epoch 2 Batch 300 Loss 0.9630 Accuracy 0.4972\n",
            "Epoch 2 Batch 350 Loss 0.9605 Accuracy 0.4967\n",
            "Epoch 2 Batch 400 Loss 0.9598 Accuracy 0.4966\n",
            "Epoch 2 Batch 450 Loss 0.9556 Accuracy 0.4969\n",
            "Epoch 2 Batch 500 Loss 0.9531 Accuracy 0.4970\n",
            "Epoch 2 Batch 550 Loss 0.9539 Accuracy 0.4964\n",
            "Epoch 2 Batch 600 Loss 0.9507 Accuracy 0.4965\n",
            "Epoch 2 Batch 650 Loss 0.9499 Accuracy 0.4968\n",
            "Epoch 2 Batch 700 Loss 0.9490 Accuracy 0.4970\n",
            "Epoch 2 Batch 750 Loss 0.9469 Accuracy 0.4972\n",
            "Epoch 2 Batch 800 Loss 0.9450 Accuracy 0.4976\n",
            "Epoch 2 Batch 850 Loss 0.9439 Accuracy 0.4975\n",
            "Epoch 2 Batch 900 Loss 0.9436 Accuracy 0.4975\n",
            "Epoch 2 Batch 950 Loss 0.9427 Accuracy 0.4974\n",
            "Epoch 2 Batch 1000 Loss 0.9422 Accuracy 0.4975\n",
            "Epoch 2 Batch 1050 Loss 0.9420 Accuracy 0.4978\n",
            "Epoch 2 Batch 1100 Loss 0.9400 Accuracy 0.4982\n",
            "Epoch 2 Batch 1150 Loss 0.9392 Accuracy 0.4985\n",
            "Epoch 2 Batch 1200 Loss 0.9368 Accuracy 0.4988\n",
            "Epoch 2 Batch 1250 Loss 0.9349 Accuracy 0.4990\n",
            "Epoch 2 Batch 1300 Loss 0.9327 Accuracy 0.4998\n",
            "Epoch 2 Batch 1350 Loss 0.9303 Accuracy 0.5005\n",
            "Epoch 2 Batch 1400 Loss 0.9280 Accuracy 0.5011\n",
            "Epoch 2 Batch 1450 Loss 0.9252 Accuracy 0.5015\n",
            "Epoch 2 Batch 1500 Loss 0.9227 Accuracy 0.5025\n",
            "Epoch 2 Batch 1550 Loss 0.9203 Accuracy 0.5034\n",
            "Epoch 2 Batch 1600 Loss 0.9175 Accuracy 0.5042\n",
            "Epoch 2 Batch 1650 Loss 0.9150 Accuracy 0.5049\n",
            "Epoch 2 Batch 1700 Loss 0.9127 Accuracy 0.5058\n",
            "Epoch 2 Batch 1750 Loss 0.9101 Accuracy 0.5068\n",
            "Epoch 2 Batch 1800 Loss 0.9079 Accuracy 0.5076\n",
            "Epoch 2 Batch 1850 Loss 0.9058 Accuracy 0.5083\n",
            "Epoch 2 Batch 1900 Loss 0.9036 Accuracy 0.5090\n",
            "Epoch 2 Batch 1950 Loss 0.9017 Accuracy 0.5097\n",
            "Epoch 2 Batch 2000 Loss 0.8995 Accuracy 0.5103\n",
            "Epoch 2 Batch 2050 Loss 0.8979 Accuracy 0.5108\n",
            "Epoch 2 Batch 2100 Loss 0.8959 Accuracy 0.5112\n",
            "Epoch 2 Batch 2150 Loss 0.8932 Accuracy 0.5115\n",
            "Epoch 2 Batch 2200 Loss 0.8901 Accuracy 0.5117\n",
            "Epoch 2 Batch 2250 Loss 0.8873 Accuracy 0.5118\n",
            "Epoch 2 Batch 2300 Loss 0.8848 Accuracy 0.5120\n",
            "Epoch 2 Batch 2350 Loss 0.8820 Accuracy 0.5122\n",
            "Epoch 2 Batch 2400 Loss 0.8789 Accuracy 0.5123\n",
            "Epoch 2 Batch 2450 Loss 0.8761 Accuracy 0.5125\n",
            "Epoch 2 Batch 2500 Loss 0.8737 Accuracy 0.5128\n",
            "Epoch 2 Batch 2550 Loss 0.8710 Accuracy 0.5131\n",
            "Epoch 2 Batch 2600 Loss 0.8684 Accuracy 0.5134\n",
            "Epoch 2 Batch 2650 Loss 0.8659 Accuracy 0.5138\n",
            "Epoch 2 Batch 2700 Loss 0.8641 Accuracy 0.5141\n",
            "Epoch 2 Batch 2750 Loss 0.8620 Accuracy 0.5145\n",
            "Epoch 2 Batch 2800 Loss 0.8601 Accuracy 0.5147\n",
            "Epoch 2 Batch 2850 Loss 0.8580 Accuracy 0.5150\n",
            "Epoch 2 Batch 2900 Loss 0.8558 Accuracy 0.5153\n",
            "Epoch 2 Batch 2950 Loss 0.8541 Accuracy 0.5155\n",
            "Epoch 2 Batch 3000 Loss 0.8521 Accuracy 0.5158\n",
            "Epoch 2 Batch 3050 Loss 0.8503 Accuracy 0.5160\n",
            "Epoch 2 Batch 3100 Loss 0.8485 Accuracy 0.5163\n",
            "Epoch 2 Batch 3150 Loss 0.8470 Accuracy 0.5165\n",
            "Epoch 2 Batch 3200 Loss 0.8452 Accuracy 0.5167\n",
            "Epoch 2 Batch 3250 Loss 0.8437 Accuracy 0.5170\n",
            "Epoch 2 Batch 3300 Loss 0.8417 Accuracy 0.5173\n",
            "Epoch 2 Batch 3350 Loss 0.8399 Accuracy 0.5175\n",
            "Epoch 2 Batch 3400 Loss 0.8383 Accuracy 0.5177\n",
            "Epoch 2 Batch 3450 Loss 0.8363 Accuracy 0.5180\n",
            "Epoch 2 Batch 3500 Loss 0.8346 Accuracy 0.5183\n",
            "Epoch 2 Batch 3550 Loss 0.8328 Accuracy 0.5186\n",
            "Epoch 2 Batch 3600 Loss 0.8309 Accuracy 0.5188\n",
            "Epoch 2 Batch 3650 Loss 0.8295 Accuracy 0.5191\n",
            "Epoch 2 Batch 3700 Loss 0.8281 Accuracy 0.5195\n",
            "Epoch 2 Batch 3750 Loss 0.8267 Accuracy 0.5198\n",
            "Epoch 2 Batch 3800 Loss 0.8257 Accuracy 0.5200\n",
            "Epoch 2 Batch 3850 Loss 0.8244 Accuracy 0.5203\n",
            "Epoch 2 Batch 3900 Loss 0.8232 Accuracy 0.5207\n",
            "Epoch 2 Batch 3950 Loss 0.8219 Accuracy 0.5209\n",
            "Epoch 2 Batch 4000 Loss 0.8208 Accuracy 0.5213\n",
            "Epoch 2 Batch 4050 Loss 0.8197 Accuracy 0.5216\n",
            "Epoch 2 Batch 4100 Loss 0.8189 Accuracy 0.5218\n",
            "Epoch 2 Batch 4150 Loss 0.8184 Accuracy 0.5219\n",
            "Epoch 2 Batch 4200 Loss 0.8187 Accuracy 0.5219\n",
            "Epoch 2 Batch 4250 Loss 0.8190 Accuracy 0.5218\n",
            "Epoch 2 Batch 4300 Loss 0.8199 Accuracy 0.5217\n",
            "Epoch 2 Batch 4350 Loss 0.8208 Accuracy 0.5216\n",
            "Epoch 2 Batch 4400 Loss 0.8218 Accuracy 0.5214\n",
            "Epoch 2 Batch 4450 Loss 0.8229 Accuracy 0.5212\n",
            "Epoch 2 Batch 4500 Loss 0.8242 Accuracy 0.5210\n",
            "Epoch 2 Batch 4550 Loss 0.8258 Accuracy 0.5208\n",
            "Epoch 2 Batch 4600 Loss 0.8273 Accuracy 0.5206\n",
            "Epoch 2 Batch 4650 Loss 0.8287 Accuracy 0.5204\n",
            "Epoch 2 Batch 4700 Loss 0.8300 Accuracy 0.5202\n",
            "Epoch 2 Batch 4750 Loss 0.8313 Accuracy 0.5200\n",
            "Epoch 2 Batch 4800 Loss 0.8326 Accuracy 0.5198\n",
            "Epoch 2 Batch 4850 Loss 0.8338 Accuracy 0.5196\n",
            "Epoch 2 Batch 4900 Loss 0.8352 Accuracy 0.5194\n",
            "Epoch 2 Batch 4950 Loss 0.8365 Accuracy 0.5192\n",
            "Epoch 2 Batch 5000 Loss 0.8379 Accuracy 0.5190\n",
            "Epoch 2 Batch 5050 Loss 0.8396 Accuracy 0.5188\n",
            "Epoch 2 Batch 5100 Loss 0.8408 Accuracy 0.5185\n",
            "Epoch 2 Batch 5150 Loss 0.8421 Accuracy 0.5182\n",
            "Epoch 2 Batch 5200 Loss 0.8434 Accuracy 0.5179\n",
            "Epoch 2 Batch 5250 Loss 0.8445 Accuracy 0.5177\n",
            "Epoch 2 Batch 5300 Loss 0.8455 Accuracy 0.5174\n",
            "Epoch 2 Batch 5350 Loss 0.8465 Accuracy 0.5170\n",
            "Epoch 2 Batch 5400 Loss 0.8478 Accuracy 0.5168\n",
            "Epoch 2 Batch 5450 Loss 0.8489 Accuracy 0.5166\n",
            "Epoch 2 Batch 5500 Loss 0.8500 Accuracy 0.5163\n",
            "Epoch 2 Batch 5550 Loss 0.8510 Accuracy 0.5160\n",
            "Epoch 2 Batch 5600 Loss 0.8523 Accuracy 0.5158\n",
            "Epoch 2 Batch 5650 Loss 0.8533 Accuracy 0.5155\n",
            "Epoch 2 Batch 5700 Loss 0.8542 Accuracy 0.5152\n",
            "Saving checkpoint for epoch 2 at ./drive/My Drive/projects/transformer/ckpt/ckpt-17\n",
            "Time taken for 1 epoch: 1444.3444108963013 secs\n",
            "\n",
            "Start of epoch 3\n",
            "Epoch 3 Batch 0 Loss 0.9130 Accuracy 0.4852\n",
            "Epoch 3 Batch 50 Loss 0.9601 Accuracy 0.4958\n",
            "Epoch 3 Batch 100 Loss 0.9415 Accuracy 0.4968\n",
            "Epoch 3 Batch 150 Loss 0.9502 Accuracy 0.4992\n",
            "Epoch 3 Batch 200 Loss 0.9521 Accuracy 0.4985\n",
            "Epoch 3 Batch 250 Loss 0.9495 Accuracy 0.4992\n",
            "Epoch 3 Batch 300 Loss 0.9513 Accuracy 0.4988\n",
            "Epoch 3 Batch 350 Loss 0.9501 Accuracy 0.4985\n",
            "Epoch 3 Batch 400 Loss 0.9469 Accuracy 0.4989\n",
            "Epoch 3 Batch 450 Loss 0.9454 Accuracy 0.4985\n",
            "Epoch 3 Batch 500 Loss 0.9442 Accuracy 0.4974\n",
            "Epoch 3 Batch 550 Loss 0.9425 Accuracy 0.4976\n",
            "Epoch 3 Batch 600 Loss 0.9431 Accuracy 0.4978\n",
            "Epoch 3 Batch 650 Loss 0.9418 Accuracy 0.4980\n",
            "Epoch 3 Batch 700 Loss 0.9407 Accuracy 0.4986\n",
            "Epoch 3 Batch 750 Loss 0.9402 Accuracy 0.4988\n",
            "Epoch 3 Batch 800 Loss 0.9392 Accuracy 0.4993\n",
            "Epoch 3 Batch 850 Loss 0.9380 Accuracy 0.4995\n",
            "Epoch 3 Batch 900 Loss 0.9365 Accuracy 0.4997\n",
            "Epoch 3 Batch 950 Loss 0.9351 Accuracy 0.4995\n",
            "Epoch 3 Batch 1000 Loss 0.9331 Accuracy 0.4996\n",
            "Epoch 3 Batch 1050 Loss 0.9319 Accuracy 0.4998\n",
            "Epoch 3 Batch 1100 Loss 0.9305 Accuracy 0.4999\n",
            "Epoch 3 Batch 1150 Loss 0.9286 Accuracy 0.5003\n",
            "Epoch 3 Batch 1200 Loss 0.9278 Accuracy 0.5003\n",
            "Epoch 3 Batch 1250 Loss 0.9265 Accuracy 0.5007\n",
            "Epoch 3 Batch 1300 Loss 0.9247 Accuracy 0.5010\n",
            "Epoch 3 Batch 1350 Loss 0.9225 Accuracy 0.5016\n",
            "Epoch 3 Batch 1400 Loss 0.9205 Accuracy 0.5023\n",
            "Epoch 3 Batch 1450 Loss 0.9185 Accuracy 0.5031\n",
            "Epoch 3 Batch 1500 Loss 0.9154 Accuracy 0.5040\n",
            "Epoch 3 Batch 1550 Loss 0.9134 Accuracy 0.5046\n",
            "Epoch 3 Batch 1600 Loss 0.9107 Accuracy 0.5055\n",
            "Epoch 3 Batch 1650 Loss 0.9083 Accuracy 0.5064\n",
            "Epoch 3 Batch 1700 Loss 0.9064 Accuracy 0.5070\n",
            "Epoch 3 Batch 1750 Loss 0.9040 Accuracy 0.5079\n",
            "Epoch 3 Batch 1800 Loss 0.9018 Accuracy 0.5087\n",
            "Epoch 3 Batch 1850 Loss 0.8993 Accuracy 0.5094\n",
            "Epoch 3 Batch 1900 Loss 0.8973 Accuracy 0.5102\n",
            "Epoch 3 Batch 1950 Loss 0.8957 Accuracy 0.5108\n",
            "Epoch 3 Batch 2000 Loss 0.8937 Accuracy 0.5114\n",
            "Epoch 3 Batch 2050 Loss 0.8920 Accuracy 0.5119\n",
            "Epoch 3 Batch 2100 Loss 0.8895 Accuracy 0.5124\n",
            "Epoch 3 Batch 2150 Loss 0.8878 Accuracy 0.5126\n",
            "Epoch 3 Batch 2200 Loss 0.8844 Accuracy 0.5127\n",
            "Epoch 3 Batch 2250 Loss 0.8817 Accuracy 0.5129\n",
            "Epoch 3 Batch 2300 Loss 0.8789 Accuracy 0.5131\n",
            "Epoch 3 Batch 2350 Loss 0.8765 Accuracy 0.5134\n",
            "Epoch 3 Batch 2400 Loss 0.8738 Accuracy 0.5136\n",
            "Epoch 3 Batch 2450 Loss 0.8711 Accuracy 0.5139\n",
            "Epoch 3 Batch 2500 Loss 0.8679 Accuracy 0.5141\n",
            "Epoch 3 Batch 2550 Loss 0.8655 Accuracy 0.5144\n",
            "Epoch 3 Batch 2600 Loss 0.8627 Accuracy 0.5147\n",
            "Epoch 3 Batch 2650 Loss 0.8602 Accuracy 0.5149\n",
            "Epoch 3 Batch 2700 Loss 0.8576 Accuracy 0.5153\n",
            "Epoch 3 Batch 2750 Loss 0.8551 Accuracy 0.5156\n",
            "Epoch 3 Batch 2800 Loss 0.8534 Accuracy 0.5158\n",
            "Epoch 3 Batch 2850 Loss 0.8518 Accuracy 0.5161\n",
            "Epoch 3 Batch 2900 Loss 0.8498 Accuracy 0.5164\n",
            "Epoch 3 Batch 2950 Loss 0.8481 Accuracy 0.5166\n",
            "Epoch 3 Batch 3000 Loss 0.8464 Accuracy 0.5168\n",
            "Epoch 3 Batch 3050 Loss 0.8445 Accuracy 0.5171\n",
            "Epoch 3 Batch 3100 Loss 0.8429 Accuracy 0.5174\n",
            "Epoch 3 Batch 3150 Loss 0.8409 Accuracy 0.5176\n",
            "Epoch 3 Batch 3200 Loss 0.8391 Accuracy 0.5178\n",
            "Epoch 3 Batch 3250 Loss 0.8373 Accuracy 0.5179\n",
            "Epoch 3 Batch 3300 Loss 0.8352 Accuracy 0.5181\n",
            "Epoch 3 Batch 3350 Loss 0.8334 Accuracy 0.5184\n",
            "Epoch 3 Batch 3400 Loss 0.8316 Accuracy 0.5187\n",
            "Epoch 3 Batch 3450 Loss 0.8301 Accuracy 0.5189\n",
            "Epoch 3 Batch 3500 Loss 0.8284 Accuracy 0.5192\n",
            "Epoch 3 Batch 3550 Loss 0.8267 Accuracy 0.5194\n",
            "Epoch 3 Batch 3600 Loss 0.8250 Accuracy 0.5197\n",
            "Epoch 3 Batch 3650 Loss 0.8236 Accuracy 0.5200\n",
            "Epoch 3 Batch 3700 Loss 0.8223 Accuracy 0.5203\n",
            "Epoch 3 Batch 3750 Loss 0.8207 Accuracy 0.5206\n",
            "Epoch 3 Batch 3800 Loss 0.8194 Accuracy 0.5209\n",
            "Epoch 3 Batch 3850 Loss 0.8181 Accuracy 0.5213\n",
            "Epoch 3 Batch 3900 Loss 0.8168 Accuracy 0.5217\n",
            "Epoch 3 Batch 3950 Loss 0.8156 Accuracy 0.5220\n",
            "Epoch 3 Batch 4000 Loss 0.8144 Accuracy 0.5223\n",
            "Epoch 3 Batch 4050 Loss 0.8133 Accuracy 0.5225\n",
            "Epoch 3 Batch 4100 Loss 0.8120 Accuracy 0.5227\n",
            "Epoch 3 Batch 4150 Loss 0.8118 Accuracy 0.5228\n",
            "Epoch 3 Batch 4200 Loss 0.8121 Accuracy 0.5228\n",
            "Epoch 3 Batch 4250 Loss 0.8125 Accuracy 0.5228\n",
            "Epoch 3 Batch 4300 Loss 0.8132 Accuracy 0.5227\n",
            "Epoch 3 Batch 4350 Loss 0.8142 Accuracy 0.5225\n",
            "Epoch 3 Batch 4400 Loss 0.8154 Accuracy 0.5224\n",
            "Epoch 3 Batch 4450 Loss 0.8165 Accuracy 0.5222\n",
            "Epoch 3 Batch 4500 Loss 0.8179 Accuracy 0.5220\n",
            "Epoch 3 Batch 4550 Loss 0.8194 Accuracy 0.5218\n",
            "Epoch 3 Batch 4600 Loss 0.8210 Accuracy 0.5216\n",
            "Epoch 3 Batch 4650 Loss 0.8223 Accuracy 0.5214\n",
            "Epoch 3 Batch 4700 Loss 0.8237 Accuracy 0.5212\n",
            "Epoch 3 Batch 4750 Loss 0.8248 Accuracy 0.5211\n",
            "Epoch 3 Batch 4800 Loss 0.8261 Accuracy 0.5209\n",
            "Epoch 3 Batch 4850 Loss 0.8275 Accuracy 0.5207\n",
            "Epoch 3 Batch 4900 Loss 0.8287 Accuracy 0.5205\n",
            "Epoch 3 Batch 4950 Loss 0.8301 Accuracy 0.5203\n",
            "Epoch 3 Batch 5000 Loss 0.8315 Accuracy 0.5200\n",
            "Epoch 3 Batch 5050 Loss 0.8327 Accuracy 0.5198\n",
            "Epoch 3 Batch 5100 Loss 0.8338 Accuracy 0.5196\n",
            "Epoch 3 Batch 5150 Loss 0.8354 Accuracy 0.5194\n",
            "Epoch 3 Batch 5200 Loss 0.8367 Accuracy 0.5191\n",
            "Epoch 3 Batch 5250 Loss 0.8379 Accuracy 0.5188\n",
            "Epoch 3 Batch 5300 Loss 0.8391 Accuracy 0.5185\n",
            "Epoch 3 Batch 5350 Loss 0.8404 Accuracy 0.5181\n",
            "Epoch 3 Batch 5400 Loss 0.8416 Accuracy 0.5178\n",
            "Epoch 3 Batch 5450 Loss 0.8428 Accuracy 0.5175\n",
            "Epoch 3 Batch 5500 Loss 0.8439 Accuracy 0.5173\n",
            "Epoch 3 Batch 5550 Loss 0.8450 Accuracy 0.5170\n",
            "Epoch 3 Batch 5600 Loss 0.8459 Accuracy 0.5167\n",
            "Epoch 3 Batch 5650 Loss 0.8468 Accuracy 0.5165\n",
            "Epoch 3 Batch 5700 Loss 0.8479 Accuracy 0.5163\n",
            "Saving checkpoint for epoch 3 at ./drive/My Drive/projects/transformer/ckpt/ckpt-18\n",
            "Time taken for 1 epoch: 1448.6473886966705 secs\n",
            "\n",
            "Start of epoch 4\n",
            "Epoch 4 Batch 0 Loss 0.9622 Accuracy 0.5214\n",
            "Epoch 4 Batch 50 Loss 0.9688 Accuracy 0.4979\n",
            "Epoch 4 Batch 100 Loss 0.9469 Accuracy 0.4984\n",
            "Epoch 4 Batch 150 Loss 0.9444 Accuracy 0.4978\n",
            "Epoch 4 Batch 200 Loss 0.9405 Accuracy 0.4983\n",
            "Epoch 4 Batch 250 Loss 0.9380 Accuracy 0.4986\n",
            "Epoch 4 Batch 300 Loss 0.9416 Accuracy 0.4978\n",
            "Epoch 4 Batch 350 Loss 0.9413 Accuracy 0.4993\n",
            "Epoch 4 Batch 400 Loss 0.9407 Accuracy 0.4987\n",
            "Epoch 4 Batch 450 Loss 0.9397 Accuracy 0.4990\n",
            "Epoch 4 Batch 500 Loss 0.9397 Accuracy 0.4990\n",
            "Epoch 4 Batch 550 Loss 0.9372 Accuracy 0.4988\n",
            "Epoch 4 Batch 600 Loss 0.9361 Accuracy 0.4988\n",
            "Epoch 4 Batch 650 Loss 0.9359 Accuracy 0.4989\n",
            "Epoch 4 Batch 700 Loss 0.9351 Accuracy 0.4992\n",
            "Epoch 4 Batch 750 Loss 0.9344 Accuracy 0.4995\n",
            "Epoch 4 Batch 800 Loss 0.9314 Accuracy 0.4994\n",
            "Epoch 4 Batch 850 Loss 0.9314 Accuracy 0.4999\n",
            "Epoch 4 Batch 900 Loss 0.9313 Accuracy 0.5000\n",
            "Epoch 4 Batch 950 Loss 0.9306 Accuracy 0.4999\n",
            "Epoch 4 Batch 1000 Loss 0.9287 Accuracy 0.5002\n",
            "Epoch 4 Batch 1050 Loss 0.9278 Accuracy 0.5005\n",
            "Epoch 4 Batch 1100 Loss 0.9259 Accuracy 0.5008\n",
            "Epoch 4 Batch 1150 Loss 0.9249 Accuracy 0.5010\n",
            "Epoch 4 Batch 1200 Loss 0.9231 Accuracy 0.5013\n",
            "Epoch 4 Batch 1250 Loss 0.9219 Accuracy 0.5013\n",
            "Epoch 4 Batch 1300 Loss 0.9195 Accuracy 0.5018\n",
            "Epoch 4 Batch 1350 Loss 0.9170 Accuracy 0.5024\n",
            "Epoch 4 Batch 1400 Loss 0.9150 Accuracy 0.5031\n",
            "Epoch 4 Batch 1450 Loss 0.9123 Accuracy 0.5040\n",
            "Epoch 4 Batch 1500 Loss 0.9101 Accuracy 0.5049\n",
            "Epoch 4 Batch 1550 Loss 0.9078 Accuracy 0.5058\n",
            "Epoch 4 Batch 1600 Loss 0.9047 Accuracy 0.5066\n",
            "Epoch 4 Batch 1650 Loss 0.9022 Accuracy 0.5074\n",
            "Epoch 4 Batch 1700 Loss 0.9001 Accuracy 0.5083\n",
            "Epoch 4 Batch 1750 Loss 0.8985 Accuracy 0.5090\n",
            "Epoch 4 Batch 1800 Loss 0.8961 Accuracy 0.5098\n",
            "Epoch 4 Batch 1850 Loss 0.8934 Accuracy 0.5105\n",
            "Epoch 4 Batch 1900 Loss 0.8913 Accuracy 0.5113\n",
            "Epoch 4 Batch 1950 Loss 0.8894 Accuracy 0.5119\n",
            "Epoch 4 Batch 2000 Loss 0.8870 Accuracy 0.5125\n",
            "Epoch 4 Batch 2050 Loss 0.8851 Accuracy 0.5130\n",
            "Epoch 4 Batch 2100 Loss 0.8830 Accuracy 0.5132\n",
            "Epoch 4 Batch 2150 Loss 0.8802 Accuracy 0.5136\n",
            "Epoch 4 Batch 2200 Loss 0.8770 Accuracy 0.5138\n",
            "Epoch 4 Batch 2250 Loss 0.8738 Accuracy 0.5141\n",
            "Epoch 4 Batch 2300 Loss 0.8709 Accuracy 0.5142\n",
            "Epoch 4 Batch 2350 Loss 0.8686 Accuracy 0.5144\n",
            "Epoch 4 Batch 2400 Loss 0.8662 Accuracy 0.5148\n",
            "Epoch 4 Batch 2450 Loss 0.8631 Accuracy 0.5150\n",
            "Epoch 4 Batch 2500 Loss 0.8607 Accuracy 0.5152\n",
            "Epoch 4 Batch 2550 Loss 0.8583 Accuracy 0.5155\n",
            "Epoch 4 Batch 2600 Loss 0.8558 Accuracy 0.5157\n",
            "Epoch 4 Batch 2650 Loss 0.8538 Accuracy 0.5161\n",
            "Epoch 4 Batch 2700 Loss 0.8517 Accuracy 0.5164\n",
            "Epoch 4 Batch 2750 Loss 0.8497 Accuracy 0.5166\n",
            "Epoch 4 Batch 2800 Loss 0.8474 Accuracy 0.5168\n",
            "Epoch 4 Batch 2850 Loss 0.8455 Accuracy 0.5171\n",
            "Epoch 4 Batch 2900 Loss 0.8438 Accuracy 0.5174\n",
            "Epoch 4 Batch 2950 Loss 0.8422 Accuracy 0.5176\n",
            "Epoch 4 Batch 3000 Loss 0.8403 Accuracy 0.5178\n",
            "Epoch 4 Batch 3050 Loss 0.8385 Accuracy 0.5180\n",
            "Epoch 4 Batch 3100 Loss 0.8369 Accuracy 0.5184\n",
            "Epoch 4 Batch 3150 Loss 0.8351 Accuracy 0.5185\n",
            "Epoch 4 Batch 3200 Loss 0.8334 Accuracy 0.5187\n",
            "Epoch 4 Batch 3250 Loss 0.8319 Accuracy 0.5189\n",
            "Epoch 4 Batch 3300 Loss 0.8298 Accuracy 0.5191\n",
            "Epoch 4 Batch 3350 Loss 0.8280 Accuracy 0.5195\n",
            "Epoch 4 Batch 3400 Loss 0.8262 Accuracy 0.5198\n",
            "Epoch 4 Batch 3450 Loss 0.8246 Accuracy 0.5200\n",
            "Epoch 4 Batch 3500 Loss 0.8232 Accuracy 0.5203\n",
            "Epoch 4 Batch 3550 Loss 0.8216 Accuracy 0.5206\n",
            "Epoch 4 Batch 3600 Loss 0.8197 Accuracy 0.5209\n",
            "Epoch 4 Batch 3650 Loss 0.8182 Accuracy 0.5213\n",
            "Epoch 4 Batch 3700 Loss 0.8165 Accuracy 0.5215\n",
            "Epoch 4 Batch 3750 Loss 0.8151 Accuracy 0.5218\n",
            "Epoch 4 Batch 3800 Loss 0.8138 Accuracy 0.5220\n",
            "Epoch 4 Batch 3850 Loss 0.8125 Accuracy 0.5224\n",
            "Epoch 4 Batch 3900 Loss 0.8113 Accuracy 0.5226\n",
            "Epoch 4 Batch 3950 Loss 0.8102 Accuracy 0.5229\n",
            "Epoch 4 Batch 4000 Loss 0.8089 Accuracy 0.5232\n",
            "Epoch 4 Batch 4050 Loss 0.8079 Accuracy 0.5235\n",
            "Epoch 4 Batch 4100 Loss 0.8070 Accuracy 0.5237\n",
            "Epoch 4 Batch 4150 Loss 0.8067 Accuracy 0.5239\n",
            "Epoch 4 Batch 4200 Loss 0.8071 Accuracy 0.5239\n",
            "Epoch 4 Batch 4250 Loss 0.8074 Accuracy 0.5238\n",
            "Epoch 4 Batch 4300 Loss 0.8081 Accuracy 0.5237\n",
            "Epoch 4 Batch 4350 Loss 0.8092 Accuracy 0.5235\n",
            "Epoch 4 Batch 4400 Loss 0.8102 Accuracy 0.5233\n",
            "Epoch 4 Batch 4450 Loss 0.8115 Accuracy 0.5232\n",
            "Epoch 4 Batch 4500 Loss 0.8127 Accuracy 0.5230\n",
            "Epoch 4 Batch 4550 Loss 0.8140 Accuracy 0.5228\n",
            "Epoch 4 Batch 4600 Loss 0.8154 Accuracy 0.5226\n",
            "Epoch 4 Batch 4650 Loss 0.8165 Accuracy 0.5224\n",
            "Epoch 4 Batch 4700 Loss 0.8181 Accuracy 0.5222\n",
            "Epoch 4 Batch 4750 Loss 0.8193 Accuracy 0.5220\n",
            "Epoch 4 Batch 4800 Loss 0.8206 Accuracy 0.5218\n",
            "Epoch 4 Batch 4850 Loss 0.8218 Accuracy 0.5216\n",
            "Epoch 4 Batch 4900 Loss 0.8233 Accuracy 0.5215\n",
            "Epoch 4 Batch 4950 Loss 0.8248 Accuracy 0.5213\n",
            "Epoch 4 Batch 5000 Loss 0.8261 Accuracy 0.5211\n",
            "Epoch 4 Batch 5050 Loss 0.8275 Accuracy 0.5209\n",
            "Epoch 4 Batch 5100 Loss 0.8286 Accuracy 0.5206\n",
            "Epoch 4 Batch 5150 Loss 0.8299 Accuracy 0.5203\n",
            "Epoch 4 Batch 5200 Loss 0.8311 Accuracy 0.5200\n",
            "Epoch 4 Batch 5250 Loss 0.8324 Accuracy 0.5198\n",
            "Epoch 4 Batch 5300 Loss 0.8337 Accuracy 0.5195\n",
            "Epoch 4 Batch 5350 Loss 0.8351 Accuracy 0.5192\n",
            "Epoch 4 Batch 5400 Loss 0.8362 Accuracy 0.5188\n",
            "Epoch 4 Batch 5450 Loss 0.8375 Accuracy 0.5185\n",
            "Epoch 4 Batch 5500 Loss 0.8386 Accuracy 0.5182\n",
            "Epoch 4 Batch 5550 Loss 0.8396 Accuracy 0.5180\n",
            "Epoch 4 Batch 5600 Loss 0.8406 Accuracy 0.5178\n",
            "Epoch 4 Batch 5650 Loss 0.8416 Accuracy 0.5175\n",
            "Epoch 4 Batch 5700 Loss 0.8424 Accuracy 0.5173\n",
            "Saving checkpoint for epoch 4 at ./drive/My Drive/projects/transformer/ckpt/ckpt-19\n",
            "Time taken for 1 epoch: 1453.7539238929749 secs\n",
            "\n",
            "Start of epoch 5\n",
            "Epoch 5 Batch 0 Loss 0.9365 Accuracy 0.5214\n",
            "Epoch 5 Batch 50 Loss 0.9213 Accuracy 0.5012\n",
            "Epoch 5 Batch 100 Loss 0.9278 Accuracy 0.4977\n",
            "Epoch 5 Batch 150 Loss 0.9323 Accuracy 0.4995\n",
            "Epoch 5 Batch 200 Loss 0.9382 Accuracy 0.5001\n",
            "Epoch 5 Batch 250 Loss 0.9369 Accuracy 0.5008\n",
            "Epoch 5 Batch 300 Loss 0.9367 Accuracy 0.5000\n",
            "Epoch 5 Batch 350 Loss 0.9392 Accuracy 0.4997\n",
            "Epoch 5 Batch 400 Loss 0.9373 Accuracy 0.5001\n",
            "Epoch 5 Batch 450 Loss 0.9353 Accuracy 0.5004\n",
            "Epoch 5 Batch 500 Loss 0.9334 Accuracy 0.4997\n",
            "Epoch 5 Batch 550 Loss 0.9304 Accuracy 0.4996\n",
            "Epoch 5 Batch 600 Loss 0.9301 Accuracy 0.4996\n",
            "Epoch 5 Batch 650 Loss 0.9297 Accuracy 0.4998\n",
            "Epoch 5 Batch 700 Loss 0.9284 Accuracy 0.5002\n",
            "Epoch 5 Batch 750 Loss 0.9296 Accuracy 0.5007\n",
            "Epoch 5 Batch 800 Loss 0.9298 Accuracy 0.5009\n",
            "Epoch 5 Batch 850 Loss 0.9294 Accuracy 0.5012\n",
            "Epoch 5 Batch 900 Loss 0.9276 Accuracy 0.5012\n",
            "Epoch 5 Batch 950 Loss 0.9259 Accuracy 0.5013\n",
            "Epoch 5 Batch 1000 Loss 0.9246 Accuracy 0.5014\n",
            "Epoch 5 Batch 1050 Loss 0.9233 Accuracy 0.5015\n",
            "Epoch 5 Batch 1100 Loss 0.9222 Accuracy 0.5018\n",
            "Epoch 5 Batch 1150 Loss 0.9205 Accuracy 0.5019\n",
            "Epoch 5 Batch 1200 Loss 0.9189 Accuracy 0.5018\n",
            "Epoch 5 Batch 1250 Loss 0.9169 Accuracy 0.5023\n",
            "Epoch 5 Batch 1300 Loss 0.9144 Accuracy 0.5028\n",
            "Epoch 5 Batch 1350 Loss 0.9116 Accuracy 0.5034\n",
            "Epoch 5 Batch 1400 Loss 0.9094 Accuracy 0.5040\n",
            "Epoch 5 Batch 1450 Loss 0.9074 Accuracy 0.5046\n",
            "Epoch 5 Batch 1500 Loss 0.9050 Accuracy 0.5054\n",
            "Epoch 5 Batch 1550 Loss 0.9023 Accuracy 0.5064\n",
            "Epoch 5 Batch 1600 Loss 0.9002 Accuracy 0.5072\n",
            "Epoch 5 Batch 1650 Loss 0.8978 Accuracy 0.5080\n",
            "Epoch 5 Batch 1700 Loss 0.8953 Accuracy 0.5088\n",
            "Epoch 5 Batch 1750 Loss 0.8933 Accuracy 0.5098\n",
            "Epoch 5 Batch 1800 Loss 0.8911 Accuracy 0.5107\n",
            "Epoch 5 Batch 1850 Loss 0.8892 Accuracy 0.5114\n",
            "Epoch 5 Batch 1900 Loss 0.8873 Accuracy 0.5122\n",
            "Epoch 5 Batch 1950 Loss 0.8855 Accuracy 0.5129\n",
            "Epoch 5 Batch 2000 Loss 0.8835 Accuracy 0.5135\n",
            "Epoch 5 Batch 2050 Loss 0.8809 Accuracy 0.5140\n",
            "Epoch 5 Batch 2100 Loss 0.8788 Accuracy 0.5144\n",
            "Epoch 5 Batch 2150 Loss 0.8759 Accuracy 0.5146\n",
            "Epoch 5 Batch 2200 Loss 0.8729 Accuracy 0.5148\n",
            "Epoch 5 Batch 2250 Loss 0.8700 Accuracy 0.5151\n",
            "Epoch 5 Batch 2300 Loss 0.8673 Accuracy 0.5151\n",
            "Epoch 5 Batch 2350 Loss 0.8645 Accuracy 0.5153\n",
            "Epoch 5 Batch 2400 Loss 0.8619 Accuracy 0.5154\n",
            "Epoch 5 Batch 2450 Loss 0.8593 Accuracy 0.5157\n",
            "Epoch 5 Batch 2500 Loss 0.8570 Accuracy 0.5160\n",
            "Epoch 5 Batch 2550 Loss 0.8547 Accuracy 0.5162\n",
            "Epoch 5 Batch 2600 Loss 0.8520 Accuracy 0.5165\n",
            "Epoch 5 Batch 2650 Loss 0.8492 Accuracy 0.5169\n",
            "Epoch 5 Batch 2700 Loss 0.8467 Accuracy 0.5172\n",
            "Epoch 5 Batch 2750 Loss 0.8445 Accuracy 0.5175\n",
            "Epoch 5 Batch 2800 Loss 0.8425 Accuracy 0.5177\n",
            "Epoch 5 Batch 2850 Loss 0.8404 Accuracy 0.5180\n",
            "Epoch 5 Batch 2900 Loss 0.8385 Accuracy 0.5182\n",
            "Epoch 5 Batch 2950 Loss 0.8366 Accuracy 0.5184\n",
            "Epoch 5 Batch 3000 Loss 0.8350 Accuracy 0.5186\n",
            "Epoch 5 Batch 3050 Loss 0.8335 Accuracy 0.5189\n",
            "Epoch 5 Batch 3100 Loss 0.8319 Accuracy 0.5191\n",
            "Epoch 5 Batch 3150 Loss 0.8305 Accuracy 0.5193\n",
            "Epoch 5 Batch 3200 Loss 0.8289 Accuracy 0.5196\n",
            "Epoch 5 Batch 3250 Loss 0.8271 Accuracy 0.5198\n",
            "Epoch 5 Batch 3300 Loss 0.8254 Accuracy 0.5201\n",
            "Epoch 5 Batch 3350 Loss 0.8234 Accuracy 0.5203\n",
            "Epoch 5 Batch 3400 Loss 0.8214 Accuracy 0.5206\n",
            "Epoch 5 Batch 3450 Loss 0.8198 Accuracy 0.5208\n",
            "Epoch 5 Batch 3500 Loss 0.8182 Accuracy 0.5211\n",
            "Epoch 5 Batch 3550 Loss 0.8168 Accuracy 0.5214\n",
            "Epoch 5 Batch 3600 Loss 0.8150 Accuracy 0.5218\n",
            "Epoch 5 Batch 3650 Loss 0.8135 Accuracy 0.5220\n",
            "Epoch 5 Batch 3700 Loss 0.8120 Accuracy 0.5223\n",
            "Epoch 5 Batch 3750 Loss 0.8105 Accuracy 0.5226\n",
            "Epoch 5 Batch 3800 Loss 0.8090 Accuracy 0.5230\n",
            "Epoch 5 Batch 3850 Loss 0.8075 Accuracy 0.5232\n",
            "Epoch 5 Batch 3900 Loss 0.8062 Accuracy 0.5235\n",
            "Epoch 5 Batch 3950 Loss 0.8049 Accuracy 0.5238\n",
            "Epoch 5 Batch 4000 Loss 0.8035 Accuracy 0.5242\n",
            "Epoch 5 Batch 4050 Loss 0.8026 Accuracy 0.5244\n",
            "Epoch 5 Batch 4100 Loss 0.8016 Accuracy 0.5246\n",
            "Epoch 5 Batch 4150 Loss 0.8012 Accuracy 0.5247\n",
            "Epoch 5 Batch 4200 Loss 0.8014 Accuracy 0.5248\n",
            "Epoch 5 Batch 4250 Loss 0.8018 Accuracy 0.5247\n",
            "Epoch 5 Batch 4300 Loss 0.8029 Accuracy 0.5246\n",
            "Epoch 5 Batch 4350 Loss 0.8040 Accuracy 0.5245\n",
            "Epoch 5 Batch 4400 Loss 0.8053 Accuracy 0.5243\n",
            "Epoch 5 Batch 4450 Loss 0.8065 Accuracy 0.5240\n",
            "Epoch 5 Batch 4500 Loss 0.8077 Accuracy 0.5238\n",
            "Epoch 5 Batch 4550 Loss 0.8091 Accuracy 0.5237\n",
            "Epoch 5 Batch 4600 Loss 0.8105 Accuracy 0.5234\n",
            "Epoch 5 Batch 4650 Loss 0.8119 Accuracy 0.5232\n",
            "Epoch 5 Batch 4700 Loss 0.8134 Accuracy 0.5231\n",
            "Epoch 5 Batch 4750 Loss 0.8147 Accuracy 0.5229\n",
            "Epoch 5 Batch 4800 Loss 0.8158 Accuracy 0.5227\n",
            "Epoch 5 Batch 4850 Loss 0.8170 Accuracy 0.5226\n",
            "Epoch 5 Batch 4900 Loss 0.8183 Accuracy 0.5223\n",
            "Epoch 5 Batch 4950 Loss 0.8197 Accuracy 0.5221\n",
            "Epoch 5 Batch 5000 Loss 0.8210 Accuracy 0.5218\n",
            "Epoch 5 Batch 5050 Loss 0.8222 Accuracy 0.5216\n",
            "Epoch 5 Batch 5100 Loss 0.8236 Accuracy 0.5214\n",
            "Epoch 5 Batch 5150 Loss 0.8248 Accuracy 0.5211\n",
            "Epoch 5 Batch 5200 Loss 0.8261 Accuracy 0.5209\n",
            "Epoch 5 Batch 5250 Loss 0.8275 Accuracy 0.5206\n",
            "Epoch 5 Batch 5300 Loss 0.8289 Accuracy 0.5203\n",
            "Epoch 5 Batch 5350 Loss 0.8301 Accuracy 0.5200\n",
            "Epoch 5 Batch 5400 Loss 0.8313 Accuracy 0.5197\n",
            "Epoch 5 Batch 5450 Loss 0.8322 Accuracy 0.5194\n",
            "Epoch 5 Batch 5500 Loss 0.8335 Accuracy 0.5191\n",
            "Epoch 5 Batch 5550 Loss 0.8344 Accuracy 0.5189\n",
            "Epoch 5 Batch 5600 Loss 0.8355 Accuracy 0.5187\n",
            "Epoch 5 Batch 5650 Loss 0.8366 Accuracy 0.5184\n",
            "Epoch 5 Batch 5700 Loss 0.8375 Accuracy 0.5181\n",
            "Saving checkpoint for epoch 5 at ./drive/My Drive/projects/transformer/ckpt/ckpt-20\n",
            "Time taken for 1 epoch: 1444.3247916698456 secs\n",
            "\n",
            "Start of epoch 6\n",
            "Epoch 6 Batch 0 Loss 1.0119 Accuracy 0.4877\n",
            "Epoch 6 Batch 50 Loss 0.9686 Accuracy 0.4927\n",
            "Epoch 6 Batch 100 Loss 0.9536 Accuracy 0.4964\n",
            "Epoch 6 Batch 150 Loss 0.9533 Accuracy 0.4971\n",
            "Epoch 6 Batch 200 Loss 0.9453 Accuracy 0.4991\n",
            "Epoch 6 Batch 250 Loss 0.9417 Accuracy 0.4997\n",
            "Epoch 6 Batch 300 Loss 0.9398 Accuracy 0.4995\n",
            "Epoch 6 Batch 350 Loss 0.9366 Accuracy 0.4990\n",
            "Epoch 6 Batch 400 Loss 0.9323 Accuracy 0.4990\n",
            "Epoch 6 Batch 450 Loss 0.9293 Accuracy 0.4996\n",
            "Epoch 6 Batch 500 Loss 0.9287 Accuracy 0.4996\n",
            "Epoch 6 Batch 550 Loss 0.9282 Accuracy 0.5002\n",
            "Epoch 6 Batch 600 Loss 0.9261 Accuracy 0.5003\n",
            "Epoch 6 Batch 650 Loss 0.9272 Accuracy 0.5008\n",
            "Epoch 6 Batch 700 Loss 0.9253 Accuracy 0.5010\n",
            "Epoch 6 Batch 750 Loss 0.9250 Accuracy 0.5012\n",
            "Epoch 6 Batch 800 Loss 0.9253 Accuracy 0.5018\n",
            "Epoch 6 Batch 850 Loss 0.9241 Accuracy 0.5022\n",
            "Epoch 6 Batch 900 Loss 0.9243 Accuracy 0.5024\n",
            "Epoch 6 Batch 950 Loss 0.9216 Accuracy 0.5025\n",
            "Epoch 6 Batch 1000 Loss 0.9192 Accuracy 0.5027\n",
            "Epoch 6 Batch 1050 Loss 0.9176 Accuracy 0.5029\n",
            "Epoch 6 Batch 1100 Loss 0.9151 Accuracy 0.5027\n",
            "Epoch 6 Batch 1150 Loss 0.9154 Accuracy 0.5029\n",
            "Epoch 6 Batch 1200 Loss 0.9134 Accuracy 0.5031\n",
            "Epoch 6 Batch 1250 Loss 0.9119 Accuracy 0.5037\n",
            "Epoch 6 Batch 1300 Loss 0.9092 Accuracy 0.5041\n",
            "Epoch 6 Batch 1350 Loss 0.9071 Accuracy 0.5047\n",
            "Epoch 6 Batch 1400 Loss 0.9043 Accuracy 0.5053\n",
            "Epoch 6 Batch 1450 Loss 0.9018 Accuracy 0.5060\n",
            "Epoch 6 Batch 1500 Loss 0.8988 Accuracy 0.5067\n",
            "Epoch 6 Batch 1550 Loss 0.8965 Accuracy 0.5075\n",
            "Epoch 6 Batch 1600 Loss 0.8942 Accuracy 0.5083\n",
            "Epoch 6 Batch 1650 Loss 0.8920 Accuracy 0.5093\n",
            "Epoch 6 Batch 1700 Loss 0.8896 Accuracy 0.5101\n",
            "Epoch 6 Batch 1750 Loss 0.8874 Accuracy 0.5107\n",
            "Epoch 6 Batch 1800 Loss 0.8848 Accuracy 0.5114\n",
            "Epoch 6 Batch 1850 Loss 0.8829 Accuracy 0.5121\n",
            "Epoch 6 Batch 1900 Loss 0.8808 Accuracy 0.5130\n",
            "Epoch 6 Batch 1950 Loss 0.8790 Accuracy 0.5138\n",
            "Epoch 6 Batch 2000 Loss 0.8773 Accuracy 0.5143\n",
            "Epoch 6 Batch 2050 Loss 0.8751 Accuracy 0.5148\n",
            "Epoch 6 Batch 2100 Loss 0.8730 Accuracy 0.5152\n",
            "Epoch 6 Batch 2150 Loss 0.8708 Accuracy 0.5155\n",
            "Epoch 6 Batch 2200 Loss 0.8670 Accuracy 0.5157\n",
            "Epoch 6 Batch 2250 Loss 0.8644 Accuracy 0.5158\n",
            "Epoch 6 Batch 2300 Loss 0.8616 Accuracy 0.5159\n",
            "Epoch 6 Batch 2350 Loss 0.8591 Accuracy 0.5161\n",
            "Epoch 6 Batch 2400 Loss 0.8565 Accuracy 0.5163\n",
            "Epoch 6 Batch 2450 Loss 0.8543 Accuracy 0.5165\n",
            "Epoch 6 Batch 2500 Loss 0.8515 Accuracy 0.5167\n",
            "Epoch 6 Batch 2550 Loss 0.8488 Accuracy 0.5170\n",
            "Epoch 6 Batch 2600 Loss 0.8465 Accuracy 0.5174\n",
            "Epoch 6 Batch 2650 Loss 0.8442 Accuracy 0.5178\n",
            "Epoch 6 Batch 2700 Loss 0.8424 Accuracy 0.5180\n",
            "Epoch 6 Batch 2750 Loss 0.8402 Accuracy 0.5183\n",
            "Epoch 6 Batch 2800 Loss 0.8382 Accuracy 0.5186\n",
            "Epoch 6 Batch 2850 Loss 0.8363 Accuracy 0.5189\n",
            "Epoch 6 Batch 2900 Loss 0.8338 Accuracy 0.5192\n",
            "Epoch 6 Batch 2950 Loss 0.8321 Accuracy 0.5194\n",
            "Epoch 6 Batch 3000 Loss 0.8304 Accuracy 0.5196\n",
            "Epoch 6 Batch 3050 Loss 0.8286 Accuracy 0.5198\n",
            "Epoch 6 Batch 3100 Loss 0.8271 Accuracy 0.5200\n",
            "Epoch 6 Batch 3150 Loss 0.8256 Accuracy 0.5203\n",
            "Epoch 6 Batch 3200 Loss 0.8239 Accuracy 0.5205\n",
            "Epoch 6 Batch 3250 Loss 0.8220 Accuracy 0.5207\n",
            "Epoch 6 Batch 3300 Loss 0.8204 Accuracy 0.5209\n",
            "Epoch 6 Batch 3350 Loss 0.8186 Accuracy 0.5213\n",
            "Epoch 6 Batch 3400 Loss 0.8167 Accuracy 0.5215\n",
            "Epoch 6 Batch 3450 Loss 0.8151 Accuracy 0.5218\n",
            "Epoch 6 Batch 3500 Loss 0.8133 Accuracy 0.5221\n",
            "Epoch 6 Batch 3550 Loss 0.8116 Accuracy 0.5224\n",
            "Epoch 6 Batch 3600 Loss 0.8101 Accuracy 0.5226\n",
            "Epoch 6 Batch 3650 Loss 0.8086 Accuracy 0.5229\n",
            "Epoch 6 Batch 3700 Loss 0.8071 Accuracy 0.5232\n",
            "Epoch 6 Batch 3750 Loss 0.8056 Accuracy 0.5235\n",
            "Epoch 6 Batch 3800 Loss 0.8044 Accuracy 0.5238\n",
            "Epoch 6 Batch 3850 Loss 0.8030 Accuracy 0.5241\n",
            "Epoch 6 Batch 3900 Loss 0.8017 Accuracy 0.5245\n",
            "Epoch 6 Batch 3950 Loss 0.8003 Accuracy 0.5248\n",
            "Epoch 6 Batch 4000 Loss 0.7991 Accuracy 0.5251\n",
            "Epoch 6 Batch 4050 Loss 0.7981 Accuracy 0.5255\n",
            "Epoch 6 Batch 4100 Loss 0.7969 Accuracy 0.5256\n",
            "Epoch 6 Batch 4150 Loss 0.7967 Accuracy 0.5257\n",
            "Epoch 6 Batch 4200 Loss 0.7969 Accuracy 0.5257\n",
            "Epoch 6 Batch 4250 Loss 0.7972 Accuracy 0.5256\n",
            "Epoch 6 Batch 4300 Loss 0.7980 Accuracy 0.5256\n",
            "Epoch 6 Batch 4350 Loss 0.7990 Accuracy 0.5254\n",
            "Epoch 6 Batch 4400 Loss 0.8001 Accuracy 0.5252\n",
            "Epoch 6 Batch 4450 Loss 0.8013 Accuracy 0.5250\n",
            "Epoch 6 Batch 4500 Loss 0.8025 Accuracy 0.5248\n",
            "Epoch 6 Batch 4550 Loss 0.8037 Accuracy 0.5246\n",
            "Epoch 6 Batch 4600 Loss 0.8049 Accuracy 0.5244\n",
            "Epoch 6 Batch 4650 Loss 0.8065 Accuracy 0.5242\n",
            "Epoch 6 Batch 4700 Loss 0.8077 Accuracy 0.5240\n",
            "Epoch 6 Batch 4750 Loss 0.8093 Accuracy 0.5238\n",
            "Epoch 6 Batch 4800 Loss 0.8105 Accuracy 0.5237\n",
            "Epoch 6 Batch 4850 Loss 0.8116 Accuracy 0.5235\n",
            "Epoch 6 Batch 4900 Loss 0.8130 Accuracy 0.5232\n",
            "Epoch 6 Batch 4950 Loss 0.8146 Accuracy 0.5230\n",
            "Epoch 6 Batch 5000 Loss 0.8160 Accuracy 0.5228\n",
            "Epoch 6 Batch 5050 Loss 0.8173 Accuracy 0.5226\n",
            "Epoch 6 Batch 5100 Loss 0.8188 Accuracy 0.5223\n",
            "Epoch 6 Batch 5150 Loss 0.8200 Accuracy 0.5221\n",
            "Epoch 6 Batch 5200 Loss 0.8211 Accuracy 0.5218\n",
            "Epoch 6 Batch 5250 Loss 0.8225 Accuracy 0.5215\n",
            "Epoch 6 Batch 5300 Loss 0.8238 Accuracy 0.5212\n",
            "Epoch 6 Batch 5350 Loss 0.8249 Accuracy 0.5209\n",
            "Epoch 6 Batch 5400 Loss 0.8263 Accuracy 0.5206\n",
            "Epoch 6 Batch 5450 Loss 0.8272 Accuracy 0.5203\n",
            "Epoch 6 Batch 5500 Loss 0.8283 Accuracy 0.5200\n",
            "Epoch 6 Batch 5550 Loss 0.8295 Accuracy 0.5197\n",
            "Epoch 6 Batch 5600 Loss 0.8305 Accuracy 0.5196\n",
            "Epoch 6 Batch 5650 Loss 0.8318 Accuracy 0.5193\n",
            "Epoch 6 Batch 5700 Loss 0.8326 Accuracy 0.5190\n",
            "Saving checkpoint for epoch 6 at ./drive/My Drive/projects/transformer/ckpt/ckpt-21\n",
            "Time taken for 1 epoch: 1449.105771780014 secs\n",
            "\n",
            "Start of epoch 7\n",
            "Epoch 7 Batch 0 Loss 0.8802 Accuracy 0.4942\n",
            "Epoch 7 Batch 50 Loss 0.9488 Accuracy 0.4977\n",
            "Epoch 7 Batch 100 Loss 0.9383 Accuracy 0.5009\n",
            "Epoch 7 Batch 150 Loss 0.9385 Accuracy 0.5015\n",
            "Epoch 7 Batch 200 Loss 0.9351 Accuracy 0.5012\n",
            "Epoch 7 Batch 250 Loss 0.9359 Accuracy 0.5020\n",
            "Epoch 7 Batch 300 Loss 0.9369 Accuracy 0.5020\n",
            "Epoch 7 Batch 350 Loss 0.9353 Accuracy 0.5019\n",
            "Epoch 7 Batch 400 Loss 0.9333 Accuracy 0.5017\n",
            "Epoch 7 Batch 450 Loss 0.9327 Accuracy 0.5012\n",
            "Epoch 7 Batch 500 Loss 0.9290 Accuracy 0.5010\n",
            "Epoch 7 Batch 550 Loss 0.9272 Accuracy 0.5013\n",
            "Epoch 7 Batch 600 Loss 0.9263 Accuracy 0.5016\n",
            "Epoch 7 Batch 650 Loss 0.9231 Accuracy 0.5017\n",
            "Epoch 7 Batch 700 Loss 0.9221 Accuracy 0.5022\n",
            "Epoch 7 Batch 750 Loss 0.9216 Accuracy 0.5023\n",
            "Epoch 7 Batch 800 Loss 0.9201 Accuracy 0.5023\n",
            "Epoch 7 Batch 850 Loss 0.9189 Accuracy 0.5025\n",
            "Epoch 7 Batch 900 Loss 0.9183 Accuracy 0.5027\n",
            "Epoch 7 Batch 950 Loss 0.9155 Accuracy 0.5027\n",
            "Epoch 7 Batch 1000 Loss 0.9132 Accuracy 0.5029\n",
            "Epoch 7 Batch 1050 Loss 0.9124 Accuracy 0.5029\n",
            "Epoch 7 Batch 1100 Loss 0.9112 Accuracy 0.5032\n",
            "Epoch 7 Batch 1150 Loss 0.9109 Accuracy 0.5034\n",
            "Epoch 7 Batch 1200 Loss 0.9100 Accuracy 0.5037\n",
            "Epoch 7 Batch 1250 Loss 0.9071 Accuracy 0.5040\n",
            "Epoch 7 Batch 1300 Loss 0.9054 Accuracy 0.5043\n",
            "Epoch 7 Batch 1350 Loss 0.9029 Accuracy 0.5049\n",
            "Epoch 7 Batch 1400 Loss 0.9003 Accuracy 0.5056\n",
            "Epoch 7 Batch 1450 Loss 0.8971 Accuracy 0.5064\n",
            "Epoch 7 Batch 1500 Loss 0.8948 Accuracy 0.5072\n",
            "Epoch 7 Batch 1550 Loss 0.8926 Accuracy 0.5082\n",
            "Epoch 7 Batch 1600 Loss 0.8900 Accuracy 0.5091\n",
            "Epoch 7 Batch 1650 Loss 0.8872 Accuracy 0.5098\n",
            "Epoch 7 Batch 1700 Loss 0.8853 Accuracy 0.5106\n",
            "Epoch 7 Batch 1750 Loss 0.8831 Accuracy 0.5116\n",
            "Epoch 7 Batch 1800 Loss 0.8811 Accuracy 0.5124\n",
            "Epoch 7 Batch 1850 Loss 0.8789 Accuracy 0.5132\n",
            "Epoch 7 Batch 1900 Loss 0.8768 Accuracy 0.5139\n",
            "Epoch 7 Batch 1950 Loss 0.8747 Accuracy 0.5147\n",
            "Epoch 7 Batch 2000 Loss 0.8724 Accuracy 0.5153\n",
            "Epoch 7 Batch 2050 Loss 0.8704 Accuracy 0.5158\n",
            "Epoch 7 Batch 2100 Loss 0.8681 Accuracy 0.5160\n",
            "Epoch 7 Batch 2150 Loss 0.8661 Accuracy 0.5162\n",
            "Epoch 7 Batch 2200 Loss 0.8638 Accuracy 0.5164\n",
            "Epoch 7 Batch 2250 Loss 0.8607 Accuracy 0.5166\n",
            "Epoch 7 Batch 2300 Loss 0.8580 Accuracy 0.5168\n",
            "Epoch 7 Batch 2350 Loss 0.8555 Accuracy 0.5170\n",
            "Epoch 7 Batch 2400 Loss 0.8526 Accuracy 0.5173\n",
            "Epoch 7 Batch 2450 Loss 0.8499 Accuracy 0.5176\n",
            "Epoch 7 Batch 2500 Loss 0.8472 Accuracy 0.5179\n",
            "Epoch 7 Batch 2550 Loss 0.8450 Accuracy 0.5182\n",
            "Epoch 7 Batch 2600 Loss 0.8424 Accuracy 0.5185\n",
            "Epoch 7 Batch 2650 Loss 0.8397 Accuracy 0.5188\n",
            "Epoch 7 Batch 2700 Loss 0.8379 Accuracy 0.5191\n",
            "Epoch 7 Batch 2750 Loss 0.8358 Accuracy 0.5194\n",
            "Epoch 7 Batch 2800 Loss 0.8338 Accuracy 0.5197\n",
            "Epoch 7 Batch 2850 Loss 0.8315 Accuracy 0.5199\n",
            "Epoch 7 Batch 2900 Loss 0.8295 Accuracy 0.5201\n",
            "Epoch 7 Batch 2950 Loss 0.8276 Accuracy 0.5204\n",
            "Epoch 7 Batch 3000 Loss 0.8255 Accuracy 0.5207\n",
            "Epoch 7 Batch 3050 Loss 0.8239 Accuracy 0.5210\n",
            "Epoch 7 Batch 3100 Loss 0.8225 Accuracy 0.5212\n",
            "Epoch 7 Batch 3150 Loss 0.8208 Accuracy 0.5213\n",
            "Epoch 7 Batch 3200 Loss 0.8190 Accuracy 0.5215\n",
            "Epoch 7 Batch 3250 Loss 0.8174 Accuracy 0.5216\n",
            "Epoch 7 Batch 3300 Loss 0.8155 Accuracy 0.5218\n",
            "Epoch 7 Batch 3350 Loss 0.8136 Accuracy 0.5221\n",
            "Epoch 7 Batch 3400 Loss 0.8120 Accuracy 0.5224\n",
            "Epoch 7 Batch 3450 Loss 0.8100 Accuracy 0.5227\n",
            "Epoch 7 Batch 3500 Loss 0.8085 Accuracy 0.5230\n",
            "Epoch 7 Batch 3550 Loss 0.8069 Accuracy 0.5233\n",
            "Epoch 7 Batch 3600 Loss 0.8054 Accuracy 0.5235\n",
            "Epoch 7 Batch 3650 Loss 0.8039 Accuracy 0.5237\n",
            "Epoch 7 Batch 3700 Loss 0.8024 Accuracy 0.5241\n",
            "Epoch 7 Batch 3750 Loss 0.8008 Accuracy 0.5244\n",
            "Epoch 7 Batch 3800 Loss 0.7994 Accuracy 0.5247\n",
            "Epoch 7 Batch 3850 Loss 0.7982 Accuracy 0.5250\n",
            "Epoch 7 Batch 3900 Loss 0.7971 Accuracy 0.5253\n",
            "Epoch 7 Batch 3950 Loss 0.7959 Accuracy 0.5257\n",
            "Epoch 7 Batch 4000 Loss 0.7946 Accuracy 0.5260\n",
            "Epoch 7 Batch 4050 Loss 0.7933 Accuracy 0.5263\n",
            "Epoch 7 Batch 4100 Loss 0.7925 Accuracy 0.5265\n",
            "Epoch 7 Batch 4150 Loss 0.7922 Accuracy 0.5266\n",
            "Epoch 7 Batch 4200 Loss 0.7925 Accuracy 0.5265\n",
            "Epoch 7 Batch 4250 Loss 0.7928 Accuracy 0.5264\n",
            "Epoch 7 Batch 4300 Loss 0.7937 Accuracy 0.5263\n",
            "Epoch 7 Batch 4350 Loss 0.7947 Accuracy 0.5262\n",
            "Epoch 7 Batch 4400 Loss 0.7960 Accuracy 0.5260\n",
            "Epoch 7 Batch 4450 Loss 0.7972 Accuracy 0.5258\n",
            "Epoch 7 Batch 4500 Loss 0.7986 Accuracy 0.5256\n",
            "Epoch 7 Batch 4550 Loss 0.7997 Accuracy 0.5254\n",
            "Epoch 7 Batch 4600 Loss 0.8010 Accuracy 0.5252\n",
            "Epoch 7 Batch 4650 Loss 0.8023 Accuracy 0.5250\n",
            "Epoch 7 Batch 4700 Loss 0.8039 Accuracy 0.5249\n",
            "Epoch 7 Batch 4750 Loss 0.8051 Accuracy 0.5246\n",
            "Epoch 7 Batch 4800 Loss 0.8065 Accuracy 0.5244\n",
            "Epoch 7 Batch 4850 Loss 0.8078 Accuracy 0.5242\n",
            "Epoch 7 Batch 4900 Loss 0.8091 Accuracy 0.5240\n",
            "Epoch 7 Batch 4950 Loss 0.8104 Accuracy 0.5237\n",
            "Epoch 7 Batch 5000 Loss 0.8117 Accuracy 0.5235\n",
            "Epoch 7 Batch 5050 Loss 0.8132 Accuracy 0.5233\n",
            "Epoch 7 Batch 5100 Loss 0.8143 Accuracy 0.5230\n",
            "Epoch 7 Batch 5150 Loss 0.8157 Accuracy 0.5227\n",
            "Epoch 7 Batch 5200 Loss 0.8169 Accuracy 0.5225\n",
            "Epoch 7 Batch 5250 Loss 0.8182 Accuracy 0.5223\n",
            "Epoch 7 Batch 5300 Loss 0.8193 Accuracy 0.5220\n",
            "Epoch 7 Batch 5350 Loss 0.8203 Accuracy 0.5217\n",
            "Epoch 7 Batch 5400 Loss 0.8214 Accuracy 0.5214\n",
            "Epoch 7 Batch 5450 Loss 0.8228 Accuracy 0.5211\n",
            "Epoch 7 Batch 5500 Loss 0.8240 Accuracy 0.5207\n",
            "Epoch 7 Batch 5550 Loss 0.8250 Accuracy 0.5205\n",
            "Epoch 7 Batch 5600 Loss 0.8261 Accuracy 0.5202\n",
            "Epoch 7 Batch 5650 Loss 0.8271 Accuracy 0.5200\n",
            "Epoch 7 Batch 5700 Loss 0.8280 Accuracy 0.5197\n",
            "Saving checkpoint for epoch 7 at ./drive/My Drive/projects/transformer/ckpt/ckpt-22\n",
            "Time taken for 1 epoch: 1432.7689785957336 secs\n",
            "\n",
            "Start of epoch 8\n",
            "Epoch 8 Batch 0 Loss 0.9609 Accuracy 0.5074\n",
            "Epoch 8 Batch 50 Loss 0.9325 Accuracy 0.5052\n",
            "Epoch 8 Batch 100 Loss 0.9371 Accuracy 0.5029\n",
            "Epoch 8 Batch 150 Loss 0.9382 Accuracy 0.5021\n",
            "Epoch 8 Batch 200 Loss 0.9413 Accuracy 0.5022\n",
            "Epoch 8 Batch 250 Loss 0.9369 Accuracy 0.5015\n",
            "Epoch 8 Batch 300 Loss 0.9342 Accuracy 0.5013\n",
            "Epoch 8 Batch 350 Loss 0.9284 Accuracy 0.5014\n",
            "Epoch 8 Batch 400 Loss 0.9229 Accuracy 0.5020\n",
            "Epoch 8 Batch 450 Loss 0.9219 Accuracy 0.5013\n",
            "Epoch 8 Batch 500 Loss 0.9199 Accuracy 0.5012\n",
            "Epoch 8 Batch 550 Loss 0.9181 Accuracy 0.5014\n",
            "Epoch 8 Batch 600 Loss 0.9166 Accuracy 0.5019\n",
            "Epoch 8 Batch 650 Loss 0.9142 Accuracy 0.5023\n",
            "Epoch 8 Batch 700 Loss 0.9125 Accuracy 0.5026\n",
            "Epoch 8 Batch 750 Loss 0.9140 Accuracy 0.5029\n",
            "Epoch 8 Batch 800 Loss 0.9136 Accuracy 0.5030\n",
            "Epoch 8 Batch 850 Loss 0.9124 Accuracy 0.5033\n",
            "Epoch 8 Batch 900 Loss 0.9115 Accuracy 0.5031\n",
            "Epoch 8 Batch 950 Loss 0.9094 Accuracy 0.5032\n",
            "Epoch 8 Batch 1000 Loss 0.9072 Accuracy 0.5035\n",
            "Epoch 8 Batch 1050 Loss 0.9058 Accuracy 0.5037\n",
            "Epoch 8 Batch 1100 Loss 0.9048 Accuracy 0.5037\n",
            "Epoch 8 Batch 1150 Loss 0.9037 Accuracy 0.5042\n",
            "Epoch 8 Batch 1200 Loss 0.9022 Accuracy 0.5047\n",
            "Epoch 8 Batch 1250 Loss 0.9006 Accuracy 0.5051\n",
            "Epoch 8 Batch 1300 Loss 0.8993 Accuracy 0.5055\n",
            "Epoch 8 Batch 1350 Loss 0.8968 Accuracy 0.5059\n",
            "Epoch 8 Batch 1400 Loss 0.8944 Accuracy 0.5066\n",
            "Epoch 8 Batch 1450 Loss 0.8924 Accuracy 0.5072\n",
            "Epoch 8 Batch 1500 Loss 0.8903 Accuracy 0.5081\n",
            "Epoch 8 Batch 1550 Loss 0.8880 Accuracy 0.5089\n",
            "Epoch 8 Batch 1600 Loss 0.8852 Accuracy 0.5099\n",
            "Epoch 8 Batch 1650 Loss 0.8829 Accuracy 0.5107\n",
            "Epoch 8 Batch 1700 Loss 0.8809 Accuracy 0.5115\n",
            "Epoch 8 Batch 1750 Loss 0.8785 Accuracy 0.5123\n",
            "Epoch 8 Batch 1800 Loss 0.8759 Accuracy 0.5132\n",
            "Epoch 8 Batch 1850 Loss 0.8740 Accuracy 0.5140\n",
            "Epoch 8 Batch 1900 Loss 0.8720 Accuracy 0.5149\n",
            "Epoch 8 Batch 1950 Loss 0.8696 Accuracy 0.5156\n",
            "Epoch 8 Batch 2000 Loss 0.8673 Accuracy 0.5161\n",
            "Epoch 8 Batch 2050 Loss 0.8649 Accuracy 0.5166\n",
            "Epoch 8 Batch 2100 Loss 0.8624 Accuracy 0.5169\n",
            "Epoch 8 Batch 2150 Loss 0.8599 Accuracy 0.5171\n",
            "Epoch 8 Batch 2200 Loss 0.8572 Accuracy 0.5172\n",
            "Epoch 8 Batch 2250 Loss 0.8549 Accuracy 0.5173\n",
            "Epoch 8 Batch 2300 Loss 0.8521 Accuracy 0.5175\n",
            "Epoch 8 Batch 2350 Loss 0.8499 Accuracy 0.5178\n",
            "Epoch 8 Batch 2400 Loss 0.8474 Accuracy 0.5180\n",
            "Epoch 8 Batch 2450 Loss 0.8447 Accuracy 0.5183\n",
            "Epoch 8 Batch 2500 Loss 0.8420 Accuracy 0.5185\n",
            "Epoch 8 Batch 2550 Loss 0.8393 Accuracy 0.5188\n",
            "Epoch 8 Batch 2600 Loss 0.8367 Accuracy 0.5192\n",
            "Epoch 8 Batch 2650 Loss 0.8344 Accuracy 0.5194\n",
            "Epoch 8 Batch 2700 Loss 0.8320 Accuracy 0.5197\n",
            "Epoch 8 Batch 2750 Loss 0.8302 Accuracy 0.5200\n",
            "Epoch 8 Batch 2800 Loss 0.8285 Accuracy 0.5203\n",
            "Epoch 8 Batch 2850 Loss 0.8266 Accuracy 0.5205\n",
            "Epoch 8 Batch 2900 Loss 0.8248 Accuracy 0.5207\n",
            "Epoch 8 Batch 2950 Loss 0.8228 Accuracy 0.5209\n",
            "Epoch 8 Batch 3000 Loss 0.8209 Accuracy 0.5211\n",
            "Epoch 8 Batch 3050 Loss 0.8193 Accuracy 0.5214\n",
            "Epoch 8 Batch 3100 Loss 0.8176 Accuracy 0.5216\n",
            "Epoch 8 Batch 3150 Loss 0.8162 Accuracy 0.5219\n",
            "Epoch 8 Batch 3200 Loss 0.8144 Accuracy 0.5220\n",
            "Epoch 8 Batch 3250 Loss 0.8125 Accuracy 0.5222\n",
            "Epoch 8 Batch 3300 Loss 0.8109 Accuracy 0.5225\n",
            "Epoch 8 Batch 3350 Loss 0.8090 Accuracy 0.5227\n",
            "Epoch 8 Batch 3400 Loss 0.8071 Accuracy 0.5230\n",
            "Epoch 8 Batch 3450 Loss 0.8054 Accuracy 0.5233\n",
            "Epoch 8 Batch 3500 Loss 0.8038 Accuracy 0.5235\n",
            "Epoch 8 Batch 3550 Loss 0.8023 Accuracy 0.5238\n",
            "Epoch 8 Batch 3600 Loss 0.8006 Accuracy 0.5241\n",
            "Epoch 8 Batch 3650 Loss 0.7993 Accuracy 0.5244\n",
            "Epoch 8 Batch 3700 Loss 0.7977 Accuracy 0.5247\n",
            "Epoch 8 Batch 3750 Loss 0.7960 Accuracy 0.5250\n",
            "Epoch 8 Batch 3800 Loss 0.7947 Accuracy 0.5253\n",
            "Epoch 8 Batch 3850 Loss 0.7931 Accuracy 0.5257\n",
            "Epoch 8 Batch 3900 Loss 0.7920 Accuracy 0.5260\n",
            "Epoch 8 Batch 3950 Loss 0.7908 Accuracy 0.5262\n",
            "Epoch 8 Batch 4000 Loss 0.7898 Accuracy 0.5265\n",
            "Epoch 8 Batch 4050 Loss 0.7887 Accuracy 0.5268\n",
            "Epoch 8 Batch 4100 Loss 0.7875 Accuracy 0.5270\n",
            "Epoch 8 Batch 4150 Loss 0.7871 Accuracy 0.5271\n",
            "Epoch 8 Batch 4200 Loss 0.7874 Accuracy 0.5272\n",
            "Epoch 8 Batch 4250 Loss 0.7878 Accuracy 0.5271\n",
            "Epoch 8 Batch 4300 Loss 0.7888 Accuracy 0.5270\n",
            "Epoch 8 Batch 4350 Loss 0.7898 Accuracy 0.5268\n",
            "Epoch 8 Batch 4400 Loss 0.7910 Accuracy 0.5266\n",
            "Epoch 8 Batch 4450 Loss 0.7923 Accuracy 0.5264\n",
            "Epoch 8 Batch 4500 Loss 0.7939 Accuracy 0.5262\n",
            "Epoch 8 Batch 4550 Loss 0.7955 Accuracy 0.5260\n",
            "Epoch 8 Batch 4600 Loss 0.7970 Accuracy 0.5258\n",
            "Epoch 8 Batch 4650 Loss 0.7982 Accuracy 0.5257\n",
            "Epoch 8 Batch 4700 Loss 0.7996 Accuracy 0.5254\n",
            "Epoch 8 Batch 4750 Loss 0.8008 Accuracy 0.5252\n",
            "Epoch 8 Batch 4800 Loss 0.8021 Accuracy 0.5250\n",
            "Epoch 8 Batch 4850 Loss 0.8033 Accuracy 0.5248\n",
            "Epoch 8 Batch 4900 Loss 0.8045 Accuracy 0.5247\n",
            "Epoch 8 Batch 4950 Loss 0.8060 Accuracy 0.5244\n",
            "Epoch 8 Batch 5000 Loss 0.8073 Accuracy 0.5242\n",
            "Epoch 8 Batch 5050 Loss 0.8085 Accuracy 0.5239\n",
            "Epoch 8 Batch 5100 Loss 0.8097 Accuracy 0.5237\n",
            "Epoch 8 Batch 5150 Loss 0.8110 Accuracy 0.5235\n",
            "Epoch 8 Batch 5200 Loss 0.8124 Accuracy 0.5232\n",
            "Epoch 8 Batch 5250 Loss 0.8135 Accuracy 0.5229\n",
            "Epoch 8 Batch 5300 Loss 0.8147 Accuracy 0.5226\n",
            "Epoch 8 Batch 5350 Loss 0.8159 Accuracy 0.5223\n",
            "Epoch 8 Batch 5400 Loss 0.8170 Accuracy 0.5220\n",
            "Epoch 8 Batch 5450 Loss 0.8183 Accuracy 0.5217\n",
            "Epoch 8 Batch 5500 Loss 0.8192 Accuracy 0.5214\n",
            "Epoch 8 Batch 5550 Loss 0.8205 Accuracy 0.5212\n",
            "Epoch 8 Batch 5600 Loss 0.8215 Accuracy 0.5210\n",
            "Epoch 8 Batch 5650 Loss 0.8224 Accuracy 0.5207\n",
            "Epoch 8 Batch 5700 Loss 0.8236 Accuracy 0.5204\n",
            "Saving checkpoint for epoch 8 at ./drive/My Drive/projects/transformer/ckpt/ckpt-23\n",
            "Time taken for 1 epoch: 1425.8465909957886 secs\n",
            "\n",
            "Start of epoch 9\n",
            "Epoch 9 Batch 0 Loss 1.1149 Accuracy 0.5123\n",
            "Epoch 9 Batch 50 Loss 0.9252 Accuracy 0.5043\n",
            "Epoch 9 Batch 100 Loss 0.9141 Accuracy 0.5029\n",
            "Epoch 9 Batch 150 Loss 0.9207 Accuracy 0.5037\n",
            "Epoch 9 Batch 200 Loss 0.9202 Accuracy 0.5040\n",
            "Epoch 9 Batch 250 Loss 0.9192 Accuracy 0.5038\n",
            "Epoch 9 Batch 300 Loss 0.9197 Accuracy 0.5032\n",
            "Epoch 9 Batch 350 Loss 0.9193 Accuracy 0.5025\n",
            "Epoch 9 Batch 400 Loss 0.9175 Accuracy 0.5025\n",
            "Epoch 9 Batch 450 Loss 0.9149 Accuracy 0.5027\n",
            "Epoch 9 Batch 500 Loss 0.9151 Accuracy 0.5030\n",
            "Epoch 9 Batch 550 Loss 0.9130 Accuracy 0.5030\n",
            "Epoch 9 Batch 600 Loss 0.9126 Accuracy 0.5033\n",
            "Epoch 9 Batch 650 Loss 0.9103 Accuracy 0.5036\n",
            "Epoch 9 Batch 700 Loss 0.9096 Accuracy 0.5041\n",
            "Epoch 9 Batch 750 Loss 0.9092 Accuracy 0.5043\n",
            "Epoch 9 Batch 800 Loss 0.9082 Accuracy 0.5044\n",
            "Epoch 9 Batch 850 Loss 0.9066 Accuracy 0.5045\n",
            "Epoch 9 Batch 900 Loss 0.9070 Accuracy 0.5044\n",
            "Epoch 9 Batch 950 Loss 0.9073 Accuracy 0.5043\n",
            "Epoch 9 Batch 1000 Loss 0.9049 Accuracy 0.5046\n",
            "Epoch 9 Batch 1050 Loss 0.9032 Accuracy 0.5047\n",
            "Epoch 9 Batch 1100 Loss 0.9016 Accuracy 0.5049\n",
            "Epoch 9 Batch 1150 Loss 0.9006 Accuracy 0.5051\n",
            "Epoch 9 Batch 1200 Loss 0.8995 Accuracy 0.5054\n",
            "Epoch 9 Batch 1250 Loss 0.8978 Accuracy 0.5056\n",
            "Epoch 9 Batch 1300 Loss 0.8942 Accuracy 0.5062\n",
            "Epoch 9 Batch 1350 Loss 0.8929 Accuracy 0.5066\n",
            "Epoch 9 Batch 1400 Loss 0.8909 Accuracy 0.5074\n",
            "Epoch 9 Batch 1450 Loss 0.8885 Accuracy 0.5081\n",
            "Epoch 9 Batch 1500 Loss 0.8862 Accuracy 0.5089\n",
            "Epoch 9 Batch 1550 Loss 0.8837 Accuracy 0.5097\n",
            "Epoch 9 Batch 1600 Loss 0.8816 Accuracy 0.5105\n",
            "Epoch 9 Batch 1650 Loss 0.8791 Accuracy 0.5115\n",
            "Epoch 9 Batch 1700 Loss 0.8765 Accuracy 0.5120\n",
            "Epoch 9 Batch 1750 Loss 0.8743 Accuracy 0.5127\n",
            "Epoch 9 Batch 1800 Loss 0.8720 Accuracy 0.5135\n",
            "Epoch 9 Batch 1850 Loss 0.8704 Accuracy 0.5144\n",
            "Epoch 9 Batch 1900 Loss 0.8684 Accuracy 0.5153\n",
            "Epoch 9 Batch 1950 Loss 0.8663 Accuracy 0.5161\n",
            "Epoch 9 Batch 2000 Loss 0.8642 Accuracy 0.5168\n",
            "Epoch 9 Batch 2050 Loss 0.8619 Accuracy 0.5173\n",
            "Epoch 9 Batch 2100 Loss 0.8594 Accuracy 0.5177\n",
            "Epoch 9 Batch 2150 Loss 0.8571 Accuracy 0.5179\n",
            "Epoch 9 Batch 2200 Loss 0.8544 Accuracy 0.5181\n",
            "Epoch 9 Batch 2250 Loss 0.8515 Accuracy 0.5182\n",
            "Epoch 9 Batch 2300 Loss 0.8487 Accuracy 0.5183\n",
            "Epoch 9 Batch 2350 Loss 0.8459 Accuracy 0.5185\n",
            "Epoch 9 Batch 2400 Loss 0.8439 Accuracy 0.5188\n",
            "Epoch 9 Batch 2450 Loss 0.8412 Accuracy 0.5191\n",
            "Epoch 9 Batch 2500 Loss 0.8387 Accuracy 0.5194\n",
            "Epoch 9 Batch 2550 Loss 0.8361 Accuracy 0.5197\n",
            "Epoch 9 Batch 2600 Loss 0.8337 Accuracy 0.5200\n",
            "Epoch 9 Batch 2650 Loss 0.8309 Accuracy 0.5202\n",
            "Epoch 9 Batch 2700 Loss 0.8284 Accuracy 0.5204\n",
            "Epoch 9 Batch 2750 Loss 0.8264 Accuracy 0.5207\n",
            "Epoch 9 Batch 2800 Loss 0.8245 Accuracy 0.5209\n",
            "Epoch 9 Batch 2850 Loss 0.8226 Accuracy 0.5212\n",
            "Epoch 9 Batch 2900 Loss 0.8205 Accuracy 0.5215\n",
            "Epoch 9 Batch 2950 Loss 0.8185 Accuracy 0.5217\n",
            "Epoch 9 Batch 3000 Loss 0.8167 Accuracy 0.5220\n",
            "Epoch 9 Batch 3050 Loss 0.8153 Accuracy 0.5223\n",
            "Epoch 9 Batch 3100 Loss 0.8136 Accuracy 0.5225\n",
            "Epoch 9 Batch 3150 Loss 0.8118 Accuracy 0.5227\n",
            "Epoch 9 Batch 3200 Loss 0.8100 Accuracy 0.5228\n",
            "Epoch 9 Batch 3250 Loss 0.8080 Accuracy 0.5230\n",
            "Epoch 9 Batch 3300 Loss 0.8065 Accuracy 0.5232\n",
            "Epoch 9 Batch 3350 Loss 0.8048 Accuracy 0.5235\n",
            "Epoch 9 Batch 3400 Loss 0.8029 Accuracy 0.5237\n",
            "Epoch 9 Batch 3450 Loss 0.8013 Accuracy 0.5241\n",
            "Epoch 9 Batch 3500 Loss 0.7998 Accuracy 0.5244\n",
            "Epoch 9 Batch 3550 Loss 0.7985 Accuracy 0.5246\n",
            "Epoch 9 Batch 3600 Loss 0.7969 Accuracy 0.5249\n",
            "Epoch 9 Batch 3650 Loss 0.7953 Accuracy 0.5251\n",
            "Epoch 9 Batch 3700 Loss 0.7936 Accuracy 0.5255\n",
            "Epoch 9 Batch 3750 Loss 0.7924 Accuracy 0.5257\n",
            "Epoch 9 Batch 3800 Loss 0.7908 Accuracy 0.5260\n",
            "Epoch 9 Batch 3850 Loss 0.7894 Accuracy 0.5264\n",
            "Epoch 9 Batch 3900 Loss 0.7883 Accuracy 0.5267\n",
            "Epoch 9 Batch 3950 Loss 0.7872 Accuracy 0.5270\n",
            "Epoch 9 Batch 4000 Loss 0.7862 Accuracy 0.5272\n",
            "Epoch 9 Batch 4050 Loss 0.7850 Accuracy 0.5275\n",
            "Epoch 9 Batch 4100 Loss 0.7842 Accuracy 0.5277\n",
            "Epoch 9 Batch 4150 Loss 0.7838 Accuracy 0.5278\n",
            "Epoch 9 Batch 4200 Loss 0.7841 Accuracy 0.5279\n",
            "Epoch 9 Batch 4250 Loss 0.7846 Accuracy 0.5278\n",
            "Epoch 9 Batch 4300 Loss 0.7855 Accuracy 0.5277\n",
            "Epoch 9 Batch 4350 Loss 0.7860 Accuracy 0.5276\n",
            "Epoch 9 Batch 4400 Loss 0.7871 Accuracy 0.5274\n",
            "Epoch 9 Batch 4450 Loss 0.7884 Accuracy 0.5273\n",
            "Epoch 9 Batch 4500 Loss 0.7901 Accuracy 0.5271\n",
            "Epoch 9 Batch 4550 Loss 0.7915 Accuracy 0.5269\n",
            "Epoch 9 Batch 4600 Loss 0.7927 Accuracy 0.5267\n",
            "Epoch 9 Batch 4650 Loss 0.7940 Accuracy 0.5265\n",
            "Epoch 9 Batch 4700 Loss 0.7954 Accuracy 0.5263\n",
            "Epoch 9 Batch 4750 Loss 0.7968 Accuracy 0.5260\n",
            "Epoch 9 Batch 4800 Loss 0.7980 Accuracy 0.5258\n",
            "Epoch 9 Batch 4850 Loss 0.7993 Accuracy 0.5257\n",
            "Epoch 9 Batch 4900 Loss 0.8004 Accuracy 0.5254\n",
            "Epoch 9 Batch 4950 Loss 0.8017 Accuracy 0.5252\n",
            "Epoch 9 Batch 5000 Loss 0.8029 Accuracy 0.5250\n",
            "Epoch 9 Batch 5050 Loss 0.8042 Accuracy 0.5248\n",
            "Epoch 9 Batch 5100 Loss 0.8056 Accuracy 0.5245\n",
            "Epoch 9 Batch 5150 Loss 0.8068 Accuracy 0.5243\n",
            "Epoch 9 Batch 5200 Loss 0.8081 Accuracy 0.5240\n",
            "Epoch 9 Batch 5250 Loss 0.8095 Accuracy 0.5238\n",
            "Epoch 9 Batch 5300 Loss 0.8108 Accuracy 0.5235\n",
            "Epoch 9 Batch 5350 Loss 0.8120 Accuracy 0.5232\n",
            "Epoch 9 Batch 5400 Loss 0.8133 Accuracy 0.5229\n",
            "Epoch 9 Batch 5450 Loss 0.8145 Accuracy 0.5226\n",
            "Epoch 9 Batch 5500 Loss 0.8155 Accuracy 0.5223\n",
            "Epoch 9 Batch 5550 Loss 0.8164 Accuracy 0.5221\n",
            "Epoch 9 Batch 5600 Loss 0.8175 Accuracy 0.5218\n",
            "Epoch 9 Batch 5650 Loss 0.8184 Accuracy 0.5215\n",
            "Epoch 9 Batch 5700 Loss 0.8196 Accuracy 0.5213\n",
            "Saving checkpoint for epoch 9 at ./drive/My Drive/projects/transformer/ckpt/ckpt-24\n",
            "Time taken for 1 epoch: 1427.5661861896515 secs\n",
            "\n",
            "Start of epoch 10\n",
            "Epoch 10 Batch 0 Loss 0.8659 Accuracy 0.5280\n",
            "Epoch 10 Batch 50 Loss 0.9259 Accuracy 0.5001\n",
            "Epoch 10 Batch 100 Loss 0.9217 Accuracy 0.5017\n",
            "Epoch 10 Batch 150 Loss 0.9202 Accuracy 0.5014\n",
            "Epoch 10 Batch 200 Loss 0.9241 Accuracy 0.5025\n",
            "Epoch 10 Batch 250 Loss 0.9224 Accuracy 0.5031\n",
            "Epoch 10 Batch 300 Loss 0.9205 Accuracy 0.5036\n",
            "Epoch 10 Batch 350 Loss 0.9199 Accuracy 0.5040\n",
            "Epoch 10 Batch 400 Loss 0.9173 Accuracy 0.5032\n",
            "Epoch 10 Batch 450 Loss 0.9140 Accuracy 0.5036\n",
            "Epoch 10 Batch 500 Loss 0.9124 Accuracy 0.5034\n",
            "Epoch 10 Batch 550 Loss 0.9112 Accuracy 0.5035\n",
            "Epoch 10 Batch 600 Loss 0.9100 Accuracy 0.5035\n",
            "Epoch 10 Batch 650 Loss 0.9107 Accuracy 0.5040\n",
            "Epoch 10 Batch 700 Loss 0.9097 Accuracy 0.5043\n",
            "Epoch 10 Batch 750 Loss 0.9096 Accuracy 0.5048\n",
            "Epoch 10 Batch 800 Loss 0.9089 Accuracy 0.5048\n",
            "Epoch 10 Batch 850 Loss 0.9080 Accuracy 0.5049\n",
            "Epoch 10 Batch 900 Loss 0.9080 Accuracy 0.5048\n",
            "Epoch 10 Batch 950 Loss 0.9068 Accuracy 0.5046\n",
            "Epoch 10 Batch 1000 Loss 0.9046 Accuracy 0.5049\n",
            "Epoch 10 Batch 1050 Loss 0.9019 Accuracy 0.5048\n",
            "Epoch 10 Batch 1100 Loss 0.9006 Accuracy 0.5050\n",
            "Epoch 10 Batch 1150 Loss 0.8984 Accuracy 0.5053\n",
            "Epoch 10 Batch 1200 Loss 0.8960 Accuracy 0.5057\n",
            "Epoch 10 Batch 1250 Loss 0.8950 Accuracy 0.5060\n",
            "Epoch 10 Batch 1300 Loss 0.8932 Accuracy 0.5064\n",
            "Epoch 10 Batch 1350 Loss 0.8906 Accuracy 0.5070\n",
            "Epoch 10 Batch 1400 Loss 0.8886 Accuracy 0.5076\n",
            "Epoch 10 Batch 1450 Loss 0.8864 Accuracy 0.5086\n",
            "Epoch 10 Batch 1500 Loss 0.8838 Accuracy 0.5094\n",
            "Epoch 10 Batch 1550 Loss 0.8805 Accuracy 0.5101\n",
            "Epoch 10 Batch 1600 Loss 0.8781 Accuracy 0.5109\n",
            "Epoch 10 Batch 1650 Loss 0.8759 Accuracy 0.5117\n",
            "Epoch 10 Batch 1700 Loss 0.8735 Accuracy 0.5126\n",
            "Epoch 10 Batch 1750 Loss 0.8712 Accuracy 0.5134\n",
            "Epoch 10 Batch 1800 Loss 0.8691 Accuracy 0.5144\n",
            "Epoch 10 Batch 1850 Loss 0.8669 Accuracy 0.5153\n",
            "Epoch 10 Batch 1900 Loss 0.8650 Accuracy 0.5162\n",
            "Epoch 10 Batch 1950 Loss 0.8629 Accuracy 0.5167\n",
            "Epoch 10 Batch 2000 Loss 0.8607 Accuracy 0.5172\n",
            "Epoch 10 Batch 2050 Loss 0.8587 Accuracy 0.5178\n",
            "Epoch 10 Batch 2100 Loss 0.8560 Accuracy 0.5182\n",
            "Epoch 10 Batch 2150 Loss 0.8533 Accuracy 0.5184\n",
            "Epoch 10 Batch 2200 Loss 0.8502 Accuracy 0.5185\n",
            "Epoch 10 Batch 2250 Loss 0.8478 Accuracy 0.5187\n",
            "Epoch 10 Batch 2300 Loss 0.8450 Accuracy 0.5189\n",
            "Epoch 10 Batch 2350 Loss 0.8422 Accuracy 0.5191\n",
            "Epoch 10 Batch 2400 Loss 0.8395 Accuracy 0.5193\n",
            "Epoch 10 Batch 2450 Loss 0.8371 Accuracy 0.5197\n",
            "Epoch 10 Batch 2500 Loss 0.8344 Accuracy 0.5199\n",
            "Epoch 10 Batch 2550 Loss 0.8317 Accuracy 0.5201\n",
            "Epoch 10 Batch 2600 Loss 0.8295 Accuracy 0.5203\n",
            "Epoch 10 Batch 2650 Loss 0.8271 Accuracy 0.5206\n",
            "Epoch 10 Batch 2700 Loss 0.8244 Accuracy 0.5210\n",
            "Epoch 10 Batch 2750 Loss 0.8225 Accuracy 0.5212\n",
            "Epoch 10 Batch 2800 Loss 0.8204 Accuracy 0.5215\n",
            "Epoch 10 Batch 2850 Loss 0.8185 Accuracy 0.5217\n",
            "Epoch 10 Batch 2900 Loss 0.8168 Accuracy 0.5220\n",
            "Epoch 10 Batch 2950 Loss 0.8152 Accuracy 0.5223\n",
            "Epoch 10 Batch 3000 Loss 0.8132 Accuracy 0.5225\n",
            "Epoch 10 Batch 3050 Loss 0.8116 Accuracy 0.5227\n",
            "Epoch 10 Batch 3100 Loss 0.8101 Accuracy 0.5229\n",
            "Epoch 10 Batch 3150 Loss 0.8084 Accuracy 0.5232\n",
            "Epoch 10 Batch 3200 Loss 0.8067 Accuracy 0.5233\n",
            "Epoch 10 Batch 3250 Loss 0.8047 Accuracy 0.5235\n",
            "Epoch 10 Batch 3300 Loss 0.8028 Accuracy 0.5237\n",
            "Epoch 10 Batch 3350 Loss 0.8009 Accuracy 0.5240\n",
            "Epoch 10 Batch 3400 Loss 0.7994 Accuracy 0.5242\n",
            "Epoch 10 Batch 3450 Loss 0.7978 Accuracy 0.5244\n",
            "Epoch 10 Batch 3500 Loss 0.7960 Accuracy 0.5247\n",
            "Epoch 10 Batch 3550 Loss 0.7943 Accuracy 0.5250\n",
            "Epoch 10 Batch 3600 Loss 0.7927 Accuracy 0.5253\n",
            "Epoch 10 Batch 3650 Loss 0.7912 Accuracy 0.5257\n",
            "Epoch 10 Batch 3700 Loss 0.7901 Accuracy 0.5261\n",
            "Epoch 10 Batch 3750 Loss 0.7888 Accuracy 0.5264\n",
            "Epoch 10 Batch 3800 Loss 0.7874 Accuracy 0.5267\n",
            "Epoch 10 Batch 3850 Loss 0.7860 Accuracy 0.5269\n",
            "Epoch 10 Batch 3900 Loss 0.7847 Accuracy 0.5272\n",
            "Epoch 10 Batch 3950 Loss 0.7835 Accuracy 0.5276\n",
            "Epoch 10 Batch 4000 Loss 0.7823 Accuracy 0.5278\n",
            "Epoch 10 Batch 4050 Loss 0.7812 Accuracy 0.5281\n",
            "Epoch 10 Batch 4100 Loss 0.7801 Accuracy 0.5283\n",
            "Epoch 10 Batch 4150 Loss 0.7797 Accuracy 0.5283\n",
            "Epoch 10 Batch 4200 Loss 0.7801 Accuracy 0.5283\n",
            "Epoch 10 Batch 4250 Loss 0.7804 Accuracy 0.5283\n",
            "Epoch 10 Batch 4300 Loss 0.7815 Accuracy 0.5282\n",
            "Epoch 10 Batch 4350 Loss 0.7824 Accuracy 0.5281\n",
            "Epoch 10 Batch 4400 Loss 0.7833 Accuracy 0.5280\n",
            "Epoch 10 Batch 4450 Loss 0.7843 Accuracy 0.5277\n",
            "Epoch 10 Batch 4500 Loss 0.7859 Accuracy 0.5275\n",
            "Epoch 10 Batch 4550 Loss 0.7872 Accuracy 0.5273\n",
            "Epoch 10 Batch 4600 Loss 0.7888 Accuracy 0.5271\n",
            "Epoch 10 Batch 4650 Loss 0.7902 Accuracy 0.5269\n",
            "Epoch 10 Batch 4700 Loss 0.7915 Accuracy 0.5267\n",
            "Epoch 10 Batch 4750 Loss 0.7930 Accuracy 0.5265\n",
            "Epoch 10 Batch 4800 Loss 0.7941 Accuracy 0.5263\n",
            "Epoch 10 Batch 4850 Loss 0.7954 Accuracy 0.5262\n",
            "Epoch 10 Batch 4900 Loss 0.7966 Accuracy 0.5260\n",
            "Epoch 10 Batch 4950 Loss 0.7978 Accuracy 0.5258\n",
            "Epoch 10 Batch 5000 Loss 0.7992 Accuracy 0.5255\n",
            "Epoch 10 Batch 5050 Loss 0.8007 Accuracy 0.5253\n",
            "Epoch 10 Batch 5100 Loss 0.8022 Accuracy 0.5250\n",
            "Epoch 10 Batch 5150 Loss 0.8037 Accuracy 0.5248\n",
            "Epoch 10 Batch 5200 Loss 0.8050 Accuracy 0.5245\n",
            "Epoch 10 Batch 5250 Loss 0.8063 Accuracy 0.5242\n",
            "Epoch 10 Batch 5300 Loss 0.8075 Accuracy 0.5239\n",
            "Epoch 10 Batch 5350 Loss 0.8089 Accuracy 0.5236\n",
            "Epoch 10 Batch 5400 Loss 0.8101 Accuracy 0.5233\n",
            "Epoch 10 Batch 5450 Loss 0.8112 Accuracy 0.5230\n",
            "Epoch 10 Batch 5500 Loss 0.8123 Accuracy 0.5227\n",
            "Epoch 10 Batch 5550 Loss 0.8134 Accuracy 0.5225\n",
            "Epoch 10 Batch 5600 Loss 0.8143 Accuracy 0.5222\n",
            "Epoch 10 Batch 5650 Loss 0.8153 Accuracy 0.5219\n",
            "Epoch 10 Batch 5700 Loss 0.8161 Accuracy 0.5217\n",
            "Saving checkpoint for epoch 10 at ./drive/My Drive/projects/transformer/ckpt/ckpt-25\n",
            "Time taken for 1 epoch: 1418.7114162445068 secs\n",
            "\n",
            "Start of epoch 11\n",
            "Epoch 11 Batch 0 Loss 0.7998 Accuracy 0.4753\n",
            "Epoch 11 Batch 50 Loss 0.9241 Accuracy 0.4989\n",
            "Epoch 11 Batch 100 Loss 0.9102 Accuracy 0.5002\n",
            "Epoch 11 Batch 150 Loss 0.9074 Accuracy 0.5022\n",
            "Epoch 11 Batch 200 Loss 0.9105 Accuracy 0.5024\n",
            "Epoch 11 Batch 250 Loss 0.9126 Accuracy 0.5039\n",
            "Epoch 11 Batch 300 Loss 0.9116 Accuracy 0.5046\n",
            "Epoch 11 Batch 350 Loss 0.9147 Accuracy 0.5048\n",
            "Epoch 11 Batch 400 Loss 0.9119 Accuracy 0.5041\n",
            "Epoch 11 Batch 450 Loss 0.9086 Accuracy 0.5044\n",
            "Epoch 11 Batch 500 Loss 0.9094 Accuracy 0.5049\n",
            "Epoch 11 Batch 550 Loss 0.9091 Accuracy 0.5048\n",
            "Epoch 11 Batch 600 Loss 0.9071 Accuracy 0.5049\n",
            "Epoch 11 Batch 650 Loss 0.9074 Accuracy 0.5052\n",
            "Epoch 11 Batch 700 Loss 0.9051 Accuracy 0.5052\n",
            "Epoch 11 Batch 750 Loss 0.9042 Accuracy 0.5053\n",
            "Epoch 11 Batch 800 Loss 0.9031 Accuracy 0.5056\n",
            "Epoch 11 Batch 850 Loss 0.9024 Accuracy 0.5059\n",
            "Epoch 11 Batch 900 Loss 0.9006 Accuracy 0.5055\n",
            "Epoch 11 Batch 950 Loss 0.8993 Accuracy 0.5055\n",
            "Epoch 11 Batch 1000 Loss 0.8968 Accuracy 0.5056\n",
            "Epoch 11 Batch 1050 Loss 0.8960 Accuracy 0.5058\n",
            "Epoch 11 Batch 1100 Loss 0.8955 Accuracy 0.5062\n",
            "Epoch 11 Batch 1150 Loss 0.8948 Accuracy 0.5063\n",
            "Epoch 11 Batch 1200 Loss 0.8926 Accuracy 0.5066\n",
            "Epoch 11 Batch 1250 Loss 0.8906 Accuracy 0.5070\n",
            "Epoch 11 Batch 1300 Loss 0.8894 Accuracy 0.5073\n",
            "Epoch 11 Batch 1350 Loss 0.8870 Accuracy 0.5079\n",
            "Epoch 11 Batch 1400 Loss 0.8839 Accuracy 0.5085\n",
            "Epoch 11 Batch 1450 Loss 0.8816 Accuracy 0.5092\n",
            "Epoch 11 Batch 1500 Loss 0.8792 Accuracy 0.5099\n",
            "Epoch 11 Batch 1550 Loss 0.8764 Accuracy 0.5109\n",
            "Epoch 11 Batch 1600 Loss 0.8742 Accuracy 0.5116\n",
            "Epoch 11 Batch 1650 Loss 0.8720 Accuracy 0.5124\n",
            "Epoch 11 Batch 1700 Loss 0.8698 Accuracy 0.5131\n",
            "Epoch 11 Batch 1750 Loss 0.8678 Accuracy 0.5138\n",
            "Epoch 11 Batch 1800 Loss 0.8653 Accuracy 0.5146\n",
            "Epoch 11 Batch 1850 Loss 0.8631 Accuracy 0.5156\n",
            "Epoch 11 Batch 1900 Loss 0.8612 Accuracy 0.5163\n",
            "Epoch 11 Batch 1950 Loss 0.8590 Accuracy 0.5170\n",
            "Epoch 11 Batch 2000 Loss 0.8572 Accuracy 0.5176\n",
            "Epoch 11 Batch 2050 Loss 0.8552 Accuracy 0.5182\n",
            "Epoch 11 Batch 2100 Loss 0.8532 Accuracy 0.5185\n",
            "Epoch 11 Batch 2150 Loss 0.8508 Accuracy 0.5189\n",
            "Epoch 11 Batch 2200 Loss 0.8477 Accuracy 0.5191\n",
            "Epoch 11 Batch 2250 Loss 0.8447 Accuracy 0.5192\n",
            "Epoch 11 Batch 2300 Loss 0.8417 Accuracy 0.5193\n",
            "Epoch 11 Batch 2350 Loss 0.8387 Accuracy 0.5195\n",
            "Epoch 11 Batch 2400 Loss 0.8359 Accuracy 0.5198\n",
            "Epoch 11 Batch 2450 Loss 0.8336 Accuracy 0.5200\n",
            "Epoch 11 Batch 2500 Loss 0.8309 Accuracy 0.5204\n",
            "Epoch 11 Batch 2550 Loss 0.8283 Accuracy 0.5206\n",
            "Epoch 11 Batch 2600 Loss 0.8261 Accuracy 0.5208\n",
            "Epoch 11 Batch 2650 Loss 0.8235 Accuracy 0.5213\n",
            "Epoch 11 Batch 2700 Loss 0.8211 Accuracy 0.5216\n",
            "Epoch 11 Batch 2750 Loss 0.8191 Accuracy 0.5218\n",
            "Epoch 11 Batch 2800 Loss 0.8170 Accuracy 0.5221\n",
            "Epoch 11 Batch 2850 Loss 0.8151 Accuracy 0.5223\n",
            "Epoch 11 Batch 2900 Loss 0.8131 Accuracy 0.5225\n",
            "Epoch 11 Batch 2950 Loss 0.8113 Accuracy 0.5228\n",
            "Epoch 11 Batch 3000 Loss 0.8096 Accuracy 0.5229\n",
            "Epoch 11 Batch 3050 Loss 0.8079 Accuracy 0.5232\n",
            "Epoch 11 Batch 3100 Loss 0.8064 Accuracy 0.5235\n",
            "Epoch 11 Batch 3150 Loss 0.8048 Accuracy 0.5237\n",
            "Epoch 11 Batch 3200 Loss 0.8032 Accuracy 0.5238\n",
            "Epoch 11 Batch 3250 Loss 0.8014 Accuracy 0.5240\n",
            "Epoch 11 Batch 3300 Loss 0.7996 Accuracy 0.5242\n",
            "Epoch 11 Batch 3350 Loss 0.7977 Accuracy 0.5245\n",
            "Epoch 11 Batch 3400 Loss 0.7961 Accuracy 0.5249\n",
            "Epoch 11 Batch 3450 Loss 0.7943 Accuracy 0.5251\n",
            "Epoch 11 Batch 3500 Loss 0.7927 Accuracy 0.5254\n",
            "Epoch 11 Batch 3550 Loss 0.7912 Accuracy 0.5256\n",
            "Epoch 11 Batch 3600 Loss 0.7893 Accuracy 0.5259\n",
            "Epoch 11 Batch 3650 Loss 0.7875 Accuracy 0.5262\n",
            "Epoch 11 Batch 3700 Loss 0.7860 Accuracy 0.5265\n",
            "Epoch 11 Batch 3750 Loss 0.7846 Accuracy 0.5268\n",
            "Epoch 11 Batch 3800 Loss 0.7833 Accuracy 0.5271\n",
            "Epoch 11 Batch 3850 Loss 0.7820 Accuracy 0.5275\n",
            "Epoch 11 Batch 3900 Loss 0.7808 Accuracy 0.5278\n",
            "Epoch 11 Batch 3950 Loss 0.7797 Accuracy 0.5281\n",
            "Epoch 11 Batch 4000 Loss 0.7785 Accuracy 0.5284\n",
            "Epoch 11 Batch 4050 Loss 0.7777 Accuracy 0.5287\n",
            "Epoch 11 Batch 4100 Loss 0.7766 Accuracy 0.5289\n",
            "Epoch 11 Batch 4150 Loss 0.7764 Accuracy 0.5289\n",
            "Epoch 11 Batch 4200 Loss 0.7767 Accuracy 0.5289\n",
            "Epoch 11 Batch 4250 Loss 0.7771 Accuracy 0.5289\n",
            "Epoch 11 Batch 4300 Loss 0.7779 Accuracy 0.5288\n",
            "Epoch 11 Batch 4350 Loss 0.7790 Accuracy 0.5286\n",
            "Epoch 11 Batch 4400 Loss 0.7800 Accuracy 0.5285\n",
            "Epoch 11 Batch 4450 Loss 0.7814 Accuracy 0.5282\n",
            "Epoch 11 Batch 4500 Loss 0.7827 Accuracy 0.5279\n",
            "Epoch 11 Batch 4550 Loss 0.7838 Accuracy 0.5278\n",
            "Epoch 11 Batch 4600 Loss 0.7850 Accuracy 0.5276\n",
            "Epoch 11 Batch 4650 Loss 0.7864 Accuracy 0.5275\n",
            "Epoch 11 Batch 4700 Loss 0.7878 Accuracy 0.5273\n",
            "Epoch 11 Batch 4750 Loss 0.7890 Accuracy 0.5271\n",
            "Epoch 11 Batch 4800 Loss 0.7903 Accuracy 0.5269\n",
            "Epoch 11 Batch 4850 Loss 0.7916 Accuracy 0.5267\n",
            "Epoch 11 Batch 4900 Loss 0.7931 Accuracy 0.5265\n",
            "Epoch 11 Batch 4950 Loss 0.7945 Accuracy 0.5263\n",
            "Epoch 11 Batch 5000 Loss 0.7962 Accuracy 0.5261\n",
            "Epoch 11 Batch 5050 Loss 0.7975 Accuracy 0.5259\n",
            "Epoch 11 Batch 5100 Loss 0.7989 Accuracy 0.5256\n",
            "Epoch 11 Batch 5150 Loss 0.8003 Accuracy 0.5253\n",
            "Epoch 11 Batch 5200 Loss 0.8016 Accuracy 0.5250\n",
            "Epoch 11 Batch 5250 Loss 0.8027 Accuracy 0.5247\n",
            "Epoch 11 Batch 5300 Loss 0.8040 Accuracy 0.5245\n",
            "Epoch 11 Batch 5350 Loss 0.8053 Accuracy 0.5242\n",
            "Epoch 11 Batch 5400 Loss 0.8063 Accuracy 0.5239\n",
            "Epoch 11 Batch 5450 Loss 0.8073 Accuracy 0.5236\n",
            "Epoch 11 Batch 5500 Loss 0.8086 Accuracy 0.5234\n",
            "Epoch 11 Batch 5550 Loss 0.8094 Accuracy 0.5231\n",
            "Epoch 11 Batch 5600 Loss 0.8105 Accuracy 0.5228\n",
            "Epoch 11 Batch 5650 Loss 0.8116 Accuracy 0.5226\n",
            "Epoch 11 Batch 5700 Loss 0.8125 Accuracy 0.5223\n",
            "Saving checkpoint for epoch 11 at ./drive/My Drive/projects/transformer/ckpt/ckpt-26\n",
            "Time taken for 1 epoch: 1427.681283712387 secs\n",
            "\n",
            "Start of epoch 12\n",
            "Epoch 12 Batch 0 Loss 0.9480 Accuracy 0.4729\n",
            "Epoch 12 Batch 50 Loss 0.9101 Accuracy 0.4973\n",
            "Epoch 12 Batch 100 Loss 0.9061 Accuracy 0.5023\n",
            "Epoch 12 Batch 150 Loss 0.9125 Accuracy 0.5033\n",
            "Epoch 12 Batch 200 Loss 0.9143 Accuracy 0.5041\n",
            "Epoch 12 Batch 250 Loss 0.9125 Accuracy 0.5035\n",
            "Epoch 12 Batch 300 Loss 0.9089 Accuracy 0.5053\n",
            "Epoch 12 Batch 350 Loss 0.9047 Accuracy 0.5057\n",
            "Epoch 12 Batch 400 Loss 0.8997 Accuracy 0.5057\n",
            "Epoch 12 Batch 450 Loss 0.9002 Accuracy 0.5056\n",
            "Epoch 12 Batch 500 Loss 0.8982 Accuracy 0.5057\n",
            "Epoch 12 Batch 550 Loss 0.8973 Accuracy 0.5051\n",
            "Epoch 12 Batch 600 Loss 0.8978 Accuracy 0.5051\n",
            "Epoch 12 Batch 650 Loss 0.8978 Accuracy 0.5051\n",
            "Epoch 12 Batch 700 Loss 0.8968 Accuracy 0.5054\n",
            "Epoch 12 Batch 750 Loss 0.8964 Accuracy 0.5055\n",
            "Epoch 12 Batch 800 Loss 0.8966 Accuracy 0.5056\n",
            "Epoch 12 Batch 850 Loss 0.8960 Accuracy 0.5058\n",
            "Epoch 12 Batch 900 Loss 0.8955 Accuracy 0.5059\n",
            "Epoch 12 Batch 950 Loss 0.8950 Accuracy 0.5060\n",
            "Epoch 12 Batch 1000 Loss 0.8934 Accuracy 0.5063\n",
            "Epoch 12 Batch 1050 Loss 0.8923 Accuracy 0.5063\n",
            "Epoch 12 Batch 1100 Loss 0.8913 Accuracy 0.5064\n",
            "Epoch 12 Batch 1150 Loss 0.8902 Accuracy 0.5067\n",
            "Epoch 12 Batch 1200 Loss 0.8888 Accuracy 0.5070\n",
            "Epoch 12 Batch 1250 Loss 0.8869 Accuracy 0.5072\n",
            "Epoch 12 Batch 1300 Loss 0.8850 Accuracy 0.5076\n",
            "Epoch 12 Batch 1350 Loss 0.8835 Accuracy 0.5083\n",
            "Epoch 12 Batch 1400 Loss 0.8816 Accuracy 0.5090\n",
            "Epoch 12 Batch 1450 Loss 0.8790 Accuracy 0.5098\n",
            "Epoch 12 Batch 1500 Loss 0.8766 Accuracy 0.5104\n",
            "Epoch 12 Batch 1550 Loss 0.8736 Accuracy 0.5113\n",
            "Epoch 12 Batch 1600 Loss 0.8709 Accuracy 0.5121\n",
            "Epoch 12 Batch 1650 Loss 0.8681 Accuracy 0.5129\n",
            "Epoch 12 Batch 1700 Loss 0.8656 Accuracy 0.5136\n",
            "Epoch 12 Batch 1750 Loss 0.8633 Accuracy 0.5144\n",
            "Epoch 12 Batch 1800 Loss 0.8613 Accuracy 0.5153\n",
            "Epoch 12 Batch 1850 Loss 0.8589 Accuracy 0.5162\n",
            "Epoch 12 Batch 1900 Loss 0.8561 Accuracy 0.5170\n",
            "Epoch 12 Batch 1950 Loss 0.8541 Accuracy 0.5175\n",
            "Epoch 12 Batch 2000 Loss 0.8521 Accuracy 0.5181\n",
            "Epoch 12 Batch 2050 Loss 0.8500 Accuracy 0.5186\n",
            "Epoch 12 Batch 2100 Loss 0.8477 Accuracy 0.5190\n",
            "Epoch 12 Batch 2150 Loss 0.8453 Accuracy 0.5192\n",
            "Epoch 12 Batch 2200 Loss 0.8423 Accuracy 0.5195\n",
            "Epoch 12 Batch 2250 Loss 0.8395 Accuracy 0.5198\n",
            "Epoch 12 Batch 2300 Loss 0.8372 Accuracy 0.5199\n",
            "Epoch 12 Batch 2350 Loss 0.8344 Accuracy 0.5202\n",
            "Epoch 12 Batch 2400 Loss 0.8319 Accuracy 0.5205\n",
            "Epoch 12 Batch 2450 Loss 0.8294 Accuracy 0.5207\n",
            "Epoch 12 Batch 2500 Loss 0.8270 Accuracy 0.5209\n",
            "Epoch 12 Batch 2550 Loss 0.8246 Accuracy 0.5212\n",
            "Epoch 12 Batch 2600 Loss 0.8221 Accuracy 0.5214\n",
            "Epoch 12 Batch 2650 Loss 0.8198 Accuracy 0.5216\n",
            "Epoch 12 Batch 2700 Loss 0.8174 Accuracy 0.5219\n",
            "Epoch 12 Batch 2750 Loss 0.8155 Accuracy 0.5221\n",
            "Epoch 12 Batch 2800 Loss 0.8137 Accuracy 0.5224\n",
            "Epoch 12 Batch 2850 Loss 0.8117 Accuracy 0.5226\n",
            "Epoch 12 Batch 2900 Loss 0.8097 Accuracy 0.5229\n",
            "Epoch 12 Batch 2950 Loss 0.8077 Accuracy 0.5232\n",
            "Epoch 12 Batch 3000 Loss 0.8061 Accuracy 0.5234\n",
            "Epoch 12 Batch 3050 Loss 0.8043 Accuracy 0.5237\n",
            "Epoch 12 Batch 3100 Loss 0.8025 Accuracy 0.5239\n",
            "Epoch 12 Batch 3150 Loss 0.8007 Accuracy 0.5242\n",
            "Epoch 12 Batch 3200 Loss 0.7992 Accuracy 0.5244\n",
            "Epoch 12 Batch 3250 Loss 0.7976 Accuracy 0.5247\n",
            "Epoch 12 Batch 3300 Loss 0.7958 Accuracy 0.5248\n",
            "Epoch 12 Batch 3350 Loss 0.7939 Accuracy 0.5251\n",
            "Epoch 12 Batch 3400 Loss 0.7924 Accuracy 0.5254\n",
            "Epoch 12 Batch 3450 Loss 0.7908 Accuracy 0.5256\n",
            "Epoch 12 Batch 3500 Loss 0.7889 Accuracy 0.5258\n",
            "Epoch 12 Batch 3550 Loss 0.7875 Accuracy 0.5261\n",
            "Epoch 12 Batch 3600 Loss 0.7859 Accuracy 0.5265\n",
            "Epoch 12 Batch 3650 Loss 0.7842 Accuracy 0.5267\n",
            "Epoch 12 Batch 3700 Loss 0.7828 Accuracy 0.5271\n",
            "Epoch 12 Batch 3750 Loss 0.7814 Accuracy 0.5273\n",
            "Epoch 12 Batch 3800 Loss 0.7798 Accuracy 0.5277\n",
            "Epoch 12 Batch 3850 Loss 0.7786 Accuracy 0.5281\n",
            "Epoch 12 Batch 3900 Loss 0.7773 Accuracy 0.5284\n",
            "Epoch 12 Batch 3950 Loss 0.7762 Accuracy 0.5288\n",
            "Epoch 12 Batch 4000 Loss 0.7753 Accuracy 0.5290\n",
            "Epoch 12 Batch 4050 Loss 0.7743 Accuracy 0.5293\n",
            "Epoch 12 Batch 4100 Loss 0.7733 Accuracy 0.5294\n",
            "Epoch 12 Batch 4150 Loss 0.7729 Accuracy 0.5295\n",
            "Epoch 12 Batch 4200 Loss 0.7731 Accuracy 0.5295\n",
            "Epoch 12 Batch 4250 Loss 0.7736 Accuracy 0.5295\n",
            "Epoch 12 Batch 4300 Loss 0.7746 Accuracy 0.5294\n",
            "Epoch 12 Batch 4350 Loss 0.7757 Accuracy 0.5293\n",
            "Epoch 12 Batch 4400 Loss 0.7768 Accuracy 0.5291\n",
            "Epoch 12 Batch 4450 Loss 0.7781 Accuracy 0.5289\n",
            "Epoch 12 Batch 4500 Loss 0.7792 Accuracy 0.5287\n",
            "Epoch 12 Batch 4550 Loss 0.7807 Accuracy 0.5285\n",
            "Epoch 12 Batch 4600 Loss 0.7822 Accuracy 0.5283\n",
            "Epoch 12 Batch 4650 Loss 0.7835 Accuracy 0.5281\n",
            "Epoch 12 Batch 4700 Loss 0.7849 Accuracy 0.5279\n",
            "Epoch 12 Batch 4750 Loss 0.7864 Accuracy 0.5277\n",
            "Epoch 12 Batch 4800 Loss 0.7875 Accuracy 0.5274\n",
            "Epoch 12 Batch 4850 Loss 0.7887 Accuracy 0.5272\n",
            "Epoch 12 Batch 4900 Loss 0.7898 Accuracy 0.5270\n",
            "Epoch 12 Batch 4950 Loss 0.7912 Accuracy 0.5268\n",
            "Epoch 12 Batch 5000 Loss 0.7927 Accuracy 0.5266\n",
            "Epoch 12 Batch 5050 Loss 0.7941 Accuracy 0.5264\n",
            "Epoch 12 Batch 5100 Loss 0.7954 Accuracy 0.5261\n",
            "Epoch 12 Batch 5150 Loss 0.7966 Accuracy 0.5258\n",
            "Epoch 12 Batch 5200 Loss 0.7978 Accuracy 0.5256\n",
            "Epoch 12 Batch 5250 Loss 0.7990 Accuracy 0.5253\n",
            "Epoch 12 Batch 5300 Loss 0.8002 Accuracy 0.5250\n",
            "Epoch 12 Batch 5350 Loss 0.8014 Accuracy 0.5247\n",
            "Epoch 12 Batch 5400 Loss 0.8027 Accuracy 0.5244\n",
            "Epoch 12 Batch 5450 Loss 0.8038 Accuracy 0.5242\n",
            "Epoch 12 Batch 5500 Loss 0.8048 Accuracy 0.5239\n",
            "Epoch 12 Batch 5550 Loss 0.8060 Accuracy 0.5236\n",
            "Epoch 12 Batch 5600 Loss 0.8068 Accuracy 0.5234\n",
            "Epoch 12 Batch 5650 Loss 0.8079 Accuracy 0.5231\n",
            "Epoch 12 Batch 5700 Loss 0.8090 Accuracy 0.5229\n",
            "Saving checkpoint for epoch 12 at ./drive/My Drive/projects/transformer/ckpt/ckpt-27\n",
            "Time taken for 1 epoch: 1424.2260043621063 secs\n",
            "\n",
            "Start of epoch 13\n",
            "Epoch 13 Batch 0 Loss 0.8893 Accuracy 0.4844\n",
            "Epoch 13 Batch 50 Loss 0.9124 Accuracy 0.5091\n",
            "Epoch 13 Batch 100 Loss 0.9130 Accuracy 0.5076\n",
            "Epoch 13 Batch 150 Loss 0.9114 Accuracy 0.5072\n",
            "Epoch 13 Batch 200 Loss 0.9039 Accuracy 0.5055\n",
            "Epoch 13 Batch 250 Loss 0.9037 Accuracy 0.5064\n",
            "Epoch 13 Batch 300 Loss 0.9039 Accuracy 0.5059\n",
            "Epoch 13 Batch 350 Loss 0.9034 Accuracy 0.5056\n",
            "Epoch 13 Batch 400 Loss 0.9019 Accuracy 0.5056\n",
            "Epoch 13 Batch 450 Loss 0.9007 Accuracy 0.5057\n",
            "Epoch 13 Batch 500 Loss 0.9001 Accuracy 0.5052\n",
            "Epoch 13 Batch 550 Loss 0.8988 Accuracy 0.5054\n",
            "Epoch 13 Batch 600 Loss 0.8978 Accuracy 0.5055\n",
            "Epoch 13 Batch 650 Loss 0.8969 Accuracy 0.5056\n",
            "Epoch 13 Batch 700 Loss 0.8967 Accuracy 0.5058\n",
            "Epoch 13 Batch 750 Loss 0.8961 Accuracy 0.5060\n",
            "Epoch 13 Batch 800 Loss 0.8963 Accuracy 0.5064\n",
            "Epoch 13 Batch 850 Loss 0.8951 Accuracy 0.5068\n",
            "Epoch 13 Batch 900 Loss 0.8934 Accuracy 0.5070\n",
            "Epoch 13 Batch 950 Loss 0.8913 Accuracy 0.5069\n",
            "Epoch 13 Batch 1000 Loss 0.8903 Accuracy 0.5074\n",
            "Epoch 13 Batch 1050 Loss 0.8894 Accuracy 0.5071\n",
            "Epoch 13 Batch 1100 Loss 0.8886 Accuracy 0.5072\n",
            "Epoch 13 Batch 1150 Loss 0.8871 Accuracy 0.5073\n",
            "Epoch 13 Batch 1200 Loss 0.8847 Accuracy 0.5075\n",
            "Epoch 13 Batch 1250 Loss 0.8831 Accuracy 0.5078\n",
            "Epoch 13 Batch 1300 Loss 0.8805 Accuracy 0.5083\n",
            "Epoch 13 Batch 1350 Loss 0.8777 Accuracy 0.5089\n",
            "Epoch 13 Batch 1400 Loss 0.8754 Accuracy 0.5097\n",
            "Epoch 13 Batch 1450 Loss 0.8729 Accuracy 0.5104\n",
            "Epoch 13 Batch 1500 Loss 0.8707 Accuracy 0.5113\n",
            "Epoch 13 Batch 1550 Loss 0.8683 Accuracy 0.5121\n",
            "Epoch 13 Batch 1600 Loss 0.8659 Accuracy 0.5130\n",
            "Epoch 13 Batch 1650 Loss 0.8643 Accuracy 0.5138\n",
            "Epoch 13 Batch 1700 Loss 0.8617 Accuracy 0.5146\n",
            "Epoch 13 Batch 1750 Loss 0.8591 Accuracy 0.5155\n",
            "Epoch 13 Batch 1800 Loss 0.8571 Accuracy 0.5163\n",
            "Epoch 13 Batch 1850 Loss 0.8549 Accuracy 0.5171\n",
            "Epoch 13 Batch 1900 Loss 0.8528 Accuracy 0.5180\n",
            "Epoch 13 Batch 1950 Loss 0.8511 Accuracy 0.5187\n",
            "Epoch 13 Batch 2000 Loss 0.8494 Accuracy 0.5193\n",
            "Epoch 13 Batch 2050 Loss 0.8474 Accuracy 0.5198\n",
            "Epoch 13 Batch 2100 Loss 0.8449 Accuracy 0.5201\n",
            "Epoch 13 Batch 2150 Loss 0.8428 Accuracy 0.5203\n",
            "Epoch 13 Batch 2200 Loss 0.8401 Accuracy 0.5205\n",
            "Epoch 13 Batch 2250 Loss 0.8375 Accuracy 0.5207\n",
            "Epoch 13 Batch 2300 Loss 0.8346 Accuracy 0.5209\n",
            "Epoch 13 Batch 2350 Loss 0.8320 Accuracy 0.5211\n",
            "Epoch 13 Batch 2400 Loss 0.8292 Accuracy 0.5214\n",
            "Epoch 13 Batch 2450 Loss 0.8269 Accuracy 0.5217\n",
            "Epoch 13 Batch 2500 Loss 0.8245 Accuracy 0.5219\n",
            "Epoch 13 Batch 2550 Loss 0.8218 Accuracy 0.5221\n",
            "Epoch 13 Batch 2600 Loss 0.8192 Accuracy 0.5223\n",
            "Epoch 13 Batch 2650 Loss 0.8166 Accuracy 0.5226\n",
            "Epoch 13 Batch 2700 Loss 0.8140 Accuracy 0.5229\n",
            "Epoch 13 Batch 2750 Loss 0.8119 Accuracy 0.5232\n",
            "Epoch 13 Batch 2800 Loss 0.8102 Accuracy 0.5235\n",
            "Epoch 13 Batch 2850 Loss 0.8080 Accuracy 0.5239\n",
            "Epoch 13 Batch 2900 Loss 0.8063 Accuracy 0.5241\n",
            "Epoch 13 Batch 2950 Loss 0.8046 Accuracy 0.5243\n",
            "Epoch 13 Batch 3000 Loss 0.8028 Accuracy 0.5245\n",
            "Epoch 13 Batch 3050 Loss 0.8010 Accuracy 0.5247\n",
            "Epoch 13 Batch 3100 Loss 0.7994 Accuracy 0.5249\n",
            "Epoch 13 Batch 3150 Loss 0.7980 Accuracy 0.5250\n",
            "Epoch 13 Batch 3200 Loss 0.7963 Accuracy 0.5252\n",
            "Epoch 13 Batch 3250 Loss 0.7947 Accuracy 0.5253\n",
            "Epoch 13 Batch 3300 Loss 0.7928 Accuracy 0.5256\n",
            "Epoch 13 Batch 3350 Loss 0.7909 Accuracy 0.5258\n",
            "Epoch 13 Batch 3400 Loss 0.7894 Accuracy 0.5261\n",
            "Epoch 13 Batch 3450 Loss 0.7876 Accuracy 0.5264\n",
            "Epoch 13 Batch 3500 Loss 0.7859 Accuracy 0.5268\n",
            "Epoch 13 Batch 3550 Loss 0.7845 Accuracy 0.5271\n",
            "Epoch 13 Batch 3600 Loss 0.7830 Accuracy 0.5274\n",
            "Epoch 13 Batch 3650 Loss 0.7812 Accuracy 0.5277\n",
            "Epoch 13 Batch 3700 Loss 0.7796 Accuracy 0.5280\n",
            "Epoch 13 Batch 3750 Loss 0.7782 Accuracy 0.5283\n",
            "Epoch 13 Batch 3800 Loss 0.7769 Accuracy 0.5285\n",
            "Epoch 13 Batch 3850 Loss 0.7758 Accuracy 0.5288\n",
            "Epoch 13 Batch 3900 Loss 0.7746 Accuracy 0.5291\n",
            "Epoch 13 Batch 3950 Loss 0.7735 Accuracy 0.5294\n",
            "Epoch 13 Batch 4000 Loss 0.7721 Accuracy 0.5298\n",
            "Epoch 13 Batch 4050 Loss 0.7710 Accuracy 0.5300\n",
            "Epoch 13 Batch 4100 Loss 0.7703 Accuracy 0.5302\n",
            "Epoch 13 Batch 4150 Loss 0.7697 Accuracy 0.5303\n",
            "Epoch 13 Batch 4200 Loss 0.7701 Accuracy 0.5302\n",
            "Epoch 13 Batch 4250 Loss 0.7708 Accuracy 0.5302\n",
            "Epoch 13 Batch 4300 Loss 0.7715 Accuracy 0.5301\n",
            "Epoch 13 Batch 4350 Loss 0.7724 Accuracy 0.5300\n",
            "Epoch 13 Batch 4400 Loss 0.7736 Accuracy 0.5297\n",
            "Epoch 13 Batch 4450 Loss 0.7749 Accuracy 0.5296\n",
            "Epoch 13 Batch 4500 Loss 0.7762 Accuracy 0.5294\n",
            "Epoch 13 Batch 4550 Loss 0.7775 Accuracy 0.5293\n",
            "Epoch 13 Batch 4600 Loss 0.7790 Accuracy 0.5291\n",
            "Epoch 13 Batch 4650 Loss 0.7803 Accuracy 0.5288\n",
            "Epoch 13 Batch 4700 Loss 0.7818 Accuracy 0.5286\n",
            "Epoch 13 Batch 4750 Loss 0.7831 Accuracy 0.5285\n",
            "Epoch 13 Batch 4800 Loss 0.7844 Accuracy 0.5282\n",
            "Epoch 13 Batch 4850 Loss 0.7857 Accuracy 0.5279\n",
            "Epoch 13 Batch 4900 Loss 0.7870 Accuracy 0.5277\n",
            "Epoch 13 Batch 4950 Loss 0.7884 Accuracy 0.5275\n",
            "Epoch 13 Batch 5000 Loss 0.7897 Accuracy 0.5273\n",
            "Epoch 13 Batch 5050 Loss 0.7909 Accuracy 0.5271\n",
            "Epoch 13 Batch 5100 Loss 0.7923 Accuracy 0.5268\n",
            "Epoch 13 Batch 5150 Loss 0.7937 Accuracy 0.5266\n",
            "Epoch 13 Batch 5200 Loss 0.7949 Accuracy 0.5263\n",
            "Epoch 13 Batch 5250 Loss 0.7961 Accuracy 0.5261\n",
            "Epoch 13 Batch 5300 Loss 0.7971 Accuracy 0.5257\n",
            "Epoch 13 Batch 5350 Loss 0.7984 Accuracy 0.5254\n",
            "Epoch 13 Batch 5400 Loss 0.7998 Accuracy 0.5251\n",
            "Epoch 13 Batch 5450 Loss 0.8008 Accuracy 0.5249\n",
            "Epoch 13 Batch 5500 Loss 0.8020 Accuracy 0.5246\n",
            "Epoch 13 Batch 5550 Loss 0.8029 Accuracy 0.5243\n",
            "Epoch 13 Batch 5600 Loss 0.8038 Accuracy 0.5240\n",
            "Epoch 13 Batch 5650 Loss 0.8048 Accuracy 0.5238\n",
            "Epoch 13 Batch 5700 Loss 0.8057 Accuracy 0.5236\n",
            "Saving checkpoint for epoch 13 at ./drive/My Drive/projects/transformer/ckpt/ckpt-28\n",
            "Time taken for 1 epoch: 1425.835440158844 secs\n",
            "\n",
            "Start of epoch 14\n",
            "Epoch 14 Batch 0 Loss 1.0189 Accuracy 0.4803\n",
            "Epoch 14 Batch 50 Loss 0.9189 Accuracy 0.5005\n",
            "Epoch 14 Batch 100 Loss 0.9084 Accuracy 0.5016\n",
            "Epoch 14 Batch 150 Loss 0.9062 Accuracy 0.5017\n",
            "Epoch 14 Batch 200 Loss 0.9046 Accuracy 0.5037\n",
            "Epoch 14 Batch 250 Loss 0.9020 Accuracy 0.5047\n",
            "Epoch 14 Batch 300 Loss 0.9016 Accuracy 0.5052\n",
            "Epoch 14 Batch 350 Loss 0.8995 Accuracy 0.5050\n",
            "Epoch 14 Batch 400 Loss 0.8995 Accuracy 0.5061\n",
            "Epoch 14 Batch 450 Loss 0.8968 Accuracy 0.5061\n",
            "Epoch 14 Batch 500 Loss 0.8962 Accuracy 0.5064\n",
            "Epoch 14 Batch 550 Loss 0.8943 Accuracy 0.5066\n",
            "Epoch 14 Batch 600 Loss 0.8938 Accuracy 0.5065\n",
            "Epoch 14 Batch 650 Loss 0.8929 Accuracy 0.5066\n",
            "Epoch 14 Batch 700 Loss 0.8910 Accuracy 0.5071\n",
            "Epoch 14 Batch 750 Loss 0.8911 Accuracy 0.5075\n",
            "Epoch 14 Batch 800 Loss 0.8911 Accuracy 0.5074\n",
            "Epoch 14 Batch 850 Loss 0.8914 Accuracy 0.5077\n",
            "Epoch 14 Batch 900 Loss 0.8906 Accuracy 0.5076\n",
            "Epoch 14 Batch 950 Loss 0.8889 Accuracy 0.5075\n",
            "Epoch 14 Batch 1000 Loss 0.8866 Accuracy 0.5078\n",
            "Epoch 14 Batch 1050 Loss 0.8863 Accuracy 0.5078\n",
            "Epoch 14 Batch 1100 Loss 0.8861 Accuracy 0.5078\n",
            "Epoch 14 Batch 1150 Loss 0.8852 Accuracy 0.5080\n",
            "Epoch 14 Batch 1200 Loss 0.8826 Accuracy 0.5084\n",
            "Epoch 14 Batch 1250 Loss 0.8806 Accuracy 0.5088\n",
            "Epoch 14 Batch 1300 Loss 0.8785 Accuracy 0.5093\n",
            "Epoch 14 Batch 1350 Loss 0.8769 Accuracy 0.5097\n",
            "Epoch 14 Batch 1400 Loss 0.8743 Accuracy 0.5105\n",
            "Epoch 14 Batch 1450 Loss 0.8719 Accuracy 0.5112\n",
            "Epoch 14 Batch 1500 Loss 0.8694 Accuracy 0.5122\n",
            "Epoch 14 Batch 1550 Loss 0.8666 Accuracy 0.5129\n",
            "Epoch 14 Batch 1600 Loss 0.8641 Accuracy 0.5138\n",
            "Epoch 14 Batch 1650 Loss 0.8622 Accuracy 0.5145\n",
            "Epoch 14 Batch 1700 Loss 0.8595 Accuracy 0.5153\n",
            "Epoch 14 Batch 1750 Loss 0.8567 Accuracy 0.5159\n",
            "Epoch 14 Batch 1800 Loss 0.8547 Accuracy 0.5167\n",
            "Epoch 14 Batch 1850 Loss 0.8521 Accuracy 0.5173\n",
            "Epoch 14 Batch 1900 Loss 0.8500 Accuracy 0.5180\n",
            "Epoch 14 Batch 1950 Loss 0.8481 Accuracy 0.5188\n",
            "Epoch 14 Batch 2000 Loss 0.8461 Accuracy 0.5194\n",
            "Epoch 14 Batch 2050 Loss 0.8438 Accuracy 0.5198\n",
            "Epoch 14 Batch 2100 Loss 0.8419 Accuracy 0.5202\n",
            "Epoch 14 Batch 2150 Loss 0.8396 Accuracy 0.5205\n",
            "Epoch 14 Batch 2200 Loss 0.8364 Accuracy 0.5206\n",
            "Epoch 14 Batch 2250 Loss 0.8338 Accuracy 0.5207\n",
            "Epoch 14 Batch 2300 Loss 0.8310 Accuracy 0.5210\n",
            "Epoch 14 Batch 2350 Loss 0.8284 Accuracy 0.5211\n",
            "Epoch 14 Batch 2400 Loss 0.8259 Accuracy 0.5214\n",
            "Epoch 14 Batch 2450 Loss 0.8234 Accuracy 0.5214\n",
            "Epoch 14 Batch 2500 Loss 0.8208 Accuracy 0.5217\n",
            "Epoch 14 Batch 2550 Loss 0.8182 Accuracy 0.5221\n",
            "Epoch 14 Batch 2600 Loss 0.8159 Accuracy 0.5225\n",
            "Epoch 14 Batch 2650 Loss 0.8134 Accuracy 0.5228\n",
            "Epoch 14 Batch 2700 Loss 0.8109 Accuracy 0.5230\n",
            "Epoch 14 Batch 2750 Loss 0.8085 Accuracy 0.5233\n",
            "Epoch 14 Batch 2800 Loss 0.8067 Accuracy 0.5236\n",
            "Epoch 14 Batch 2850 Loss 0.8046 Accuracy 0.5238\n",
            "Epoch 14 Batch 2900 Loss 0.8032 Accuracy 0.5240\n",
            "Epoch 14 Batch 2950 Loss 0.8021 Accuracy 0.5242\n",
            "Epoch 14 Batch 3000 Loss 0.8001 Accuracy 0.5246\n",
            "Epoch 14 Batch 3050 Loss 0.7983 Accuracy 0.5248\n",
            "Epoch 14 Batch 3100 Loss 0.7965 Accuracy 0.5252\n",
            "Epoch 14 Batch 3150 Loss 0.7946 Accuracy 0.5254\n",
            "Epoch 14 Batch 3200 Loss 0.7931 Accuracy 0.5256\n",
            "Epoch 14 Batch 3250 Loss 0.7917 Accuracy 0.5258\n",
            "Epoch 14 Batch 3300 Loss 0.7898 Accuracy 0.5260\n",
            "Epoch 14 Batch 3350 Loss 0.7880 Accuracy 0.5263\n",
            "Epoch 14 Batch 3400 Loss 0.7861 Accuracy 0.5265\n",
            "Epoch 14 Batch 3450 Loss 0.7844 Accuracy 0.5267\n",
            "Epoch 14 Batch 3500 Loss 0.7827 Accuracy 0.5271\n",
            "Epoch 14 Batch 3550 Loss 0.7811 Accuracy 0.5274\n",
            "Epoch 14 Batch 3600 Loss 0.7796 Accuracy 0.5277\n",
            "Epoch 14 Batch 3650 Loss 0.7779 Accuracy 0.5280\n",
            "Epoch 14 Batch 3700 Loss 0.7765 Accuracy 0.5284\n",
            "Epoch 14 Batch 3750 Loss 0.7751 Accuracy 0.5287\n",
            "Epoch 14 Batch 3800 Loss 0.7737 Accuracy 0.5290\n",
            "Epoch 14 Batch 3850 Loss 0.7728 Accuracy 0.5293\n",
            "Epoch 14 Batch 3900 Loss 0.7714 Accuracy 0.5296\n",
            "Epoch 14 Batch 3950 Loss 0.7704 Accuracy 0.5298\n",
            "Epoch 14 Batch 4000 Loss 0.7691 Accuracy 0.5301\n",
            "Epoch 14 Batch 4050 Loss 0.7679 Accuracy 0.5304\n",
            "Epoch 14 Batch 4100 Loss 0.7672 Accuracy 0.5306\n",
            "Epoch 14 Batch 4150 Loss 0.7669 Accuracy 0.5307\n",
            "Epoch 14 Batch 4200 Loss 0.7672 Accuracy 0.5307\n",
            "Epoch 14 Batch 4250 Loss 0.7675 Accuracy 0.5306\n",
            "Epoch 14 Batch 4300 Loss 0.7680 Accuracy 0.5306\n",
            "Epoch 14 Batch 4350 Loss 0.7692 Accuracy 0.5305\n",
            "Epoch 14 Batch 4400 Loss 0.7702 Accuracy 0.5303\n",
            "Epoch 14 Batch 4450 Loss 0.7711 Accuracy 0.5301\n",
            "Epoch 14 Batch 4500 Loss 0.7724 Accuracy 0.5299\n",
            "Epoch 14 Batch 4550 Loss 0.7739 Accuracy 0.5297\n",
            "Epoch 14 Batch 4600 Loss 0.7754 Accuracy 0.5295\n",
            "Epoch 14 Batch 4650 Loss 0.7766 Accuracy 0.5292\n",
            "Epoch 14 Batch 4700 Loss 0.7781 Accuracy 0.5290\n",
            "Epoch 14 Batch 4750 Loss 0.7794 Accuracy 0.5288\n",
            "Epoch 14 Batch 4800 Loss 0.7808 Accuracy 0.5286\n",
            "Epoch 14 Batch 4850 Loss 0.7823 Accuracy 0.5284\n",
            "Epoch 14 Batch 4900 Loss 0.7835 Accuracy 0.5282\n",
            "Epoch 14 Batch 4950 Loss 0.7848 Accuracy 0.5279\n",
            "Epoch 14 Batch 5000 Loss 0.7863 Accuracy 0.5277\n",
            "Epoch 14 Batch 5050 Loss 0.7877 Accuracy 0.5275\n",
            "Epoch 14 Batch 5100 Loss 0.7889 Accuracy 0.5272\n",
            "Epoch 14 Batch 5150 Loss 0.7903 Accuracy 0.5270\n",
            "Epoch 14 Batch 5200 Loss 0.7916 Accuracy 0.5267\n",
            "Epoch 14 Batch 5250 Loss 0.7929 Accuracy 0.5265\n",
            "Epoch 14 Batch 5300 Loss 0.7942 Accuracy 0.5262\n",
            "Epoch 14 Batch 5350 Loss 0.7955 Accuracy 0.5259\n",
            "Epoch 14 Batch 5400 Loss 0.7966 Accuracy 0.5256\n",
            "Epoch 14 Batch 5450 Loss 0.7977 Accuracy 0.5253\n",
            "Epoch 14 Batch 5500 Loss 0.7988 Accuracy 0.5251\n",
            "Epoch 14 Batch 5550 Loss 0.7998 Accuracy 0.5248\n",
            "Epoch 14 Batch 5600 Loss 0.8007 Accuracy 0.5245\n",
            "Epoch 14 Batch 5650 Loss 0.8016 Accuracy 0.5242\n",
            "Epoch 14 Batch 5700 Loss 0.8025 Accuracy 0.5239\n",
            "Saving checkpoint for epoch 14 at ./drive/My Drive/projects/transformer/ckpt/ckpt-29\n",
            "Time taken for 1 epoch: 1429.0318706035614 secs\n",
            "\n",
            "Start of epoch 15\n",
            "Epoch 15 Batch 0 Loss 1.0046 Accuracy 0.5173\n",
            "Epoch 15 Batch 50 Loss 0.9183 Accuracy 0.5060\n",
            "Epoch 15 Batch 100 Loss 0.9102 Accuracy 0.5057\n",
            "Epoch 15 Batch 150 Loss 0.9079 Accuracy 0.5046\n",
            "Epoch 15 Batch 200 Loss 0.8999 Accuracy 0.5045\n",
            "Epoch 15 Batch 250 Loss 0.8981 Accuracy 0.5073\n",
            "Epoch 15 Batch 300 Loss 0.8985 Accuracy 0.5065\n",
            "Epoch 15 Batch 350 Loss 0.8960 Accuracy 0.5064\n",
            "Epoch 15 Batch 400 Loss 0.8982 Accuracy 0.5066\n",
            "Epoch 15 Batch 450 Loss 0.8956 Accuracy 0.5070\n",
            "Epoch 15 Batch 500 Loss 0.8929 Accuracy 0.5068\n",
            "Epoch 15 Batch 550 Loss 0.8922 Accuracy 0.5068\n",
            "Epoch 15 Batch 600 Loss 0.8913 Accuracy 0.5065\n",
            "Epoch 15 Batch 650 Loss 0.8915 Accuracy 0.5067\n",
            "Epoch 15 Batch 700 Loss 0.8906 Accuracy 0.5070\n",
            "Epoch 15 Batch 750 Loss 0.8887 Accuracy 0.5077\n",
            "Epoch 15 Batch 800 Loss 0.8881 Accuracy 0.5079\n",
            "Epoch 15 Batch 850 Loss 0.8876 Accuracy 0.5081\n",
            "Epoch 15 Batch 900 Loss 0.8872 Accuracy 0.5082\n",
            "Epoch 15 Batch 950 Loss 0.8854 Accuracy 0.5080\n",
            "Epoch 15 Batch 1000 Loss 0.8837 Accuracy 0.5082\n",
            "Epoch 15 Batch 1050 Loss 0.8821 Accuracy 0.5084\n",
            "Epoch 15 Batch 1100 Loss 0.8807 Accuracy 0.5084\n",
            "Epoch 15 Batch 1150 Loss 0.8801 Accuracy 0.5086\n",
            "Epoch 15 Batch 1200 Loss 0.8788 Accuracy 0.5089\n",
            "Epoch 15 Batch 1250 Loss 0.8769 Accuracy 0.5091\n",
            "Epoch 15 Batch 1300 Loss 0.8747 Accuracy 0.5094\n",
            "Epoch 15 Batch 1350 Loss 0.8734 Accuracy 0.5101\n",
            "Epoch 15 Batch 1400 Loss 0.8719 Accuracy 0.5108\n",
            "Epoch 15 Batch 1450 Loss 0.8687 Accuracy 0.5115\n",
            "Epoch 15 Batch 1500 Loss 0.8664 Accuracy 0.5123\n",
            "Epoch 15 Batch 1550 Loss 0.8638 Accuracy 0.5132\n",
            "Epoch 15 Batch 1600 Loss 0.8611 Accuracy 0.5140\n",
            "Epoch 15 Batch 1650 Loss 0.8583 Accuracy 0.5148\n",
            "Epoch 15 Batch 1700 Loss 0.8561 Accuracy 0.5156\n",
            "Epoch 15 Batch 1750 Loss 0.8534 Accuracy 0.5164\n",
            "Epoch 15 Batch 1800 Loss 0.8511 Accuracy 0.5173\n",
            "Epoch 15 Batch 1850 Loss 0.8488 Accuracy 0.5181\n",
            "Epoch 15 Batch 1900 Loss 0.8470 Accuracy 0.5190\n",
            "Epoch 15 Batch 1950 Loss 0.8449 Accuracy 0.5197\n",
            "Epoch 15 Batch 2000 Loss 0.8429 Accuracy 0.5204\n",
            "Epoch 15 Batch 2050 Loss 0.8413 Accuracy 0.5208\n",
            "Epoch 15 Batch 2100 Loss 0.8389 Accuracy 0.5212\n",
            "Epoch 15 Batch 2150 Loss 0.8363 Accuracy 0.5214\n",
            "Epoch 15 Batch 2200 Loss 0.8331 Accuracy 0.5214\n",
            "Epoch 15 Batch 2250 Loss 0.8307 Accuracy 0.5215\n",
            "Epoch 15 Batch 2300 Loss 0.8282 Accuracy 0.5218\n",
            "Epoch 15 Batch 2350 Loss 0.8256 Accuracy 0.5220\n",
            "Epoch 15 Batch 2400 Loss 0.8228 Accuracy 0.5222\n",
            "Epoch 15 Batch 2450 Loss 0.8201 Accuracy 0.5224\n",
            "Epoch 15 Batch 2500 Loss 0.8175 Accuracy 0.5226\n",
            "Epoch 15 Batch 2550 Loss 0.8151 Accuracy 0.5229\n",
            "Epoch 15 Batch 2600 Loss 0.8127 Accuracy 0.5233\n",
            "Epoch 15 Batch 2650 Loss 0.8102 Accuracy 0.5236\n",
            "Epoch 15 Batch 2700 Loss 0.8078 Accuracy 0.5239\n",
            "Epoch 15 Batch 2750 Loss 0.8058 Accuracy 0.5242\n",
            "Epoch 15 Batch 2800 Loss 0.8037 Accuracy 0.5245\n",
            "Epoch 15 Batch 2850 Loss 0.8016 Accuracy 0.5247\n",
            "Epoch 15 Batch 2900 Loss 0.7999 Accuracy 0.5249\n",
            "Epoch 15 Batch 2950 Loss 0.7982 Accuracy 0.5251\n",
            "Epoch 15 Batch 3000 Loss 0.7963 Accuracy 0.5254\n",
            "Epoch 15 Batch 3050 Loss 0.7945 Accuracy 0.5256\n",
            "Epoch 15 Batch 3100 Loss 0.7930 Accuracy 0.5259\n",
            "Epoch 15 Batch 3150 Loss 0.7914 Accuracy 0.5261\n",
            "Epoch 15 Batch 3200 Loss 0.7897 Accuracy 0.5263\n",
            "Epoch 15 Batch 3250 Loss 0.7881 Accuracy 0.5265\n",
            "Epoch 15 Batch 3300 Loss 0.7862 Accuracy 0.5267\n",
            "Epoch 15 Batch 3350 Loss 0.7844 Accuracy 0.5269\n",
            "Epoch 15 Batch 3400 Loss 0.7829 Accuracy 0.5272\n",
            "Epoch 15 Batch 3450 Loss 0.7814 Accuracy 0.5275\n",
            "Epoch 15 Batch 3500 Loss 0.7799 Accuracy 0.5277\n",
            "Epoch 15 Batch 3550 Loss 0.7782 Accuracy 0.5279\n",
            "Epoch 15 Batch 3600 Loss 0.7763 Accuracy 0.5282\n",
            "Epoch 15 Batch 3650 Loss 0.7749 Accuracy 0.5285\n",
            "Epoch 15 Batch 3700 Loss 0.7735 Accuracy 0.5287\n",
            "Epoch 15 Batch 3750 Loss 0.7721 Accuracy 0.5290\n",
            "Epoch 15 Batch 3800 Loss 0.7707 Accuracy 0.5294\n",
            "Epoch 15 Batch 3850 Loss 0.7694 Accuracy 0.5298\n",
            "Epoch 15 Batch 3900 Loss 0.7681 Accuracy 0.5301\n",
            "Epoch 15 Batch 3950 Loss 0.7670 Accuracy 0.5304\n",
            "Epoch 15 Batch 4000 Loss 0.7659 Accuracy 0.5307\n",
            "Epoch 15 Batch 4050 Loss 0.7649 Accuracy 0.5311\n",
            "Epoch 15 Batch 4100 Loss 0.7638 Accuracy 0.5313\n",
            "Epoch 15 Batch 4150 Loss 0.7636 Accuracy 0.5313\n",
            "Epoch 15 Batch 4200 Loss 0.7638 Accuracy 0.5313\n",
            "Epoch 15 Batch 4250 Loss 0.7641 Accuracy 0.5313\n",
            "Epoch 15 Batch 4300 Loss 0.7650 Accuracy 0.5311\n",
            "Epoch 15 Batch 4350 Loss 0.7663 Accuracy 0.5310\n",
            "Epoch 15 Batch 4400 Loss 0.7673 Accuracy 0.5308\n",
            "Epoch 15 Batch 4450 Loss 0.7689 Accuracy 0.5306\n",
            "Epoch 15 Batch 4500 Loss 0.7702 Accuracy 0.5304\n",
            "Epoch 15 Batch 4550 Loss 0.7714 Accuracy 0.5302\n",
            "Epoch 15 Batch 4600 Loss 0.7727 Accuracy 0.5300\n",
            "Epoch 15 Batch 4650 Loss 0.7744 Accuracy 0.5297\n",
            "Epoch 15 Batch 4700 Loss 0.7756 Accuracy 0.5295\n",
            "Epoch 15 Batch 4750 Loss 0.7770 Accuracy 0.5293\n",
            "Epoch 15 Batch 4800 Loss 0.7781 Accuracy 0.5291\n",
            "Epoch 15 Batch 4850 Loss 0.7794 Accuracy 0.5289\n",
            "Epoch 15 Batch 4900 Loss 0.7806 Accuracy 0.5287\n",
            "Epoch 15 Batch 4950 Loss 0.7819 Accuracy 0.5285\n",
            "Epoch 15 Batch 5000 Loss 0.7834 Accuracy 0.5283\n",
            "Epoch 15 Batch 5050 Loss 0.7846 Accuracy 0.5282\n",
            "Epoch 15 Batch 5100 Loss 0.7859 Accuracy 0.5279\n",
            "Epoch 15 Batch 5150 Loss 0.7874 Accuracy 0.5277\n",
            "Epoch 15 Batch 5200 Loss 0.7887 Accuracy 0.5274\n",
            "Epoch 15 Batch 5250 Loss 0.7900 Accuracy 0.5271\n",
            "Epoch 15 Batch 5300 Loss 0.7912 Accuracy 0.5268\n",
            "Epoch 15 Batch 5350 Loss 0.7924 Accuracy 0.5265\n",
            "Epoch 15 Batch 5400 Loss 0.7935 Accuracy 0.5262\n",
            "Epoch 15 Batch 5450 Loss 0.7947 Accuracy 0.5259\n",
            "Epoch 15 Batch 5500 Loss 0.7958 Accuracy 0.5256\n",
            "Epoch 15 Batch 5550 Loss 0.7970 Accuracy 0.5253\n",
            "Epoch 15 Batch 5600 Loss 0.7977 Accuracy 0.5250\n",
            "Epoch 15 Batch 5650 Loss 0.7986 Accuracy 0.5248\n",
            "Epoch 15 Batch 5700 Loss 0.7997 Accuracy 0.5245\n",
            "Saving checkpoint for epoch 15 at ./drive/My Drive/projects/transformer/ckpt/ckpt-30\n",
            "Time taken for 1 epoch: 1428.663575410843 secs\n",
            "\n",
            "Start of epoch 16\n",
            "Epoch 16 Batch 0 Loss 0.8907 Accuracy 0.5197\n",
            "Epoch 16 Batch 50 Loss 0.9130 Accuracy 0.5042\n",
            "Epoch 16 Batch 100 Loss 0.8995 Accuracy 0.5041\n",
            "Epoch 16 Batch 150 Loss 0.8957 Accuracy 0.5075\n",
            "Epoch 16 Batch 200 Loss 0.8941 Accuracy 0.5077\n",
            "Epoch 16 Batch 250 Loss 0.8941 Accuracy 0.5083\n",
            "Epoch 16 Batch 300 Loss 0.8968 Accuracy 0.5089\n",
            "Epoch 16 Batch 350 Loss 0.8950 Accuracy 0.5087\n",
            "Epoch 16 Batch 400 Loss 0.8942 Accuracy 0.5091\n",
            "Epoch 16 Batch 450 Loss 0.8896 Accuracy 0.5085\n",
            "Epoch 16 Batch 500 Loss 0.8895 Accuracy 0.5088\n",
            "Epoch 16 Batch 550 Loss 0.8900 Accuracy 0.5085\n",
            "Epoch 16 Batch 600 Loss 0.8881 Accuracy 0.5086\n",
            "Epoch 16 Batch 650 Loss 0.8877 Accuracy 0.5086\n",
            "Epoch 16 Batch 700 Loss 0.8872 Accuracy 0.5083\n",
            "Epoch 16 Batch 750 Loss 0.8861 Accuracy 0.5084\n",
            "Epoch 16 Batch 800 Loss 0.8853 Accuracy 0.5083\n",
            "Epoch 16 Batch 850 Loss 0.8856 Accuracy 0.5083\n",
            "Epoch 16 Batch 900 Loss 0.8848 Accuracy 0.5083\n",
            "Epoch 16 Batch 950 Loss 0.8828 Accuracy 0.5086\n",
            "Epoch 16 Batch 1000 Loss 0.8811 Accuracy 0.5084\n",
            "Epoch 16 Batch 1050 Loss 0.8813 Accuracy 0.5083\n",
            "Epoch 16 Batch 1100 Loss 0.8804 Accuracy 0.5084\n",
            "Epoch 16 Batch 1150 Loss 0.8794 Accuracy 0.5085\n",
            "Epoch 16 Batch 1200 Loss 0.8776 Accuracy 0.5090\n",
            "Epoch 16 Batch 1250 Loss 0.8757 Accuracy 0.5095\n",
            "Epoch 16 Batch 1300 Loss 0.8726 Accuracy 0.5097\n",
            "Epoch 16 Batch 1350 Loss 0.8703 Accuracy 0.5103\n",
            "Epoch 16 Batch 1400 Loss 0.8682 Accuracy 0.5109\n",
            "Epoch 16 Batch 1450 Loss 0.8663 Accuracy 0.5119\n",
            "Epoch 16 Batch 1500 Loss 0.8637 Accuracy 0.5127\n",
            "Epoch 16 Batch 1550 Loss 0.8606 Accuracy 0.5138\n",
            "Epoch 16 Batch 1600 Loss 0.8583 Accuracy 0.5148\n",
            "Epoch 16 Batch 1650 Loss 0.8565 Accuracy 0.5155\n",
            "Epoch 16 Batch 1700 Loss 0.8545 Accuracy 0.5164\n",
            "Epoch 16 Batch 1750 Loss 0.8519 Accuracy 0.5171\n",
            "Epoch 16 Batch 1800 Loss 0.8497 Accuracy 0.5178\n",
            "Epoch 16 Batch 1850 Loss 0.8476 Accuracy 0.5184\n",
            "Epoch 16 Batch 1900 Loss 0.8453 Accuracy 0.5193\n",
            "Epoch 16 Batch 1950 Loss 0.8430 Accuracy 0.5200\n",
            "Epoch 16 Batch 2000 Loss 0.8412 Accuracy 0.5203\n",
            "Epoch 16 Batch 2050 Loss 0.8390 Accuracy 0.5208\n",
            "Epoch 16 Batch 2100 Loss 0.8370 Accuracy 0.5211\n",
            "Epoch 16 Batch 2150 Loss 0.8343 Accuracy 0.5215\n",
            "Epoch 16 Batch 2200 Loss 0.8316 Accuracy 0.5215\n",
            "Epoch 16 Batch 2250 Loss 0.8286 Accuracy 0.5217\n",
            "Epoch 16 Batch 2300 Loss 0.8261 Accuracy 0.5219\n",
            "Epoch 16 Batch 2350 Loss 0.8232 Accuracy 0.5222\n",
            "Epoch 16 Batch 2400 Loss 0.8205 Accuracy 0.5226\n",
            "Epoch 16 Batch 2450 Loss 0.8177 Accuracy 0.5229\n",
            "Epoch 16 Batch 2500 Loss 0.8153 Accuracy 0.5232\n",
            "Epoch 16 Batch 2550 Loss 0.8128 Accuracy 0.5234\n",
            "Epoch 16 Batch 2600 Loss 0.8103 Accuracy 0.5237\n",
            "Epoch 16 Batch 2650 Loss 0.8078 Accuracy 0.5240\n",
            "Epoch 16 Batch 2700 Loss 0.8055 Accuracy 0.5242\n",
            "Epoch 16 Batch 2750 Loss 0.8031 Accuracy 0.5245\n",
            "Epoch 16 Batch 2800 Loss 0.8013 Accuracy 0.5247\n",
            "Epoch 16 Batch 2850 Loss 0.7995 Accuracy 0.5250\n",
            "Epoch 16 Batch 2900 Loss 0.7976 Accuracy 0.5253\n",
            "Epoch 16 Batch 2950 Loss 0.7957 Accuracy 0.5256\n",
            "Epoch 16 Batch 3000 Loss 0.7939 Accuracy 0.5258\n",
            "Epoch 16 Batch 3050 Loss 0.7924 Accuracy 0.5261\n",
            "Epoch 16 Batch 3100 Loss 0.7910 Accuracy 0.5263\n",
            "Epoch 16 Batch 3150 Loss 0.7894 Accuracy 0.5265\n",
            "Epoch 16 Batch 3200 Loss 0.7874 Accuracy 0.5267\n",
            "Epoch 16 Batch 3250 Loss 0.7859 Accuracy 0.5269\n",
            "Epoch 16 Batch 3300 Loss 0.7839 Accuracy 0.5270\n",
            "Epoch 16 Batch 3350 Loss 0.7822 Accuracy 0.5273\n",
            "Epoch 16 Batch 3400 Loss 0.7804 Accuracy 0.5275\n",
            "Epoch 16 Batch 3450 Loss 0.7787 Accuracy 0.5278\n",
            "Epoch 16 Batch 3500 Loss 0.7772 Accuracy 0.5281\n",
            "Epoch 16 Batch 3550 Loss 0.7757 Accuracy 0.5284\n",
            "Epoch 16 Batch 3600 Loss 0.7742 Accuracy 0.5286\n",
            "Epoch 16 Batch 3650 Loss 0.7727 Accuracy 0.5289\n",
            "Epoch 16 Batch 3700 Loss 0.7713 Accuracy 0.5293\n",
            "Epoch 16 Batch 3750 Loss 0.7697 Accuracy 0.5296\n",
            "Epoch 16 Batch 3800 Loss 0.7682 Accuracy 0.5299\n",
            "Epoch 16 Batch 3850 Loss 0.7671 Accuracy 0.5302\n",
            "Epoch 16 Batch 3900 Loss 0.7659 Accuracy 0.5305\n",
            "Epoch 16 Batch 3950 Loss 0.7647 Accuracy 0.5307\n",
            "Epoch 16 Batch 4000 Loss 0.7633 Accuracy 0.5310\n",
            "Epoch 16 Batch 4050 Loss 0.7622 Accuracy 0.5313\n",
            "Epoch 16 Batch 4100 Loss 0.7614 Accuracy 0.5315\n",
            "Epoch 16 Batch 4150 Loss 0.7611 Accuracy 0.5316\n",
            "Epoch 16 Batch 4200 Loss 0.7613 Accuracy 0.5316\n",
            "Epoch 16 Batch 4250 Loss 0.7617 Accuracy 0.5315\n",
            "Epoch 16 Batch 4300 Loss 0.7625 Accuracy 0.5314\n",
            "Epoch 16 Batch 4350 Loss 0.7635 Accuracy 0.5312\n",
            "Epoch 16 Batch 4400 Loss 0.7645 Accuracy 0.5310\n",
            "Epoch 16 Batch 4450 Loss 0.7658 Accuracy 0.5308\n",
            "Epoch 16 Batch 4500 Loss 0.7671 Accuracy 0.5306\n",
            "Epoch 16 Batch 4550 Loss 0.7686 Accuracy 0.5304\n",
            "Epoch 16 Batch 4600 Loss 0.7700 Accuracy 0.5302\n",
            "Epoch 16 Batch 4650 Loss 0.7713 Accuracy 0.5300\n",
            "Epoch 16 Batch 4700 Loss 0.7730 Accuracy 0.5298\n",
            "Epoch 16 Batch 4750 Loss 0.7745 Accuracy 0.5296\n",
            "Epoch 16 Batch 4800 Loss 0.7756 Accuracy 0.5295\n",
            "Epoch 16 Batch 4850 Loss 0.7769 Accuracy 0.5293\n",
            "Epoch 16 Batch 4900 Loss 0.7781 Accuracy 0.5291\n",
            "Epoch 16 Batch 4950 Loss 0.7795 Accuracy 0.5289\n",
            "Epoch 16 Batch 5000 Loss 0.7808 Accuracy 0.5287\n",
            "Epoch 16 Batch 5050 Loss 0.7823 Accuracy 0.5284\n",
            "Epoch 16 Batch 5100 Loss 0.7838 Accuracy 0.5282\n",
            "Epoch 16 Batch 5150 Loss 0.7852 Accuracy 0.5279\n",
            "Epoch 16 Batch 5200 Loss 0.7864 Accuracy 0.5277\n",
            "Epoch 16 Batch 5250 Loss 0.7876 Accuracy 0.5273\n",
            "Epoch 16 Batch 5300 Loss 0.7888 Accuracy 0.5270\n",
            "Epoch 16 Batch 5350 Loss 0.7899 Accuracy 0.5267\n",
            "Epoch 16 Batch 5400 Loss 0.7910 Accuracy 0.5264\n",
            "Epoch 16 Batch 5450 Loss 0.7921 Accuracy 0.5261\n",
            "Epoch 16 Batch 5500 Loss 0.7932 Accuracy 0.5258\n",
            "Epoch 16 Batch 5550 Loss 0.7943 Accuracy 0.5255\n",
            "Epoch 16 Batch 5600 Loss 0.7954 Accuracy 0.5253\n",
            "Epoch 16 Batch 5650 Loss 0.7963 Accuracy 0.5250\n",
            "Epoch 16 Batch 5700 Loss 0.7973 Accuracy 0.5248\n",
            "Saving checkpoint for epoch 16 at ./drive/My Drive/projects/transformer/ckpt/ckpt-31\n",
            "Time taken for 1 epoch: 1430.3212456703186 secs\n",
            "\n",
            "Start of epoch 17\n",
            "Epoch 17 Batch 0 Loss 0.8614 Accuracy 0.5074\n",
            "Epoch 17 Batch 50 Loss 0.9138 Accuracy 0.5078\n",
            "Epoch 17 Batch 100 Loss 0.8984 Accuracy 0.5049\n",
            "Epoch 17 Batch 150 Loss 0.8976 Accuracy 0.5045\n",
            "Epoch 17 Batch 200 Loss 0.8921 Accuracy 0.5052\n",
            "Epoch 17 Batch 250 Loss 0.8925 Accuracy 0.5074\n",
            "Epoch 17 Batch 300 Loss 0.8908 Accuracy 0.5078\n",
            "Epoch 17 Batch 350 Loss 0.8884 Accuracy 0.5084\n",
            "Epoch 17 Batch 400 Loss 0.8863 Accuracy 0.5084\n",
            "Epoch 17 Batch 450 Loss 0.8862 Accuracy 0.5084\n",
            "Epoch 17 Batch 500 Loss 0.8851 Accuracy 0.5085\n",
            "Epoch 17 Batch 550 Loss 0.8844 Accuracy 0.5084\n",
            "Epoch 17 Batch 600 Loss 0.8822 Accuracy 0.5083\n",
            "Epoch 17 Batch 650 Loss 0.8831 Accuracy 0.5082\n",
            "Epoch 17 Batch 700 Loss 0.8845 Accuracy 0.5086\n",
            "Epoch 17 Batch 750 Loss 0.8841 Accuracy 0.5086\n",
            "Epoch 17 Batch 800 Loss 0.8820 Accuracy 0.5090\n",
            "Epoch 17 Batch 850 Loss 0.8820 Accuracy 0.5088\n",
            "Epoch 17 Batch 900 Loss 0.8817 Accuracy 0.5088\n",
            "Epoch 17 Batch 950 Loss 0.8809 Accuracy 0.5088\n",
            "Epoch 17 Batch 1000 Loss 0.8794 Accuracy 0.5090\n",
            "Epoch 17 Batch 1050 Loss 0.8778 Accuracy 0.5092\n",
            "Epoch 17 Batch 1100 Loss 0.8771 Accuracy 0.5094\n",
            "Epoch 17 Batch 1150 Loss 0.8754 Accuracy 0.5096\n",
            "Epoch 17 Batch 1200 Loss 0.8735 Accuracy 0.5099\n",
            "Epoch 17 Batch 1250 Loss 0.8715 Accuracy 0.5104\n",
            "Epoch 17 Batch 1300 Loss 0.8692 Accuracy 0.5109\n",
            "Epoch 17 Batch 1350 Loss 0.8674 Accuracy 0.5111\n",
            "Epoch 17 Batch 1400 Loss 0.8647 Accuracy 0.5118\n",
            "Epoch 17 Batch 1450 Loss 0.8622 Accuracy 0.5127\n",
            "Epoch 17 Batch 1500 Loss 0.8595 Accuracy 0.5135\n",
            "Epoch 17 Batch 1550 Loss 0.8569 Accuracy 0.5144\n",
            "Epoch 17 Batch 1600 Loss 0.8541 Accuracy 0.5152\n",
            "Epoch 17 Batch 1650 Loss 0.8522 Accuracy 0.5160\n",
            "Epoch 17 Batch 1700 Loss 0.8497 Accuracy 0.5167\n",
            "Epoch 17 Batch 1750 Loss 0.8474 Accuracy 0.5174\n",
            "Epoch 17 Batch 1800 Loss 0.8449 Accuracy 0.5183\n",
            "Epoch 17 Batch 1850 Loss 0.8432 Accuracy 0.5191\n",
            "Epoch 17 Batch 1900 Loss 0.8409 Accuracy 0.5197\n",
            "Epoch 17 Batch 1950 Loss 0.8387 Accuracy 0.5204\n",
            "Epoch 17 Batch 2000 Loss 0.8367 Accuracy 0.5212\n",
            "Epoch 17 Batch 2050 Loss 0.8350 Accuracy 0.5217\n",
            "Epoch 17 Batch 2100 Loss 0.8327 Accuracy 0.5220\n",
            "Epoch 17 Batch 2150 Loss 0.8299 Accuracy 0.5224\n",
            "Epoch 17 Batch 2200 Loss 0.8271 Accuracy 0.5224\n",
            "Epoch 17 Batch 2250 Loss 0.8243 Accuracy 0.5225\n",
            "Epoch 17 Batch 2300 Loss 0.8218 Accuracy 0.5227\n",
            "Epoch 17 Batch 2350 Loss 0.8190 Accuracy 0.5230\n",
            "Epoch 17 Batch 2400 Loss 0.8161 Accuracy 0.5231\n",
            "Epoch 17 Batch 2450 Loss 0.8135 Accuracy 0.5234\n",
            "Epoch 17 Batch 2500 Loss 0.8110 Accuracy 0.5237\n",
            "Epoch 17 Batch 2550 Loss 0.8088 Accuracy 0.5239\n",
            "Epoch 17 Batch 2600 Loss 0.8065 Accuracy 0.5242\n",
            "Epoch 17 Batch 2650 Loss 0.8040 Accuracy 0.5245\n",
            "Epoch 17 Batch 2700 Loss 0.8017 Accuracy 0.5247\n",
            "Epoch 17 Batch 2750 Loss 0.8000 Accuracy 0.5250\n",
            "Epoch 17 Batch 2800 Loss 0.7982 Accuracy 0.5253\n",
            "Epoch 17 Batch 2850 Loss 0.7962 Accuracy 0.5257\n",
            "Epoch 17 Batch 2900 Loss 0.7942 Accuracy 0.5259\n",
            "Epoch 17 Batch 2950 Loss 0.7924 Accuracy 0.5262\n",
            "Epoch 17 Batch 3000 Loss 0.7903 Accuracy 0.5266\n",
            "Epoch 17 Batch 3050 Loss 0.7886 Accuracy 0.5267\n",
            "Epoch 17 Batch 3100 Loss 0.7872 Accuracy 0.5269\n",
            "Epoch 17 Batch 3150 Loss 0.7855 Accuracy 0.5271\n",
            "Epoch 17 Batch 3200 Loss 0.7837 Accuracy 0.5273\n",
            "Epoch 17 Batch 3250 Loss 0.7819 Accuracy 0.5274\n",
            "Epoch 17 Batch 3300 Loss 0.7800 Accuracy 0.5276\n",
            "Epoch 17 Batch 3350 Loss 0.7784 Accuracy 0.5277\n",
            "Epoch 17 Batch 3400 Loss 0.7767 Accuracy 0.5279\n",
            "Epoch 17 Batch 3450 Loss 0.7749 Accuracy 0.5283\n",
            "Epoch 17 Batch 3500 Loss 0.7732 Accuracy 0.5286\n",
            "Epoch 17 Batch 3550 Loss 0.7716 Accuracy 0.5289\n",
            "Epoch 17 Batch 3600 Loss 0.7701 Accuracy 0.5292\n",
            "Epoch 17 Batch 3650 Loss 0.7687 Accuracy 0.5295\n",
            "Epoch 17 Batch 3700 Loss 0.7673 Accuracy 0.5298\n",
            "Epoch 17 Batch 3750 Loss 0.7658 Accuracy 0.5300\n",
            "Epoch 17 Batch 3800 Loss 0.7647 Accuracy 0.5303\n",
            "Epoch 17 Batch 3850 Loss 0.7636 Accuracy 0.5306\n",
            "Epoch 17 Batch 3900 Loss 0.7623 Accuracy 0.5309\n",
            "Epoch 17 Batch 3950 Loss 0.7609 Accuracy 0.5312\n",
            "Epoch 17 Batch 4000 Loss 0.7597 Accuracy 0.5315\n",
            "Epoch 17 Batch 4050 Loss 0.7587 Accuracy 0.5318\n",
            "Epoch 17 Batch 4100 Loss 0.7579 Accuracy 0.5320\n",
            "Epoch 17 Batch 4150 Loss 0.7576 Accuracy 0.5321\n",
            "Epoch 17 Batch 4200 Loss 0.7580 Accuracy 0.5321\n",
            "Epoch 17 Batch 4250 Loss 0.7585 Accuracy 0.5321\n",
            "Epoch 17 Batch 4300 Loss 0.7593 Accuracy 0.5320\n",
            "Epoch 17 Batch 4350 Loss 0.7607 Accuracy 0.5318\n",
            "Epoch 17 Batch 4400 Loss 0.7617 Accuracy 0.5317\n",
            "Epoch 17 Batch 4450 Loss 0.7630 Accuracy 0.5314\n",
            "Epoch 17 Batch 4500 Loss 0.7642 Accuracy 0.5313\n",
            "Epoch 17 Batch 4550 Loss 0.7655 Accuracy 0.5310\n",
            "Epoch 17 Batch 4600 Loss 0.7670 Accuracy 0.5308\n",
            "Epoch 17 Batch 4650 Loss 0.7683 Accuracy 0.5306\n",
            "Epoch 17 Batch 4700 Loss 0.7697 Accuracy 0.5304\n",
            "Epoch 17 Batch 4750 Loss 0.7712 Accuracy 0.5301\n",
            "Epoch 17 Batch 4800 Loss 0.7724 Accuracy 0.5300\n",
            "Epoch 17 Batch 4850 Loss 0.7736 Accuracy 0.5298\n",
            "Epoch 17 Batch 4900 Loss 0.7749 Accuracy 0.5296\n",
            "Epoch 17 Batch 4950 Loss 0.7761 Accuracy 0.5294\n",
            "Epoch 17 Batch 5000 Loss 0.7775 Accuracy 0.5292\n",
            "Epoch 17 Batch 5050 Loss 0.7789 Accuracy 0.5289\n",
            "Epoch 17 Batch 5100 Loss 0.7800 Accuracy 0.5287\n",
            "Epoch 17 Batch 5150 Loss 0.7814 Accuracy 0.5284\n",
            "Epoch 17 Batch 5200 Loss 0.7828 Accuracy 0.5282\n",
            "Epoch 17 Batch 5250 Loss 0.7841 Accuracy 0.5279\n",
            "Epoch 17 Batch 5300 Loss 0.7853 Accuracy 0.5276\n",
            "Epoch 17 Batch 5350 Loss 0.7863 Accuracy 0.5273\n",
            "Epoch 17 Batch 5400 Loss 0.7874 Accuracy 0.5270\n",
            "Epoch 17 Batch 5450 Loss 0.7884 Accuracy 0.5268\n",
            "Epoch 17 Batch 5500 Loss 0.7897 Accuracy 0.5265\n",
            "Epoch 17 Batch 5550 Loss 0.7907 Accuracy 0.5262\n",
            "Epoch 17 Batch 5600 Loss 0.7918 Accuracy 0.5259\n",
            "Epoch 17 Batch 5650 Loss 0.7928 Accuracy 0.5257\n",
            "Epoch 17 Batch 5700 Loss 0.7939 Accuracy 0.5254\n",
            "Saving checkpoint for epoch 17 at ./drive/My Drive/projects/transformer/ckpt/ckpt-32\n",
            "Time taken for 1 epoch: 1443.5327138900757 secs\n",
            "\n",
            "Start of epoch 18\n",
            "Epoch 18 Batch 0 Loss 0.9208 Accuracy 0.4860\n",
            "Epoch 18 Batch 50 Loss 0.9034 Accuracy 0.5125\n",
            "Epoch 18 Batch 100 Loss 0.8985 Accuracy 0.5116\n",
            "Epoch 18 Batch 150 Loss 0.8953 Accuracy 0.5087\n",
            "Epoch 18 Batch 200 Loss 0.8953 Accuracy 0.5078\n",
            "Epoch 18 Batch 250 Loss 0.8920 Accuracy 0.5077\n",
            "Epoch 18 Batch 300 Loss 0.8902 Accuracy 0.5075\n",
            "Epoch 18 Batch 350 Loss 0.8903 Accuracy 0.5074\n",
            "Epoch 18 Batch 400 Loss 0.8903 Accuracy 0.5079\n",
            "Epoch 18 Batch 450 Loss 0.8876 Accuracy 0.5076\n",
            "Epoch 18 Batch 500 Loss 0.8858 Accuracy 0.5073\n",
            "Epoch 18 Batch 550 Loss 0.8848 Accuracy 0.5073\n",
            "Epoch 18 Batch 600 Loss 0.8840 Accuracy 0.5075\n",
            "Epoch 18 Batch 650 Loss 0.8838 Accuracy 0.5077\n",
            "Epoch 18 Batch 700 Loss 0.8830 Accuracy 0.5083\n",
            "Epoch 18 Batch 750 Loss 0.8800 Accuracy 0.5092\n",
            "Epoch 18 Batch 800 Loss 0.8797 Accuracy 0.5091\n",
            "Epoch 18 Batch 850 Loss 0.8787 Accuracy 0.5095\n",
            "Epoch 18 Batch 900 Loss 0.8779 Accuracy 0.5099\n",
            "Epoch 18 Batch 950 Loss 0.8760 Accuracy 0.5097\n",
            "Epoch 18 Batch 1000 Loss 0.8746 Accuracy 0.5097\n",
            "Epoch 18 Batch 1050 Loss 0.8737 Accuracy 0.5099\n",
            "Epoch 18 Batch 1100 Loss 0.8725 Accuracy 0.5100\n",
            "Epoch 18 Batch 1150 Loss 0.8711 Accuracy 0.5101\n",
            "Epoch 18 Batch 1200 Loss 0.8696 Accuracy 0.5104\n",
            "Epoch 18 Batch 1250 Loss 0.8683 Accuracy 0.5109\n",
            "Epoch 18 Batch 1300 Loss 0.8662 Accuracy 0.5113\n",
            "Epoch 18 Batch 1350 Loss 0.8649 Accuracy 0.5120\n",
            "Epoch 18 Batch 1400 Loss 0.8626 Accuracy 0.5126\n",
            "Epoch 18 Batch 1450 Loss 0.8598 Accuracy 0.5133\n",
            "Epoch 18 Batch 1500 Loss 0.8569 Accuracy 0.5141\n",
            "Epoch 18 Batch 1550 Loss 0.8540 Accuracy 0.5149\n",
            "Epoch 18 Batch 1600 Loss 0.8517 Accuracy 0.5157\n",
            "Epoch 18 Batch 1650 Loss 0.8497 Accuracy 0.5164\n",
            "Epoch 18 Batch 1700 Loss 0.8472 Accuracy 0.5173\n",
            "Epoch 18 Batch 1750 Loss 0.8446 Accuracy 0.5181\n",
            "Epoch 18 Batch 1800 Loss 0.8426 Accuracy 0.5187\n",
            "Epoch 18 Batch 1850 Loss 0.8402 Accuracy 0.5195\n",
            "Epoch 18 Batch 1900 Loss 0.8382 Accuracy 0.5202\n",
            "Epoch 18 Batch 1950 Loss 0.8359 Accuracy 0.5211\n",
            "Epoch 18 Batch 2000 Loss 0.8338 Accuracy 0.5217\n",
            "Epoch 18 Batch 2050 Loss 0.8319 Accuracy 0.5222\n",
            "Epoch 18 Batch 2100 Loss 0.8294 Accuracy 0.5226\n",
            "Epoch 18 Batch 2150 Loss 0.8268 Accuracy 0.5229\n",
            "Epoch 18 Batch 2200 Loss 0.8244 Accuracy 0.5232\n",
            "Epoch 18 Batch 2250 Loss 0.8211 Accuracy 0.5233\n",
            "Epoch 18 Batch 2300 Loss 0.8186 Accuracy 0.5233\n",
            "Epoch 18 Batch 2350 Loss 0.8159 Accuracy 0.5235\n",
            "Epoch 18 Batch 2400 Loss 0.8138 Accuracy 0.5238\n",
            "Epoch 18 Batch 2450 Loss 0.8111 Accuracy 0.5241\n",
            "Epoch 18 Batch 2500 Loss 0.8087 Accuracy 0.5243\n",
            "Epoch 18 Batch 2550 Loss 0.8065 Accuracy 0.5247\n",
            "Epoch 18 Batch 2600 Loss 0.8044 Accuracy 0.5249\n",
            "Epoch 18 Batch 2650 Loss 0.8023 Accuracy 0.5252\n",
            "Epoch 18 Batch 2700 Loss 0.7998 Accuracy 0.5255\n",
            "Epoch 18 Batch 2750 Loss 0.7976 Accuracy 0.5257\n",
            "Epoch 18 Batch 2800 Loss 0.7955 Accuracy 0.5259\n",
            "Epoch 18 Batch 2850 Loss 0.7935 Accuracy 0.5261\n",
            "Epoch 18 Batch 2900 Loss 0.7916 Accuracy 0.5263\n",
            "Epoch 18 Batch 2950 Loss 0.7896 Accuracy 0.5266\n",
            "Epoch 18 Batch 3000 Loss 0.7883 Accuracy 0.5268\n",
            "Epoch 18 Batch 3050 Loss 0.7869 Accuracy 0.5271\n",
            "Epoch 18 Batch 3100 Loss 0.7853 Accuracy 0.5273\n",
            "Epoch 18 Batch 3150 Loss 0.7837 Accuracy 0.5275\n",
            "Epoch 18 Batch 3200 Loss 0.7821 Accuracy 0.5277\n",
            "Epoch 18 Batch 3250 Loss 0.7804 Accuracy 0.5279\n",
            "Epoch 18 Batch 3300 Loss 0.7785 Accuracy 0.5281\n",
            "Epoch 18 Batch 3350 Loss 0.7767 Accuracy 0.5284\n",
            "Epoch 18 Batch 3400 Loss 0.7749 Accuracy 0.5287\n",
            "Epoch 18 Batch 3450 Loss 0.7730 Accuracy 0.5289\n",
            "Epoch 18 Batch 3500 Loss 0.7715 Accuracy 0.5292\n",
            "Epoch 18 Batch 3550 Loss 0.7698 Accuracy 0.5296\n",
            "Epoch 18 Batch 3600 Loss 0.7682 Accuracy 0.5298\n",
            "Epoch 18 Batch 3650 Loss 0.7667 Accuracy 0.5301\n",
            "Epoch 18 Batch 3700 Loss 0.7655 Accuracy 0.5303\n",
            "Epoch 18 Batch 3750 Loss 0.7641 Accuracy 0.5307\n",
            "Epoch 18 Batch 3800 Loss 0.7628 Accuracy 0.5309\n",
            "Epoch 18 Batch 3850 Loss 0.7615 Accuracy 0.5313\n",
            "Epoch 18 Batch 3900 Loss 0.7604 Accuracy 0.5316\n",
            "Epoch 18 Batch 3950 Loss 0.7591 Accuracy 0.5319\n",
            "Epoch 18 Batch 4000 Loss 0.7580 Accuracy 0.5323\n",
            "Epoch 18 Batch 4050 Loss 0.7570 Accuracy 0.5325\n",
            "Epoch 18 Batch 4100 Loss 0.7560 Accuracy 0.5327\n",
            "Epoch 18 Batch 4150 Loss 0.7558 Accuracy 0.5328\n",
            "Epoch 18 Batch 4200 Loss 0.7561 Accuracy 0.5328\n",
            "Epoch 18 Batch 4250 Loss 0.7564 Accuracy 0.5327\n",
            "Epoch 18 Batch 4300 Loss 0.7570 Accuracy 0.5326\n",
            "Epoch 18 Batch 4350 Loss 0.7579 Accuracy 0.5325\n",
            "Epoch 18 Batch 4400 Loss 0.7589 Accuracy 0.5324\n",
            "Epoch 18 Batch 4450 Loss 0.7601 Accuracy 0.5321\n",
            "Epoch 18 Batch 4500 Loss 0.7616 Accuracy 0.5320\n",
            "Epoch 18 Batch 4550 Loss 0.7627 Accuracy 0.5318\n",
            "Epoch 18 Batch 4600 Loss 0.7643 Accuracy 0.5315\n",
            "Epoch 18 Batch 4650 Loss 0.7657 Accuracy 0.5313\n",
            "Epoch 18 Batch 4700 Loss 0.7671 Accuracy 0.5312\n",
            "Epoch 18 Batch 4750 Loss 0.7684 Accuracy 0.5309\n",
            "Epoch 18 Batch 4800 Loss 0.7696 Accuracy 0.5308\n",
            "Epoch 18 Batch 4850 Loss 0.7708 Accuracy 0.5305\n",
            "Epoch 18 Batch 4900 Loss 0.7719 Accuracy 0.5303\n",
            "Epoch 18 Batch 4950 Loss 0.7733 Accuracy 0.5301\n",
            "Epoch 18 Batch 5000 Loss 0.7747 Accuracy 0.5299\n",
            "Epoch 18 Batch 5050 Loss 0.7761 Accuracy 0.5297\n",
            "Epoch 18 Batch 5100 Loss 0.7776 Accuracy 0.5294\n",
            "Epoch 18 Batch 5150 Loss 0.7790 Accuracy 0.5292\n",
            "Epoch 18 Batch 5200 Loss 0.7803 Accuracy 0.5289\n",
            "Epoch 18 Batch 5250 Loss 0.7816 Accuracy 0.5286\n",
            "Epoch 18 Batch 5300 Loss 0.7826 Accuracy 0.5283\n",
            "Epoch 18 Batch 5350 Loss 0.7839 Accuracy 0.5280\n",
            "Epoch 18 Batch 5400 Loss 0.7851 Accuracy 0.5277\n",
            "Epoch 18 Batch 5450 Loss 0.7862 Accuracy 0.5274\n",
            "Epoch 18 Batch 5500 Loss 0.7873 Accuracy 0.5271\n",
            "Epoch 18 Batch 5550 Loss 0.7885 Accuracy 0.5268\n",
            "Epoch 18 Batch 5600 Loss 0.7895 Accuracy 0.5266\n",
            "Epoch 18 Batch 5650 Loss 0.7904 Accuracy 0.5263\n",
            "Epoch 18 Batch 5700 Loss 0.7912 Accuracy 0.5261\n",
            "Saving checkpoint for epoch 18 at ./drive/My Drive/projects/transformer/ckpt/ckpt-33\n",
            "Time taken for 1 epoch: 1444.7776198387146 secs\n",
            "\n",
            "Start of epoch 19\n",
            "Epoch 19 Batch 0 Loss 0.8655 Accuracy 0.5255\n",
            "Epoch 19 Batch 50 Loss 0.8967 Accuracy 0.5116\n",
            "Epoch 19 Batch 100 Loss 0.8980 Accuracy 0.5107\n",
            "Epoch 19 Batch 150 Loss 0.8989 Accuracy 0.5086\n",
            "Epoch 19 Batch 200 Loss 0.8905 Accuracy 0.5090\n",
            "Epoch 19 Batch 250 Loss 0.8919 Accuracy 0.5090\n",
            "Epoch 19 Batch 300 Loss 0.8866 Accuracy 0.5096\n",
            "Epoch 19 Batch 350 Loss 0.8864 Accuracy 0.5089\n",
            "Epoch 19 Batch 400 Loss 0.8827 Accuracy 0.5099\n",
            "Epoch 19 Batch 450 Loss 0.8824 Accuracy 0.5092\n",
            "Epoch 19 Batch 500 Loss 0.8804 Accuracy 0.5084\n",
            "Epoch 19 Batch 550 Loss 0.8821 Accuracy 0.5080\n",
            "Epoch 19 Batch 600 Loss 0.8826 Accuracy 0.5083\n",
            "Epoch 19 Batch 650 Loss 0.8817 Accuracy 0.5084\n",
            "Epoch 19 Batch 700 Loss 0.8802 Accuracy 0.5083\n",
            "Epoch 19 Batch 750 Loss 0.8804 Accuracy 0.5087\n",
            "Epoch 19 Batch 800 Loss 0.8783 Accuracy 0.5090\n",
            "Epoch 19 Batch 850 Loss 0.8780 Accuracy 0.5091\n",
            "Epoch 19 Batch 900 Loss 0.8772 Accuracy 0.5093\n",
            "Epoch 19 Batch 950 Loss 0.8760 Accuracy 0.5093\n",
            "Epoch 19 Batch 1000 Loss 0.8740 Accuracy 0.5094\n",
            "Epoch 19 Batch 1050 Loss 0.8735 Accuracy 0.5098\n",
            "Epoch 19 Batch 1100 Loss 0.8725 Accuracy 0.5100\n",
            "Epoch 19 Batch 1150 Loss 0.8713 Accuracy 0.5103\n",
            "Epoch 19 Batch 1200 Loss 0.8697 Accuracy 0.5105\n",
            "Epoch 19 Batch 1250 Loss 0.8674 Accuracy 0.5108\n",
            "Epoch 19 Batch 1300 Loss 0.8647 Accuracy 0.5113\n",
            "Epoch 19 Batch 1350 Loss 0.8624 Accuracy 0.5119\n",
            "Epoch 19 Batch 1400 Loss 0.8602 Accuracy 0.5127\n",
            "Epoch 19 Batch 1450 Loss 0.8569 Accuracy 0.5133\n",
            "Epoch 19 Batch 1500 Loss 0.8547 Accuracy 0.5143\n",
            "Epoch 19 Batch 1550 Loss 0.8524 Accuracy 0.5150\n",
            "Epoch 19 Batch 1600 Loss 0.8502 Accuracy 0.5159\n",
            "Epoch 19 Batch 1650 Loss 0.8480 Accuracy 0.5168\n",
            "Epoch 19 Batch 1700 Loss 0.8457 Accuracy 0.5174\n",
            "Epoch 19 Batch 1750 Loss 0.8433 Accuracy 0.5182\n",
            "Epoch 19 Batch 1800 Loss 0.8407 Accuracy 0.5192\n",
            "Epoch 19 Batch 1850 Loss 0.8384 Accuracy 0.5199\n",
            "Epoch 19 Batch 1900 Loss 0.8362 Accuracy 0.5207\n",
            "Epoch 19 Batch 1950 Loss 0.8334 Accuracy 0.5213\n",
            "Epoch 19 Batch 2000 Loss 0.8320 Accuracy 0.5219\n",
            "Epoch 19 Batch 2050 Loss 0.8303 Accuracy 0.5224\n",
            "Epoch 19 Batch 2100 Loss 0.8285 Accuracy 0.5228\n",
            "Epoch 19 Batch 2150 Loss 0.8259 Accuracy 0.5230\n",
            "Epoch 19 Batch 2200 Loss 0.8232 Accuracy 0.5231\n",
            "Epoch 19 Batch 2250 Loss 0.8206 Accuracy 0.5233\n",
            "Epoch 19 Batch 2300 Loss 0.8176 Accuracy 0.5235\n",
            "Epoch 19 Batch 2350 Loss 0.8153 Accuracy 0.5238\n",
            "Epoch 19 Batch 2400 Loss 0.8127 Accuracy 0.5241\n",
            "Epoch 19 Batch 2450 Loss 0.8101 Accuracy 0.5241\n",
            "Epoch 19 Batch 2500 Loss 0.8076 Accuracy 0.5244\n",
            "Epoch 19 Batch 2550 Loss 0.8050 Accuracy 0.5248\n",
            "Epoch 19 Batch 2600 Loss 0.8023 Accuracy 0.5250\n",
            "Epoch 19 Batch 2650 Loss 0.7999 Accuracy 0.5253\n",
            "Epoch 19 Batch 2700 Loss 0.7975 Accuracy 0.5256\n",
            "Epoch 19 Batch 2750 Loss 0.7947 Accuracy 0.5258\n",
            "Epoch 19 Batch 2800 Loss 0.7930 Accuracy 0.5261\n",
            "Epoch 19 Batch 2850 Loss 0.7910 Accuracy 0.5265\n",
            "Epoch 19 Batch 2900 Loss 0.7891 Accuracy 0.5267\n",
            "Epoch 19 Batch 2950 Loss 0.7873 Accuracy 0.5270\n",
            "Epoch 19 Batch 3000 Loss 0.7855 Accuracy 0.5272\n",
            "Epoch 19 Batch 3050 Loss 0.7838 Accuracy 0.5273\n",
            "Epoch 19 Batch 3100 Loss 0.7825 Accuracy 0.5275\n",
            "Epoch 19 Batch 3150 Loss 0.7808 Accuracy 0.5278\n",
            "Epoch 19 Batch 3200 Loss 0.7793 Accuracy 0.5279\n",
            "Epoch 19 Batch 3250 Loss 0.7773 Accuracy 0.5282\n",
            "Epoch 19 Batch 3300 Loss 0.7756 Accuracy 0.5284\n",
            "Epoch 19 Batch 3350 Loss 0.7738 Accuracy 0.5286\n",
            "Epoch 19 Batch 3400 Loss 0.7719 Accuracy 0.5289\n",
            "Epoch 19 Batch 3450 Loss 0.7705 Accuracy 0.5291\n",
            "Epoch 19 Batch 3500 Loss 0.7688 Accuracy 0.5295\n",
            "Epoch 19 Batch 3550 Loss 0.7672 Accuracy 0.5297\n",
            "Epoch 19 Batch 3600 Loss 0.7658 Accuracy 0.5300\n",
            "Epoch 19 Batch 3650 Loss 0.7642 Accuracy 0.5303\n",
            "Epoch 19 Batch 3700 Loss 0.7630 Accuracy 0.5306\n",
            "Epoch 19 Batch 3750 Loss 0.7617 Accuracy 0.5309\n",
            "Epoch 19 Batch 3800 Loss 0.7603 Accuracy 0.5312\n",
            "Epoch 19 Batch 3850 Loss 0.7588 Accuracy 0.5315\n",
            "Epoch 19 Batch 3900 Loss 0.7575 Accuracy 0.5319\n",
            "Epoch 19 Batch 3950 Loss 0.7563 Accuracy 0.5321\n",
            "Epoch 19 Batch 4000 Loss 0.7552 Accuracy 0.5323\n",
            "Epoch 19 Batch 4050 Loss 0.7541 Accuracy 0.5325\n",
            "Epoch 19 Batch 4100 Loss 0.7533 Accuracy 0.5328\n",
            "Epoch 19 Batch 4150 Loss 0.7530 Accuracy 0.5328\n",
            "Epoch 19 Batch 4200 Loss 0.7532 Accuracy 0.5329\n",
            "Epoch 19 Batch 4250 Loss 0.7536 Accuracy 0.5328\n",
            "Epoch 19 Batch 4300 Loss 0.7544 Accuracy 0.5327\n",
            "Epoch 19 Batch 4350 Loss 0.7555 Accuracy 0.5326\n",
            "Epoch 19 Batch 4400 Loss 0.7567 Accuracy 0.5324\n",
            "Epoch 19 Batch 4450 Loss 0.7577 Accuracy 0.5322\n",
            "Epoch 19 Batch 4500 Loss 0.7591 Accuracy 0.5321\n",
            "Epoch 19 Batch 4550 Loss 0.7603 Accuracy 0.5319\n",
            "Epoch 19 Batch 4600 Loss 0.7615 Accuracy 0.5317\n",
            "Epoch 19 Batch 4650 Loss 0.7629 Accuracy 0.5314\n",
            "Epoch 19 Batch 4700 Loss 0.7645 Accuracy 0.5312\n",
            "Epoch 19 Batch 4750 Loss 0.7658 Accuracy 0.5311\n",
            "Epoch 19 Batch 4800 Loss 0.7671 Accuracy 0.5309\n",
            "Epoch 19 Batch 4850 Loss 0.7685 Accuracy 0.5307\n",
            "Epoch 19 Batch 4900 Loss 0.7699 Accuracy 0.5305\n",
            "Epoch 19 Batch 4950 Loss 0.7710 Accuracy 0.5303\n",
            "Epoch 19 Batch 5000 Loss 0.7724 Accuracy 0.5302\n",
            "Epoch 19 Batch 5050 Loss 0.7736 Accuracy 0.5300\n",
            "Epoch 19 Batch 5100 Loss 0.7751 Accuracy 0.5297\n",
            "Epoch 19 Batch 5150 Loss 0.7764 Accuracy 0.5294\n",
            "Epoch 19 Batch 5200 Loss 0.7778 Accuracy 0.5291\n",
            "Epoch 19 Batch 5250 Loss 0.7790 Accuracy 0.5289\n",
            "Epoch 19 Batch 5300 Loss 0.7800 Accuracy 0.5286\n",
            "Epoch 19 Batch 5350 Loss 0.7814 Accuracy 0.5283\n",
            "Epoch 19 Batch 5400 Loss 0.7824 Accuracy 0.5280\n",
            "Epoch 19 Batch 5450 Loss 0.7835 Accuracy 0.5277\n",
            "Epoch 19 Batch 5500 Loss 0.7847 Accuracy 0.5274\n",
            "Epoch 19 Batch 5550 Loss 0.7857 Accuracy 0.5271\n",
            "Epoch 19 Batch 5600 Loss 0.7868 Accuracy 0.5268\n",
            "Epoch 19 Batch 5650 Loss 0.7877 Accuracy 0.5266\n",
            "Epoch 19 Batch 5700 Loss 0.7889 Accuracy 0.5263\n",
            "Saving checkpoint for epoch 19 at ./drive/My Drive/projects/transformer/ckpt/ckpt-34\n",
            "Time taken for 1 epoch: 1430.865211725235 secs\n",
            "\n",
            "Start of epoch 20\n",
            "Epoch 20 Batch 0 Loss 0.9794 Accuracy 0.5156\n",
            "Epoch 20 Batch 50 Loss 0.9059 Accuracy 0.5127\n",
            "Epoch 20 Batch 100 Loss 0.8921 Accuracy 0.5102\n",
            "Epoch 20 Batch 150 Loss 0.8844 Accuracy 0.5105\n",
            "Epoch 20 Batch 200 Loss 0.8824 Accuracy 0.5085\n",
            "Epoch 20 Batch 250 Loss 0.8841 Accuracy 0.5092\n",
            "Epoch 20 Batch 300 Loss 0.8831 Accuracy 0.5088\n",
            "Epoch 20 Batch 350 Loss 0.8826 Accuracy 0.5084\n",
            "Epoch 20 Batch 400 Loss 0.8801 Accuracy 0.5093\n",
            "Epoch 20 Batch 450 Loss 0.8783 Accuracy 0.5092\n",
            "Epoch 20 Batch 500 Loss 0.8764 Accuracy 0.5088\n",
            "Epoch 20 Batch 550 Loss 0.8756 Accuracy 0.5090\n",
            "Epoch 20 Batch 600 Loss 0.8742 Accuracy 0.5093\n",
            "Epoch 20 Batch 650 Loss 0.8742 Accuracy 0.5095\n",
            "Epoch 20 Batch 700 Loss 0.8724 Accuracy 0.5098\n",
            "Epoch 20 Batch 750 Loss 0.8726 Accuracy 0.5100\n",
            "Epoch 20 Batch 800 Loss 0.8725 Accuracy 0.5102\n",
            "Epoch 20 Batch 850 Loss 0.8718 Accuracy 0.5105\n",
            "Epoch 20 Batch 900 Loss 0.8722 Accuracy 0.5108\n",
            "Epoch 20 Batch 950 Loss 0.8724 Accuracy 0.5107\n",
            "Epoch 20 Batch 1000 Loss 0.8702 Accuracy 0.5106\n",
            "Epoch 20 Batch 1050 Loss 0.8698 Accuracy 0.5108\n",
            "Epoch 20 Batch 1100 Loss 0.8680 Accuracy 0.5108\n",
            "Epoch 20 Batch 1150 Loss 0.8663 Accuracy 0.5111\n",
            "Epoch 20 Batch 1200 Loss 0.8649 Accuracy 0.5114\n",
            "Epoch 20 Batch 1250 Loss 0.8635 Accuracy 0.5118\n",
            "Epoch 20 Batch 1300 Loss 0.8605 Accuracy 0.5122\n",
            "Epoch 20 Batch 1350 Loss 0.8593 Accuracy 0.5127\n",
            "Epoch 20 Batch 1400 Loss 0.8571 Accuracy 0.5135\n",
            "Epoch 20 Batch 1450 Loss 0.8545 Accuracy 0.5143\n",
            "Epoch 20 Batch 1500 Loss 0.8515 Accuracy 0.5150\n",
            "Epoch 20 Batch 1550 Loss 0.8488 Accuracy 0.5160\n",
            "Epoch 20 Batch 1600 Loss 0.8458 Accuracy 0.5169\n",
            "Epoch 20 Batch 1650 Loss 0.8436 Accuracy 0.5175\n",
            "Epoch 20 Batch 1700 Loss 0.8415 Accuracy 0.5184\n",
            "Epoch 20 Batch 1750 Loss 0.8396 Accuracy 0.5192\n",
            "Epoch 20 Batch 1800 Loss 0.8376 Accuracy 0.5199\n",
            "Epoch 20 Batch 1850 Loss 0.8358 Accuracy 0.5207\n",
            "Epoch 20 Batch 1900 Loss 0.8333 Accuracy 0.5215\n",
            "Epoch 20 Batch 1950 Loss 0.8315 Accuracy 0.5221\n",
            "Epoch 20 Batch 2000 Loss 0.8293 Accuracy 0.5227\n",
            "Epoch 20 Batch 2050 Loss 0.8278 Accuracy 0.5231\n",
            "Epoch 20 Batch 2100 Loss 0.8257 Accuracy 0.5234\n",
            "Epoch 20 Batch 2150 Loss 0.8229 Accuracy 0.5237\n",
            "Epoch 20 Batch 2200 Loss 0.8200 Accuracy 0.5240\n",
            "Epoch 20 Batch 2250 Loss 0.8173 Accuracy 0.5241\n",
            "Epoch 20 Batch 2300 Loss 0.8144 Accuracy 0.5241\n",
            "Epoch 20 Batch 2350 Loss 0.8117 Accuracy 0.5243\n",
            "Epoch 20 Batch 2400 Loss 0.8093 Accuracy 0.5245\n",
            "Epoch 20 Batch 2450 Loss 0.8069 Accuracy 0.5248\n",
            "Epoch 20 Batch 2500 Loss 0.8041 Accuracy 0.5251\n",
            "Epoch 20 Batch 2550 Loss 0.8014 Accuracy 0.5252\n",
            "Epoch 20 Batch 2600 Loss 0.7991 Accuracy 0.5256\n",
            "Epoch 20 Batch 2650 Loss 0.7965 Accuracy 0.5259\n",
            "Epoch 20 Batch 2700 Loss 0.7942 Accuracy 0.5262\n",
            "Epoch 20 Batch 2750 Loss 0.7920 Accuracy 0.5265\n",
            "Epoch 20 Batch 2800 Loss 0.7901 Accuracy 0.5267\n",
            "Epoch 20 Batch 2850 Loss 0.7884 Accuracy 0.5270\n",
            "Epoch 20 Batch 2900 Loss 0.7863 Accuracy 0.5272\n",
            "Epoch 20 Batch 2950 Loss 0.7846 Accuracy 0.5275\n",
            "Epoch 20 Batch 3000 Loss 0.7829 Accuracy 0.5278\n",
            "Epoch 20 Batch 3050 Loss 0.7814 Accuracy 0.5281\n",
            "Epoch 20 Batch 3100 Loss 0.7797 Accuracy 0.5282\n",
            "Epoch 20 Batch 3150 Loss 0.7780 Accuracy 0.5285\n",
            "Epoch 20 Batch 3200 Loss 0.7762 Accuracy 0.5286\n",
            "Epoch 20 Batch 3250 Loss 0.7744 Accuracy 0.5288\n",
            "Epoch 20 Batch 3300 Loss 0.7727 Accuracy 0.5290\n",
            "Epoch 20 Batch 3350 Loss 0.7710 Accuracy 0.5293\n",
            "Epoch 20 Batch 3400 Loss 0.7692 Accuracy 0.5295\n",
            "Epoch 20 Batch 3450 Loss 0.7676 Accuracy 0.5297\n",
            "Epoch 20 Batch 3500 Loss 0.7658 Accuracy 0.5300\n",
            "Epoch 20 Batch 3550 Loss 0.7642 Accuracy 0.5303\n",
            "Epoch 20 Batch 3600 Loss 0.7629 Accuracy 0.5305\n",
            "Epoch 20 Batch 3650 Loss 0.7614 Accuracy 0.5308\n",
            "Epoch 20 Batch 3700 Loss 0.7600 Accuracy 0.5312\n",
            "Epoch 20 Batch 3750 Loss 0.7586 Accuracy 0.5314\n",
            "Epoch 20 Batch 3800 Loss 0.7573 Accuracy 0.5318\n",
            "Epoch 20 Batch 3850 Loss 0.7558 Accuracy 0.5321\n",
            "Epoch 20 Batch 3900 Loss 0.7548 Accuracy 0.5324\n",
            "Epoch 20 Batch 3950 Loss 0.7535 Accuracy 0.5327\n",
            "Epoch 20 Batch 4000 Loss 0.7524 Accuracy 0.5329\n",
            "Epoch 20 Batch 4050 Loss 0.7512 Accuracy 0.5332\n",
            "Epoch 20 Batch 4100 Loss 0.7506 Accuracy 0.5334\n",
            "Epoch 20 Batch 4150 Loss 0.7502 Accuracy 0.5335\n",
            "Epoch 20 Batch 4200 Loss 0.7505 Accuracy 0.5335\n",
            "Epoch 20 Batch 4250 Loss 0.7511 Accuracy 0.5335\n",
            "Epoch 20 Batch 4300 Loss 0.7520 Accuracy 0.5335\n",
            "Epoch 20 Batch 4350 Loss 0.7528 Accuracy 0.5333\n",
            "Epoch 20 Batch 4400 Loss 0.7538 Accuracy 0.5332\n",
            "Epoch 20 Batch 4450 Loss 0.7549 Accuracy 0.5329\n",
            "Epoch 20 Batch 4500 Loss 0.7564 Accuracy 0.5327\n",
            "Epoch 20 Batch 4550 Loss 0.7577 Accuracy 0.5325\n",
            "Epoch 20 Batch 4600 Loss 0.7591 Accuracy 0.5323\n",
            "Epoch 20 Batch 4650 Loss 0.7606 Accuracy 0.5321\n",
            "Epoch 20 Batch 4700 Loss 0.7618 Accuracy 0.5319\n",
            "Epoch 20 Batch 4750 Loss 0.7632 Accuracy 0.5317\n",
            "Epoch 20 Batch 4800 Loss 0.7643 Accuracy 0.5315\n",
            "Epoch 20 Batch 4850 Loss 0.7653 Accuracy 0.5313\n",
            "Epoch 20 Batch 4900 Loss 0.7668 Accuracy 0.5311\n",
            "Epoch 20 Batch 4950 Loss 0.7679 Accuracy 0.5308\n",
            "Epoch 20 Batch 5000 Loss 0.7693 Accuracy 0.5306\n",
            "Epoch 20 Batch 5050 Loss 0.7708 Accuracy 0.5304\n",
            "Epoch 20 Batch 5100 Loss 0.7721 Accuracy 0.5302\n",
            "Epoch 20 Batch 5150 Loss 0.7733 Accuracy 0.5299\n",
            "Epoch 20 Batch 5200 Loss 0.7744 Accuracy 0.5296\n",
            "Epoch 20 Batch 5250 Loss 0.7759 Accuracy 0.5293\n",
            "Epoch 20 Batch 5300 Loss 0.7770 Accuracy 0.5291\n",
            "Epoch 20 Batch 5350 Loss 0.7785 Accuracy 0.5288\n",
            "Epoch 20 Batch 5400 Loss 0.7796 Accuracy 0.5285\n",
            "Epoch 20 Batch 5450 Loss 0.7808 Accuracy 0.5282\n",
            "Epoch 20 Batch 5500 Loss 0.7819 Accuracy 0.5279\n",
            "Epoch 20 Batch 5550 Loss 0.7829 Accuracy 0.5275\n",
            "Epoch 20 Batch 5600 Loss 0.7839 Accuracy 0.5273\n",
            "Epoch 20 Batch 5650 Loss 0.7849 Accuracy 0.5271\n",
            "Epoch 20 Batch 5700 Loss 0.7858 Accuracy 0.5268\n",
            "Saving checkpoint for epoch 20 at ./drive/My Drive/projects/transformer/ckpt/ckpt-35\n",
            "Time taken for 1 epoch: 1432.0767476558685 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPjWz6wl4xOk",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aijwqg12yqXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(inp_sentence):\n",
        "    inp_sentence = [VOCAB_SIZE_EN-2] + tokenizer_en.encode(inp_sentence) + [VOCAB_SIZE_EN-1]\n",
        "    enc_input = tf.expand_dims(inp_sentence, axis=0)\n",
        "\n",
        "    output = tf.expand_dims([VOCAB_SIZE_FR-2], axis=0)\n",
        "\n",
        "    for _ in range(MAX_LENGTH):\n",
        "        predictions = transformer(enc_input, output, False)\n",
        "\n",
        "        prediction = predictions[:, -1:, :]\n",
        "\n",
        "        predicted_id = tf.cast(tf.argmax(prediction, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == VOCAB_SIZE_FR-1:\n",
        "            return tf.squeeze(output, axis=0)\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXgEgITm_DjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "    output = evaluate(sentence).numpy()\n",
        "\n",
        "    predicted_sentence = tokenizer_fr.decode(\n",
        "        [i for i in output if i < VOCAB_SIZE_FR-2]\n",
        "    )\n",
        "\n",
        "    print(\"Input: {}\".format(sentence))\n",
        "    print(\"Predicted translation: {}\".format(predicted_sentence))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qounFEwu_o7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bd8925f3-9f28-4b7a-aaf3-f99349095a71"
      },
      "source": [
        "translate(\"It is ideal !!\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: It is ideal !!\n",
            "Predicted translation: C'est idéal!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blt_PaJN_tat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "God is great\n",
        "I am well informed\n",
        "This a really powerfull tool\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}